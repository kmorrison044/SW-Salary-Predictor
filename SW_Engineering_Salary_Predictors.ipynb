{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7b550b62-7273-40f1-888b-a80f77daf315",
      "metadata": {
        "id": "7b550b62-7273-40f1-888b-a80f77daf315"
      },
      "source": [
        "# Final Project Morrison\n",
        "\n",
        "Link to the Kaggle Dataset:\n",
        "https://www.kaggle.com/datasets/emreksz/software-engineer-jobs-and-salaries-2024\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad547835-9d35-40f0-8e67-ee364811bbf5",
      "metadata": {
        "id": "ad547835-9d35-40f0-8e67-ee364811bbf5"
      },
      "source": [
        "# Problem Description\n",
        "\n",
        "It is a common occurrence for job seekers to find jobs on job listing sites such as Indeed, Linkedin, etc. to look for their future employer. An issue with some of these job postings is that the salary expectation is not given in the posting, leaving job seekers blind to what the employer is expecting to pay for the job. This can be an issue for candidates who land interviews, just to find out that their and the employers salary expectations were vastly different, effectively wasting the time of both the candidate and employer.\n",
        "\n",
        "Using the salary data from the kaggle dataset, I will engineer features and use them to predict SW engineering salaries to help combat this problem. In this project, I continue the work that I performed on this issue in the second ML course. Previously I used supervised algorithms to predict the salary based on the features I created from the data while using PCA as an unsupervised feature reduction technique. In this iteration of the project, I will utilize deep learning via a multilayer perceptron network to learn how to map the feature space into a predicted salary amount.\n",
        "\n",
        "Using the MLP, I hope to further reduce the MAE from the original models' results."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install us"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ljs2qd5-QNKr",
        "outputId": "9c6218a8-ac46-485d-cb01-fdd473035e98"
      },
      "id": "ljs2qd5-QNKr",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting us\n",
            "  Downloading us-3.2.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: jellyfish in /usr/local/lib/python3.10/dist-packages (from us) (1.1.0)\n",
            "Downloading us-3.2.0-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: us\n",
            "Successfully installed us-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "5d486d43-17b0-41c3-93fd-2d0e0c586b5a",
      "metadata": {
        "id": "5d486d43-17b0-41c3-93fd-2d0e0c586b5a"
      },
      "outputs": [],
      "source": [
        "# Import the proper libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, r2_score\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import norm\n",
        "import re\n",
        "import us\n",
        "from tensorflow.keras.layers import Dense, Input, Concatenate, BatchNormalization, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "from google.colab import files, drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attach my drive to my notebook so I can access the data\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QIt9lCyZQ07F",
        "outputId": "e2c1c480-aa29-47cd-a172-f263e709c794"
      },
      "id": "QIt9lCyZQ07F",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4203de67-9615-4e32-b51d-cb29ac28c518",
      "metadata": {
        "id": "4203de67-9615-4e32-b51d-cb29ac28c518"
      },
      "source": [
        "# Exploratory Data Analysis\n",
        "\n",
        "Before building my models to predict the data, I inspect the data and clean it to prepare it for the ML algorithms I will implement. Below can be observed that there are 764 salary samples. Because of this, I dropped all of the data fields that did not include salary information. I also converted the salary range into a single value by taking the average of the range.\n",
        "\n",
        "Since job titles vary from company to company, I extracted specializations, role, and seniority level from the titles to provide more universal data to the models from which to learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "769462b7-fe90-4fe0-a3f3-d069258fd5a1",
      "metadata": {
        "id": "769462b7-fe90-4fe0-a3f3-d069258fd5a1"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(r'/content/drive/MyDrive/Colab Notebooks/ML3 Final/Data/Software Engineer Salaries.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "886e9517-53b2-4092-b9c8-080d188feb59",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "886e9517-53b2-4092-b9c8-080d188feb59",
        "outputId": "d2398f90-26b4-4f2d-f293-811adc540f46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Company  Company Score  \\\n",
              "0                       ViewSoft            4.8   \n",
              "1                        Workiva            4.3   \n",
              "2     Garmin International, Inc.            3.9   \n",
              "3                       Snapchat            3.5   \n",
              "4  Vitesco Technologies Group AG            3.1   \n",
              "5                        Spotify            3.9   \n",
              "6                          Infor            4.0   \n",
              "7          Amerisoft Corporation            5.0   \n",
              "8                          WHOOP            3.3   \n",
              "9                            PFF            4.2   \n",
              "\n",
              "                                           Job Title              Location  \\\n",
              "0                                  Software Engineer          Manassas, VA   \n",
              "1                          Software Support Engineer                Remote   \n",
              "2                               C# Software Engineer              Cary, NC   \n",
              "3  Software Engineer, Fullstack, 1+ Years of Expe...       Los Angeles, CA   \n",
              "4                                  Software Engineer            Seguin, TX   \n",
              "5                                Backend Engineer II          New York, NY   \n",
              "6                        Associate Software Engineer        Alpharetta, GA   \n",
              "7                                Software Developers  Farmington Hills, MI   \n",
              "8             Software Engineer II (Backend, Health)            Boston, MA   \n",
              "9                              Sr. Software Engineer                Remote   \n",
              "\n",
              "   Date                         Salary  \n",
              "0    8d   $68K - $94K (Glassdoor est.)  \n",
              "1    2d   $61K - $104K (Employer est.)  \n",
              "2    2d  $95K - $118K (Glassdoor est.)  \n",
              "3    2d   $97K - $145K (Employer est.)  \n",
              "4    2d  $85K - $108K (Glassdoor est.)  \n",
              "5    1d  $123K - $175K (Employer est.)  \n",
              "6    7d   $77K - $94K (Glassdoor est.)  \n",
              "7  30d+  $71K - $100K (Glassdoor est.)  \n",
              "8   10d  $94K - $148K (Glassdoor est.)  \n",
              "9    1d  $147K - $189K (Employer est.)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-042092c1-adfc-4c74-b4c6-7097aada4f92\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Company Score</th>\n",
              "      <th>Job Title</th>\n",
              "      <th>Location</th>\n",
              "      <th>Date</th>\n",
              "      <th>Salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ViewSoft</td>\n",
              "      <td>4.8</td>\n",
              "      <td>Software Engineer</td>\n",
              "      <td>Manassas, VA</td>\n",
              "      <td>8d</td>\n",
              "      <td>$68K - $94K (Glassdoor est.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Workiva</td>\n",
              "      <td>4.3</td>\n",
              "      <td>Software Support Engineer</td>\n",
              "      <td>Remote</td>\n",
              "      <td>2d</td>\n",
              "      <td>$61K - $104K (Employer est.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Garmin International, Inc.</td>\n",
              "      <td>3.9</td>\n",
              "      <td>C# Software Engineer</td>\n",
              "      <td>Cary, NC</td>\n",
              "      <td>2d</td>\n",
              "      <td>$95K - $118K (Glassdoor est.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Snapchat</td>\n",
              "      <td>3.5</td>\n",
              "      <td>Software Engineer, Fullstack, 1+ Years of Expe...</td>\n",
              "      <td>Los Angeles, CA</td>\n",
              "      <td>2d</td>\n",
              "      <td>$97K - $145K (Employer est.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Vitesco Technologies Group AG</td>\n",
              "      <td>3.1</td>\n",
              "      <td>Software Engineer</td>\n",
              "      <td>Seguin, TX</td>\n",
              "      <td>2d</td>\n",
              "      <td>$85K - $108K (Glassdoor est.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Spotify</td>\n",
              "      <td>3.9</td>\n",
              "      <td>Backend Engineer II</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>1d</td>\n",
              "      <td>$123K - $175K (Employer est.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Infor</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Associate Software Engineer</td>\n",
              "      <td>Alpharetta, GA</td>\n",
              "      <td>7d</td>\n",
              "      <td>$77K - $94K (Glassdoor est.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Amerisoft Corporation</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Software Developers</td>\n",
              "      <td>Farmington Hills, MI</td>\n",
              "      <td>30d+</td>\n",
              "      <td>$71K - $100K (Glassdoor est.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>WHOOP</td>\n",
              "      <td>3.3</td>\n",
              "      <td>Software Engineer II (Backend, Health)</td>\n",
              "      <td>Boston, MA</td>\n",
              "      <td>10d</td>\n",
              "      <td>$94K - $148K (Glassdoor est.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>PFF</td>\n",
              "      <td>4.2</td>\n",
              "      <td>Sr. Software Engineer</td>\n",
              "      <td>Remote</td>\n",
              "      <td>1d</td>\n",
              "      <td>$147K - $189K (Employer est.)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-042092c1-adfc-4c74-b4c6-7097aada4f92')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-042092c1-adfc-4c74-b4c6-7097aada4f92 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-042092c1-adfc-4c74-b4c6-7097aada4f92');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a7aa6373-7e3a-4007-869a-12acd243da77\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a7aa6373-7e3a-4007-869a-12acd243da77')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a7aa6373-7e3a-4007-869a-12acd243da77 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 870,\n  \"fields\": [\n    {\n      \"column\": \"Company\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 648,\n        \"samples\": [\n          \"PacBio\",\n          \"BAE Systems\",\n          \"Turn5, Inc.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Company Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5249518335684344,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          2.5,\n          4.4,\n          2.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Job Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 542,\n        \"samples\": [\n          \"Junior Software Engineer - Panama Shift!\",\n          \"Software Engineer - Java Springboot (DT)\",\n          \"Software Engineer / Simulation - Virtual Prototyping\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 329,\n        \"samples\": [\n          \"San Francisco, CA\",\n          \"Redwood City, CA\",\n          \"Sherman, TX\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 31,\n        \"samples\": [\n          \"27d\",\n          \"16d\",\n          \"29d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Salary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 680,\n        \"samples\": [\n          \"$53K - $96K\\u00a0(Glassdoor est.)\",\n          \"$102K - $159K\\u00a0(Employer est.)\",\n          \"$141K - $179K\\u00a0(Employer est.)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7ae80e1a-cb9f-4b95-92bf-84049f59716c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "7ae80e1a-cb9f-4b95-92bf-84049f59716c",
        "outputId": "2c8d555a-68ad-4c66-b3f9-6ac274e8609c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           Company  Company Score  \\\n",
              "860  Westchester Community College            NaN   \n",
              "861                    DPS Telecom            NaN   \n",
              "862                         Roblox            NaN   \n",
              "863                         OpenAI            NaN   \n",
              "864                    Akina, Inc.            NaN   \n",
              "865                            RXO            NaN   \n",
              "866                        Infosys            NaN   \n",
              "867                      Medtronic            NaN   \n",
              "868                            NaN            NaN   \n",
              "869                            NaN            NaN   \n",
              "\n",
              "                                        Job Title                Location  \\\n",
              "860         Software Development Engineer in Test       San Francisco, CA   \n",
              "861           Software & System Dev. Sr. Engineer             Raymond, OH   \n",
              "862                          Software Engineer II            Valhalla, NY   \n",
              "863      Embedded Software Engineer (Entry-Level)      Lake Hopatcong, NJ   \n",
              "864  Senior Software Engineer - App Orchestration           San Mateo, CA   \n",
              "865   Software Engineer, Machine Learning Compute       San Francisco, CA   \n",
              "866           Software Engineer - 3 (Apache NiFi)  Annapolis Junction, MD   \n",
              "867                      Senior Software Engineer          Southfield, MI   \n",
              "868                       Junior Python Developer           Charlotte, NC   \n",
              "869  GUI Software Engineer II - Surgical Robotics              Boston, MA   \n",
              "\n",
              "     Date Salary  \n",
              "860  30d+    NaN  \n",
              "861  30d+    NaN  \n",
              "862    3d    NaN  \n",
              "863    2d    NaN  \n",
              "864  30d+    NaN  \n",
              "865    6d    NaN  \n",
              "866   18d    NaN  \n",
              "867   19d    NaN  \n",
              "868    2d    NaN  \n",
              "869   10d    NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5aa7b2e6-5bb7-4769-8fe5-84a8026d4b0f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Company Score</th>\n",
              "      <th>Job Title</th>\n",
              "      <th>Location</th>\n",
              "      <th>Date</th>\n",
              "      <th>Salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>Westchester Community College</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Software Development Engineer in Test</td>\n",
              "      <td>San Francisco, CA</td>\n",
              "      <td>30d+</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>861</th>\n",
              "      <td>DPS Telecom</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Software &amp; System Dev. Sr. Engineer</td>\n",
              "      <td>Raymond, OH</td>\n",
              "      <td>30d+</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>862</th>\n",
              "      <td>Roblox</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Software Engineer II</td>\n",
              "      <td>Valhalla, NY</td>\n",
              "      <td>3d</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>863</th>\n",
              "      <td>OpenAI</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Embedded Software Engineer (Entry-Level)</td>\n",
              "      <td>Lake Hopatcong, NJ</td>\n",
              "      <td>2d</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>864</th>\n",
              "      <td>Akina, Inc.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Senior Software Engineer - App Orchestration</td>\n",
              "      <td>San Mateo, CA</td>\n",
              "      <td>30d+</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865</th>\n",
              "      <td>RXO</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Software Engineer, Machine Learning Compute</td>\n",
              "      <td>San Francisco, CA</td>\n",
              "      <td>6d</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>866</th>\n",
              "      <td>Infosys</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Software Engineer - 3 (Apache NiFi)</td>\n",
              "      <td>Annapolis Junction, MD</td>\n",
              "      <td>18d</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>867</th>\n",
              "      <td>Medtronic</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Senior Software Engineer</td>\n",
              "      <td>Southfield, MI</td>\n",
              "      <td>19d</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>868</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Junior Python Developer</td>\n",
              "      <td>Charlotte, NC</td>\n",
              "      <td>2d</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>869</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GUI Software Engineer II - Surgical Robotics</td>\n",
              "      <td>Boston, MA</td>\n",
              "      <td>10d</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5aa7b2e6-5bb7-4769-8fe5-84a8026d4b0f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5aa7b2e6-5bb7-4769-8fe5-84a8026d4b0f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5aa7b2e6-5bb7-4769-8fe5-84a8026d4b0f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-40d2571a-6143-4ae1-85c8-ae7b37362ce7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-40d2571a-6143-4ae1-85c8-ae7b37362ce7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-40d2571a-6143-4ae1-85c8-ae7b37362ce7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4cdf6509-e73f-438e-8cfd-1d3e12518a1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4cdf6509-e73f-438e-8cfd-1d3e12518a1e",
        "outputId": "da858d6f-3a41-4a1d-a39f-6b7c36118cf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(870, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "148bb1a5-6c28-45ec-a0e0-ec2e5f09ccb8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "148bb1a5-6c28-45ec-a0e0-ec2e5f09ccb8",
        "outputId": "2ca1fdd5-30db-4dae-e11e-79be0d03f5c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 870 entries, 0 to 869\n",
            "Data columns (total 6 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Company        868 non-null    object \n",
            " 1   Company Score  789 non-null    float64\n",
            " 2   Job Title      870 non-null    object \n",
            " 3   Location       857 non-null    object \n",
            " 4   Date           870 non-null    object \n",
            " 5   Salary         764 non-null    object \n",
            "dtypes: float64(1), object(5)\n",
            "memory usage: 40.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "500642ef-1955-4298-93e1-8d7648c39e39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "500642ef-1955-4298-93e1-8d7648c39e39",
        "outputId": "d7324765-0d2e-4db8-a156-8befc079ea9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Company  Company Score          Job Title       Location  Date  \\\n",
              "count          868     789.000000                870            857   870   \n",
              "unique         648            NaN                542            329    31   \n",
              "top     CVS Health            NaN  Software Engineer  United States  30d+   \n",
              "freq             9            NaN                156             48   206   \n",
              "mean           NaN       3.895311                NaN            NaN   NaN   \n",
              "std            NaN       0.524952                NaN            NaN   NaN   \n",
              "min            NaN       1.000000                NaN            NaN   NaN   \n",
              "25%            NaN       3.600000                NaN            NaN   NaN   \n",
              "50%            NaN       3.900000                NaN            NaN   NaN   \n",
              "75%            NaN       4.200000                NaN            NaN   NaN   \n",
              "max            NaN       5.000000                NaN            NaN   NaN   \n",
              "\n",
              "                               Salary  \n",
              "count                             764  \n",
              "unique                            680  \n",
              "top     $120K - $150K (Employer est.)  \n",
              "freq                                5  \n",
              "mean                              NaN  \n",
              "std                               NaN  \n",
              "min                               NaN  \n",
              "25%                               NaN  \n",
              "50%                               NaN  \n",
              "75%                               NaN  \n",
              "max                               NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0282a38c-2cb0-49b1-b14b-4ec5da6fabe8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Company Score</th>\n",
              "      <th>Job Title</th>\n",
              "      <th>Location</th>\n",
              "      <th>Date</th>\n",
              "      <th>Salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>868</td>\n",
              "      <td>789.000000</td>\n",
              "      <td>870</td>\n",
              "      <td>857</td>\n",
              "      <td>870</td>\n",
              "      <td>764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>648</td>\n",
              "      <td>NaN</td>\n",
              "      <td>542</td>\n",
              "      <td>329</td>\n",
              "      <td>31</td>\n",
              "      <td>680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>CVS Health</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Software Engineer</td>\n",
              "      <td>United States</td>\n",
              "      <td>30d+</td>\n",
              "      <td>$120K - $150K (Employer est.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>156</td>\n",
              "      <td>48</td>\n",
              "      <td>206</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>3.895311</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.524952</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0282a38c-2cb0-49b1-b14b-4ec5da6fabe8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0282a38c-2cb0-49b1-b14b-4ec5da6fabe8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0282a38c-2cb0-49b1-b14b-4ec5da6fabe8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f93cb93a-829a-4a8f-9a3b-ae3bb22ee090\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f93cb93a-829a-4a8f-9a3b-ae3bb22ee090')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f93cb93a-829a-4a8f-9a3b-ae3bb22ee090 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 11,\n  \"fields\": [\n    {\n      \"column\": \"Company\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          648,\n          \"9\",\n          \"868\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Company Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 277.84084576258476,\n        \"min\": 0.5249518335684344,\n        \"max\": 789.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.895310519645121,\n          3.9,\n          789.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Job Title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          542,\n          \"156\",\n          \"870\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          329,\n          \"48\",\n          \"857\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          31,\n          \"206\",\n          \"870\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Salary\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          680,\n          \"5\",\n          \"764\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a4cf423c-a0d2-43e2-9257-04cacd274164",
      "metadata": {
        "id": "a4cf423c-a0d2-43e2-9257-04cacd274164"
      },
      "outputs": [],
      "source": [
        "# Extract the salary information, transform the range into a single number via averaging, and convert to an int\n",
        "def clean_salary(salary_str):\n",
        "    salary_range = re.findall(r'\\$([\\dK]+)', salary_str)\n",
        "    salary_range = [int(s.replace('K', '')) * 1000 for s in salary_range]\n",
        "    if len(salary_range) == 1:\n",
        "        return salary_range[0]\n",
        "    elif len(salary_range) > 1:\n",
        "        return np.mean(salary_range)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "df['Salary'] = df['Salary'].astype(str)\n",
        "df['Mean Salary'] = df['Salary'].apply(lambda x: pd.Series(clean_salary(x)))\n",
        "\n",
        "def extract_seniority(title):\n",
        "    seniority_terms = ['Junior', 'Senior', 'Lead', 'Manager', 'Associate']\n",
        "    for term in seniority_terms:\n",
        "        if term in title:\n",
        "            return term\n",
        "    return 'Unknown'\n",
        "\n",
        "def extract_role(title):\n",
        "    role_terms = ['Engineer', 'Developer', 'Scientist', 'Analyst', 'Architect']\n",
        "    for term in role_terms:\n",
        "        if term in title:\n",
        "            return term\n",
        "    return 'Unknown'\n",
        "\n",
        "def extract_specialization(title):\n",
        "    # Customize this list based on your data\n",
        "    specialization_terms = ['Fullstack', 'Backend', 'Frontend', 'Data', 'C#', 'Java', 'Python']\n",
        "    for term in specialization_terms:\n",
        "        if term in title:\n",
        "            return term\n",
        "    return 'Unknown'\n",
        "\n",
        "# Apply these functions to the job titles\n",
        "df['Seniority'] = df['Job Title'].apply(extract_seniority)\n",
        "df['Role'] = df['Job Title'].apply(extract_role)\n",
        "df['Specialization'] = df['Job Title'].apply(extract_specialization)\n",
        "\n",
        "# Extract the City, State, and Remote data\n",
        "def clean_location(location):\n",
        "\n",
        "    def state_name_abbr_conversion(state_name):\n",
        "        state = us.states.lookup(state_name)\n",
        "        return state.abbr if state else None\n",
        "\n",
        "    if location == None:\n",
        "        return None, None, None\n",
        "    area = location.split(',')\n",
        "    if len(area) == 2:\n",
        "        city = area[0].strip()\n",
        "        state = area[1].strip()\n",
        "        remote = False\n",
        "    elif 'Remote' or 'United States' in location:\n",
        "        city, state = None, None\n",
        "        remote = True\n",
        "    else:\n",
        "        city, state = None, state_name_abbr_conversion(location)\n",
        "        remote = False\n",
        "    return city, state, remote\n",
        "\n",
        "df['Location'] = df['Location'].astype(str)\n",
        "df[['City', 'State', 'Remote']] = df['Location'].apply(lambda x: pd.Series(clean_location(x)))\n",
        "\n",
        "# Make a data frame with the Mean Salary, City, State, Company Score, Company, and Remote Data\n",
        "clean_df = df.drop(['Job Title', 'Location', 'Salary', 'Date'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2db0f102-106b-46cd-8cc1-b970c0d6e3a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "2db0f102-106b-46cd-8cc1-b970c0d6e3a3",
        "outputId": "67d8e736-3387-4ef5-f048-19755eaa40f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           Company  Company Score  Mean Salary Seniority  \\\n",
              "0                         ViewSoft            4.8      81000.0   Unknown   \n",
              "1                          Workiva            4.3      82500.0   Unknown   \n",
              "2       Garmin International, Inc.            3.9     106500.0   Unknown   \n",
              "3                         Snapchat            3.5     121000.0   Unknown   \n",
              "4    Vitesco Technologies Group AG            3.1      96500.0   Unknown   \n",
              "..                             ...            ...          ...       ...   \n",
              "865                            RXO            NaN          NaN   Unknown   \n",
              "866                        Infosys            NaN          NaN   Unknown   \n",
              "867                      Medtronic            NaN          NaN    Senior   \n",
              "868                            NaN            NaN          NaN    Junior   \n",
              "869                            NaN            NaN          NaN   Unknown   \n",
              "\n",
              "          Role Specialization                City State  Remote  \n",
              "0     Engineer        Unknown            Manassas    VA   False  \n",
              "1     Engineer        Unknown                None  None    True  \n",
              "2     Engineer             C#                Cary    NC   False  \n",
              "3     Engineer      Fullstack         Los Angeles    CA   False  \n",
              "4     Engineer        Unknown              Seguin    TX   False  \n",
              "..         ...            ...                 ...   ...     ...  \n",
              "865   Engineer        Unknown       San Francisco    CA   False  \n",
              "866   Engineer        Unknown  Annapolis Junction    MD   False  \n",
              "867   Engineer        Unknown          Southfield    MI   False  \n",
              "868  Developer         Python           Charlotte    NC   False  \n",
              "869   Engineer        Unknown              Boston    MA   False  \n",
              "\n",
              "[870 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8f73d3d-c38d-4329-bf72-d48706fc5bc0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Company Score</th>\n",
              "      <th>Mean Salary</th>\n",
              "      <th>Seniority</th>\n",
              "      <th>Role</th>\n",
              "      <th>Specialization</th>\n",
              "      <th>City</th>\n",
              "      <th>State</th>\n",
              "      <th>Remote</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ViewSoft</td>\n",
              "      <td>4.8</td>\n",
              "      <td>81000.0</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Manassas</td>\n",
              "      <td>VA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Workiva</td>\n",
              "      <td>4.3</td>\n",
              "      <td>82500.0</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Garmin International, Inc.</td>\n",
              "      <td>3.9</td>\n",
              "      <td>106500.0</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>C#</td>\n",
              "      <td>Cary</td>\n",
              "      <td>NC</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Snapchat</td>\n",
              "      <td>3.5</td>\n",
              "      <td>121000.0</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>Fullstack</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>CA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Vitesco Technologies Group AG</td>\n",
              "      <td>3.1</td>\n",
              "      <td>96500.0</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Seguin</td>\n",
              "      <td>TX</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865</th>\n",
              "      <td>RXO</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>San Francisco</td>\n",
              "      <td>CA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>866</th>\n",
              "      <td>Infosys</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Annapolis Junction</td>\n",
              "      <td>MD</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>867</th>\n",
              "      <td>Medtronic</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Senior</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Southfield</td>\n",
              "      <td>MI</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>868</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Junior</td>\n",
              "      <td>Developer</td>\n",
              "      <td>Python</td>\n",
              "      <td>Charlotte</td>\n",
              "      <td>NC</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>869</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Engineer</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Boston</td>\n",
              "      <td>MA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>870 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8f73d3d-c38d-4329-bf72-d48706fc5bc0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a8f73d3d-c38d-4329-bf72-d48706fc5bc0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a8f73d3d-c38d-4329-bf72-d48706fc5bc0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fa638927-4333-42c4-a89f-d1651b02612b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa638927-4333-42c4-a89f-d1651b02612b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fa638927-4333-42c4-a89f-d1651b02612b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c44be024-b7a0-491c-97d7-614fea564830\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('clean_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c44be024-b7a0-491c-97d7-614fea564830 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('clean_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "clean_df",
              "summary": "{\n  \"name\": \"clean_df\",\n  \"rows\": 870,\n  \"fields\": [\n    {\n      \"column\": \"Company\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 648,\n        \"samples\": [\n          \"PacBio\",\n          \"BAE Systems\",\n          \"Turn5, Inc.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Company Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5249518335684344,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          2.5,\n          4.4,\n          2.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mean Salary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 47604.31565505837,\n        \"min\": 6500.0,\n        \"max\": 490000.0,\n        \"num_unique_values\": 262,\n        \"samples\": [\n          375000.0,\n          233500.0,\n          155500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Seniority\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Unknown\",\n          \"Associate\",\n          \"Lead\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Role\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Developer\",\n          \"Analyst\",\n          \"Engineer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Specialization\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"C#\",\n          \"Frontend\",\n          \"Unknown\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"City\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 299,\n        \"samples\": [\n          \"Alameda\",\n          \"Plano\",\n          \"Laurel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"State\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 45,\n        \"samples\": [\n          \"NH\",\n          \"DE\",\n          \"DC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Remote\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "clean_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cc719948-aa30-4067-8983-1e1a2d0d3227",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cc719948-aa30-4067-8983-1e1a2d0d3227",
        "outputId": "ab56294d-4006-4192-d587-1c320204068f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "isnull:\n",
            "Company           0\n",
            "Company Score     0\n",
            "Mean Salary       0\n",
            "Seniority         0\n",
            "Role              0\n",
            "Specialization    0\n",
            "City              0\n",
            "State             0\n",
            "Remote            0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(764, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Remove the null rows from the data or fill in with default data\n",
        "clean_df['City'] = clean_df['City'].fillna(\"Unknown\")\n",
        "clean_df['State'] = clean_df['State'].fillna(\"Unknown\")\n",
        "clean_df['Company'] = clean_df['Company'].fillna(\"Unknown\")\n",
        "clean_df = clean_df.dropna(subset=['Mean Salary', 'Company Score'])\n",
        "print(f'isnull:\\n{clean_df.isnull().sum()}')\n",
        "clean_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical variables\n",
        "clean_df = pd.get_dummies(clean_df, columns=['Remote', 'City', 'Specialization', 'Role'], drop_first = True)\n",
        "label_encoder = LabelEncoder()\n",
        "clean_df['Seniority'] = label_encoder.fit_transform(clean_df['Seniority'])\n",
        "\n",
        "# Define the variables for the models\n",
        "X = clean_df.drop(columns=['State', 'Mean Salary', 'Company'])\n",
        "y = clean_df['Mean Salary']"
      ],
      "metadata": {
        "id": "0B3DCEDQ9nYE"
      },
      "id": "0B3DCEDQ9nYE",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cc6d9dc2-e6df-44e5-8af4-83407f408037",
      "metadata": {
        "id": "cc6d9dc2-e6df-44e5-8af4-83407f408037"
      },
      "source": [
        "# Model Building and Training\n",
        "\n",
        "For each model that I originally used to predict the SW engineering salaries, I will run the base models, and then transform the feature space using PCA and rerun the models using the reduced feature space while collecting the MAE values to determine the performance of the models. After this, I will create the MLP using tensorflow and analyze the output to determine the MAE."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86caad65-c0f3-4f7b-b930-b8842d480fb0",
      "metadata": {
        "id": "86caad65-c0f3-4f7b-b930-b8842d480fb0"
      },
      "source": [
        "## Basic Linear Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c6944d18-6970-4c2b-b5e6-90995f0be0d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "c6944d18-6970-4c2b-b5e6-90995f0be0d1",
        "outputId": "b1d1037a-07d9-4474-fb90-91c3ebb974cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Summary:\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:            Mean Salary   R-squared:                       0.372\n",
            "Model:                            OLS   Adj. R-squared:                 -0.033\n",
            "Method:                 Least Squares   F-statistic:                    0.9189\n",
            "Date:                Tue, 12 Nov 2024   Prob (F-statistic):              0.761\n",
            "Time:                        12:51:49   Log-Likelihood:                -7301.5\n",
            "No. Observations:                 611   AIC:                         1.508e+04\n",
            "Df Residuals:                     371   BIC:                         1.614e+04\n",
            "Df Model:                         239                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "=============================================================================================\n",
            "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------------------\n",
            "const                      1.697e+05    5.9e+04      2.877      0.004    5.37e+04    2.86e+05\n",
            "Company Score              3534.0431   4851.069      0.729      0.467   -6004.997    1.31e+04\n",
            "Seniority                 -5769.3391   2871.293     -2.009      0.045   -1.14e+04    -123.289\n",
            "Remote_True               -1.326e+04   2.55e+04     -0.520      0.604   -6.34e+04    3.69e+04\n",
            "City_Agoura Hills          -6.28e+04      7e+04     -0.897      0.371   -2.01e+05    7.49e+04\n",
            "City_Aguadilla             -2.98e+04      7e+04     -0.425      0.671   -1.68e+05    1.08e+05\n",
            "City_Aiken                -8.758e+04   7.23e+04     -1.211      0.227    -2.3e+05    5.47e+04\n",
            "City_Albuquerque          -6.198e+04   7.03e+04     -0.882      0.378      -2e+05    7.62e+04\n",
            "City_Alpharetta           -4.751e+04   5.49e+04     -0.865      0.387   -1.55e+05    6.05e+04\n",
            "City_Andover              -4.814e+04   6.13e+04     -0.785      0.433   -1.69e+05    7.24e+04\n",
            "City_Ann Arbor            -9762.0955   7.01e+04     -0.139      0.889   -1.48e+05    1.28e+05\n",
            "City_Annapolis Junction    -3.06e+04   5.22e+04     -0.587      0.558   -1.33e+05    7.19e+04\n",
            "City_Apopka               -2.751e-09   1.87e-09     -1.470      0.142   -6.43e-09     9.3e-10\n",
            "City_Arlington             -4.84e+04    5.8e+04     -0.835      0.404   -1.62e+05    6.56e+04\n",
            "City_Atlanta               -3.26e+04   5.54e+04     -0.588      0.557   -1.42e+05    7.64e+04\n",
            "City_Auburn               -6.468e+04   7.08e+04     -0.913      0.362   -2.04e+05    7.46e+04\n",
            "City_Auburn Hills         -3.761e+04    5.8e+04     -0.649      0.517   -1.52e+05    7.64e+04\n",
            "City_Aurora                2557.2657      7e+04      0.037      0.971   -1.35e+05     1.4e+05\n",
            "City_Austin               -1.778e+04   5.32e+04     -0.334      0.738   -1.22e+05    8.68e+04\n",
            "City_Avon                 -3.171e+04   6.12e+04     -0.518      0.605   -1.52e+05    8.87e+04\n",
            "City_Baltimore             2.292e+04   6.13e+04      0.374      0.708   -9.75e+04    1.43e+05\n",
            "City_Barre                 5.548e-10   6.77e-09      0.082      0.935   -1.27e-08    1.39e-08\n",
            "City_Beavercreek          -8.868e+04      7e+04     -1.266      0.206   -2.26e+05     4.9e+04\n",
            "City_Bedford               -6.55e+04   7.01e+04     -0.935      0.351   -2.03e+05    7.23e+04\n",
            "City_Bellevue              -2.85e+04   5.36e+04     -0.532      0.595   -1.34e+05    7.68e+04\n",
            "City_Belmont              -9589.3300      7e+04     -0.137      0.891   -1.47e+05    1.28e+05\n",
            "City_Beloit               -1.531e-09   1.44e-09     -1.062      0.289   -4.37e-09    1.31e-09\n",
            "City_Bentonville          -2.929e+04   6.13e+04     -0.478      0.633    -1.5e+05    9.13e+04\n",
            "City_Berkeley             -4.997e+04   7.01e+04     -0.713      0.476   -1.88e+05    8.78e+04\n",
            "City_Berthoud             -5.024e+04      7e+04     -0.717      0.474   -1.88e+05    8.75e+04\n",
            "City_Bethpage             -2.853e+04      7e+04     -0.407      0.684   -1.66e+05    1.09e+05\n",
            "City_Bloomfield Hills      1.291e-09   7.49e-10      1.724      0.086   -1.82e-10    2.76e-09\n",
            "City_Boca Raton           -3.788e+04      7e+04     -0.541      0.589   -1.76e+05    9.98e+04\n",
            "City_Boise                 2.332e+04      7e+04      0.333      0.739   -1.14e+05    1.61e+05\n",
            "City_Bolingbrook           1.435e+04   7.01e+04      0.205      0.838   -1.23e+05    1.52e+05\n",
            "City_Boston                2338.1846   5.24e+04      0.045      0.964   -1.01e+05    1.05e+05\n",
            "City_Boulder              -5.652e+04    5.8e+04     -0.974      0.331   -1.71e+05    5.76e+04\n",
            "City_Bridgewater            753.4516   6.18e+04      0.012      0.990   -1.21e+05    1.22e+05\n",
            "City_Brookfield           -1.531e-11   7.81e-11     -0.196      0.845   -1.69e-10    1.38e-10\n",
            "City_Brooklyn             -4.588e+04      7e+04     -0.655      0.513   -1.84e+05    9.18e+04\n",
            "City_Buffalo              -5.086e+04    7.2e+04     -0.707      0.480   -1.92e+05    9.06e+04\n",
            "City_Buffalo Grove        -3.109e+04      7e+04     -0.444      0.657   -1.69e+05    1.07e+05\n",
            "City_Burlingame            4.835e+04   7.01e+04      0.690      0.491   -8.95e+04    1.86e+05\n",
            "City_Burlington           -3605.9490   5.86e+04     -0.061      0.951   -1.19e+05    1.12e+05\n",
            "City_Burr Ridge            1.234e+05   7.09e+04      1.742      0.082   -1.59e+04    2.63e+05\n",
            "City_Burtonsville         -2.256e+04   7.01e+04     -0.322      0.748    -1.6e+05    1.15e+05\n",
            "City_Cambridge             1.034e+04   6.14e+04      0.168      0.866    -1.1e+05    1.31e+05\n",
            "City_Canoga Park           4.062e+04      7e+04      0.580      0.562   -9.71e+04    1.78e+05\n",
            "City_Canton                 2.52e+04      7e+04      0.360      0.719   -1.13e+05    1.63e+05\n",
            "City_Carlisle             -1.408e+04   6.13e+04     -0.230      0.818   -1.35e+05    1.06e+05\n",
            "City_Carlsbad              1.012e+04      7e+04      0.144      0.885   -1.28e+05    1.48e+05\n",
            "City_Carol Stream         -5.748e-10   3.69e-10     -1.557      0.120    -1.3e-09    1.51e-10\n",
            "City_Carrollton           -1.121e-09   6.89e-10     -1.628      0.104   -2.48e-09    2.33e-10\n",
            "City_Cary                 -4.318e+04   7.02e+04     -0.615      0.539   -1.81e+05    9.48e+04\n",
            "City_Cedar Rapids         -7589.3300      7e+04     -0.108      0.914   -1.45e+05     1.3e+05\n",
            "City_Chalfont             -2.837e+04   5.84e+04     -0.486      0.627   -1.43e+05    8.64e+04\n",
            "City_Chantilly            -1.971e+04   5.47e+04     -0.360      0.719   -1.27e+05    8.79e+04\n",
            "City_Charlotte            -7241.1374   5.68e+04     -0.128      0.899   -1.19e+05    1.04e+05\n",
            "City_Chatsworth            9.635e+04    6.8e+04      1.417      0.157   -3.74e+04     2.3e+05\n",
            "City_Cheshire              1.691e+04      7e+04      0.241      0.809   -1.21e+05    1.55e+05\n",
            "City_Chicago              -2.833e+04   5.29e+04     -0.535      0.593   -1.32e+05    7.58e+04\n",
            "City_Cincinnati            6.479e+04   7.01e+04      0.924      0.356    -7.3e+04    2.03e+05\n",
            "City_College Park         -7.758e+04   7.19e+04     -1.079      0.281   -2.19e+05    6.38e+04\n",
            "City_Colony                6.697e+04   7.08e+04      0.945      0.345   -7.23e+04    2.06e+05\n",
            "City_Columbia              1.359e+04   5.34e+04      0.255      0.799   -9.13e+04    1.19e+05\n",
            "City_Conyers               -4.83e+04      7e+04     -0.690      0.491   -1.86e+05    8.94e+04\n",
            "City_Crystal City         -7.427e-10   3.99e-10     -1.860      0.064   -1.53e-09    4.26e-11\n",
            "City_Culver City          -2.174e+04      7e+04     -0.310      0.756   -1.59e+05    1.16e+05\n",
            "City_Cupertino            -4.339e-10   2.97e-10     -1.463      0.144   -1.02e-09    1.49e-10\n",
            "City_Dahlgren             -3.392e+04   5.63e+04     -0.602      0.547   -1.45e+05    7.68e+04\n",
            "City_Dallas               -4.147e+04   5.41e+04     -0.767      0.443   -1.48e+05    6.48e+04\n",
            "City_Dayton                1.028e-10   1.38e-10      0.747      0.456   -1.68e-10    3.74e-10\n",
            "City_Dearborn              2.524e+04    5.8e+04      0.435      0.664   -8.88e+04    1.39e+05\n",
            "City_Deerfield            -4.018e+04   6.13e+04     -0.656      0.512   -1.61e+05    8.03e+04\n",
            "City_Denver               -2.052e+04   5.53e+04     -0.371      0.711   -1.29e+05    8.82e+04\n",
            "City_Des Moines            -7.83e+04      7e+04     -1.118      0.264   -2.16e+05    5.94e+04\n",
            "City_Dublin               -1.661e-10   8.77e-11     -1.893      0.059   -3.39e-10     6.4e-12\n",
            "City_Duluth               -2.209e+04   7.09e+04     -0.312      0.755   -1.61e+05    1.17e+05\n",
            "City_Eden Prairie         -5.344e+04   7.19e+04     -0.743      0.458   -1.95e+05    8.79e+04\n",
            "City_Edison                4.362e+04      7e+04      0.623      0.534   -9.41e+04    1.81e+05\n",
            "City_Edwards AFB           1.226e-10   9.18e-11      1.336      0.182   -5.78e-11    3.03e-10\n",
            "City_Egg Harbor Township  -6.065e+04   7.01e+04     -0.866      0.387   -1.98e+05    7.71e+04\n",
            "City_Eglin AFB            -3.565e+04   7.09e+04     -0.503      0.615   -1.75e+05    1.04e+05\n",
            "City_El Segundo            2.476e+04      7e+04      0.354      0.724   -1.13e+05    1.62e+05\n",
            "City_Elkridge              4.924e-11   7.23e-11      0.681      0.496   -9.29e-11    1.91e-10\n",
            "City_Englewood Cliffs      9643.6485   7.01e+04      0.138      0.891   -1.28e+05    1.47e+05\n",
            "City_Eugene                2.576e+04      7e+04      0.368      0.713   -1.12e+05    1.63e+05\n",
            "City_Everett              -2.244e+04      7e+04     -0.320      0.749    -1.6e+05    1.15e+05\n",
            "City_Exton                 4117.4786      7e+04      0.059      0.953   -1.34e+05    1.42e+05\n",
            "City_Fairborn             -4.577e+04   7.02e+04     -0.652      0.515   -1.84e+05    9.23e+04\n",
            "City_Fairfax              -1.174e-11   5.68e-11     -0.207      0.836   -1.23e-10       1e-10\n",
            "City_Fall River            -1.26e+05      7e+04     -1.800      0.073   -2.64e+05    1.17e+04\n",
            "City_Farmington Hills      1.376e-11   5.56e-11      0.247      0.805   -9.56e-11    1.23e-10\n",
            "City_Fort Belvoir         -2.488e+04      7e+04     -0.355      0.723   -1.63e+05    1.13e+05\n",
            "City_Fort Collins         -6293.9211   5.81e+04     -0.108      0.914    -1.2e+05    1.08e+05\n",
            "City_Fort George G Meade  -1.179e-11   5.61e-11     -0.210      0.834   -1.22e-10    9.86e-11\n",
            "City_Fort Meade           -6704.1959   5.54e+04     -0.121      0.904   -1.16e+05    1.02e+05\n",
            "City_Fort Wayne            -1.28e+04      7e+04     -0.183      0.855   -1.51e+05    1.25e+05\n",
            "City_Foster City          -4.992e+04    5.8e+04     -0.861      0.390   -1.64e+05    6.41e+04\n",
            "City_Foxborough            8.197e+04      7e+04      1.171      0.243   -5.57e+04     2.2e+05\n",
            "City_Framingham           -5.048e+04   7.03e+04     -0.718      0.473   -1.89e+05    8.77e+04\n",
            "City_Franklin             -8735.9257      7e+04     -0.125      0.901   -1.46e+05    1.29e+05\n",
            "City_Frederick             4202.6406   7.09e+04      0.059      0.953   -1.35e+05    1.44e+05\n",
            "City_Fremont               -1.21e+04   5.75e+04     -0.210      0.834   -1.25e+05    1.01e+05\n",
            "City_Frisco               -5.197e+04   7.01e+04     -0.742      0.459    -1.9e+05    8.58e+04\n",
            "City_Georgetown            2358.3304   7.03e+04      0.034      0.973   -1.36e+05    1.41e+05\n",
            "City_Germantown           -4458.1988   6.22e+04     -0.072      0.943   -1.27e+05    1.18e+05\n",
            "City_Glen Cove            -4.244e+04      7e+04     -0.606      0.545    -1.8e+05    9.53e+04\n",
            "City_Greensboro            3.791e+04      7e+04      0.541      0.589   -9.98e+04    1.76e+05\n",
            "City_Greenwood Village     6.003e+04   7.01e+04      0.857      0.392   -7.77e+04    1.98e+05\n",
            "City_Hanover              -3.644e+04      7e+04     -0.520      0.603   -1.74e+05    1.01e+05\n",
            "City_Hartford              3.104e+04   6.12e+04      0.507      0.612   -8.93e+04    1.51e+05\n",
            "City_Havre de Grace        -1.48e+04      7e+04     -0.211      0.833   -1.53e+05    1.23e+05\n",
            "City_Hercules             -5.065e+04   7.09e+04     -0.714      0.475    -1.9e+05    8.88e+04\n",
            "City_Herndon              -3.564e+04   5.63e+04     -0.633      0.527   -1.46e+05    7.51e+04\n",
            "City_Highlands Ranch       2.435e+04   7.01e+04      0.348      0.728   -1.13e+05    1.62e+05\n",
            "City_Hill AFB              8850.4571   7.01e+04      0.126      0.900   -1.29e+05    1.47e+05\n",
            "City_Hillsboro             1252.7266    5.8e+04      0.022      0.983   -1.13e+05    1.15e+05\n",
            "City_Honolulu               1.22e+04      7e+04      0.174      0.862   -1.26e+05     1.5e+05\n",
            "City_Hopkins              -3.809e+04   7.01e+04     -0.543      0.587   -1.76e+05    9.98e+04\n",
            "City_Houston               7.451e+04   5.63e+04      1.323      0.187   -3.62e+04    1.85e+05\n",
            "City_Huntsville           -1.782e+04   5.81e+04     -0.307      0.759   -1.32e+05    9.65e+04\n",
            "City_Idaho Falls           6824.2873      7e+04      0.097      0.922   -1.31e+05    1.45e+05\n",
            "City_Indian Head          -4.199e-11   3.72e-11     -1.130      0.259   -1.15e-10    3.11e-11\n",
            "City_Indianola            -1.144e+04   6.12e+04     -0.187      0.852   -1.32e+05    1.09e+05\n",
            "City_Irvine                1.331e+04   6.17e+04      0.216      0.829   -1.08e+05    1.35e+05\n",
            "City_Irving               -1.707e+04   5.44e+04     -0.314      0.754   -1.24e+05    8.98e+04\n",
            "City_Jackson              -3.827e+04   7.02e+04     -0.545      0.586   -1.76e+05    9.98e+04\n",
            "City_Jacksonville         -2.129e+04   5.63e+04     -0.378      0.705   -1.32e+05    8.94e+04\n",
            "City_Jamesburg            -2.388e-11   1.15e-10     -0.208      0.836    -2.5e-10    2.02e-10\n",
            "City_Jersey City           1.925e+04   6.13e+04      0.314      0.754   -1.01e+05     1.4e+05\n",
            "City_Johns Creek            7.34e+04   7.06e+04      1.040      0.299   -6.54e+04    2.12e+05\n",
            "City_Johnston             -7870.5952   6.12e+04     -0.129      0.898   -1.28e+05    1.13e+05\n",
            "City_Kennedy Sp Ct        -5.626e+04   7.01e+04     -0.803      0.423   -1.94e+05    8.16e+04\n",
            "City_Kennedy Space Center  3.556e+04      7e+04      0.508      0.612   -1.02e+05    1.73e+05\n",
            "City_King of Prussia      -2.447e-11   7.68e-11     -0.319      0.750   -1.76e-10    1.27e-10\n",
            "City_Lake Forest          -3.268e+04      7e+04     -0.467      0.641    -1.7e+05    1.05e+05\n",
            "City_Lake Mary            -3.853e+04      7e+04     -0.550      0.583   -1.76e+05    9.92e+04\n",
            "City_Lakeland              -5.35e+04   7.01e+04     -0.764      0.446   -1.91e+05    8.43e+04\n",
            "City_Lansing              -2856.3515   7.01e+04     -0.041      0.968   -1.41e+05    1.35e+05\n",
            "City_Largo                -2.459e+04      7e+04     -0.351      0.726   -1.62e+05    1.13e+05\n",
            "City_Las Cruces            -4.53e+04      7e+04     -0.647      0.518   -1.83e+05    9.24e+04\n",
            "City_Laurel               -3.844e+04   6.12e+04     -0.628      0.530   -1.59e+05     8.2e+04\n",
            "City_Lawrenceville        -2.112e-11   1.09e-10     -0.193      0.847   -2.36e-10    1.94e-10\n",
            "City_Lehi                 -9031.0854   5.63e+04     -0.160      0.873    -1.2e+05    1.02e+05\n",
            "City_Lenexa                5.315e+04   6.16e+04      0.862      0.389   -6.81e+04    1.74e+05\n",
            "City_Lexington             4.888e+04   6.13e+04      0.798      0.426   -7.16e+04    1.69e+05\n",
            "City_Lexington Park       -5.552e+04    7.1e+04     -0.782      0.434   -1.95e+05     8.4e+04\n",
            "City_Lincoln              -1.177e+04   7.02e+04     -0.168      0.867    -1.5e+05    1.26e+05\n",
            "City_Linthicum            -6.588e+04   7.15e+04     -0.922      0.357   -2.06e+05    7.47e+04\n",
            "City_Longmont              9.167e-12   1.37e-10      0.067      0.947    -2.6e-10    2.78e-10\n",
            "City_Lorton               -2.848e+04   7.03e+04     -0.405      0.686   -1.67e+05     1.1e+05\n",
            "City_Los Altos            -2.525e+04   7.03e+04     -0.359      0.720   -1.64e+05    1.13e+05\n",
            "City_Los Angeles          -2.364e+04   5.48e+04     -0.432      0.666   -1.31e+05    8.41e+04\n",
            "City_Louisville           -4.168e+04      7e+04     -0.595      0.552   -1.79e+05     9.6e+04\n",
            "City_Madison               3.439e-12   8.06e-11      0.043      0.966   -1.55e-10    1.62e-10\n",
            "City_Malta                 -6.48e+04      7e+04     -0.925      0.356   -2.03e+05    7.29e+04\n",
            "City_Manassas             -6.427e+04   7.02e+04     -0.915      0.361   -2.02e+05    7.38e+04\n",
            "City_Maplewood             1.897e+04      7e+04      0.271      0.787   -1.19e+05    1.57e+05\n",
            "City_Mason                 5985.7051   5.81e+04      0.103      0.918   -1.08e+05     1.2e+05\n",
            "City_McKinney              7.076e+04      7e+04      1.011      0.313   -6.69e+04    2.08e+05\n",
            "City_McLean                 -1.7e+04    5.8e+04     -0.293      0.770   -1.31e+05     9.7e+04\n",
            "City_Melbourne             -606.9619   6.15e+04     -0.010      0.992   -1.22e+05     1.2e+05\n",
            "City_Melville              4.192e-11    6.5e-11      0.644      0.520    -8.6e-11     1.7e-10\n",
            "City_Menlo Park             523.2226   7.03e+04      0.007      0.994   -1.38e+05    1.39e+05\n",
            "City_Meridian               -4.7e-11    5.5e-11     -0.855      0.393   -1.55e-10    6.11e-11\n",
            "City_Miami                -9052.3928   6.14e+04     -0.148      0.883    -1.3e+05    1.12e+05\n",
            "City_Milwaukee            -4.552e+04   6.12e+04     -0.743      0.458   -1.66e+05    7.49e+04\n",
            "City_Minneapolis           1.266e+04    5.8e+04      0.218      0.827   -1.01e+05    1.27e+05\n",
            "City_Monument             -6382.5214      7e+04     -0.091      0.927   -1.44e+05    1.31e+05\n",
            "City_Moorpark             -4.319e+04   7.05e+04     -0.612      0.541   -1.82e+05    9.55e+04\n",
            "City_Morgantown           -9209.7559   7.01e+04     -0.131      0.896   -1.47e+05    1.29e+05\n",
            "City_Morris Plains        -5.403e+04    7.4e+04     -0.730      0.466      -2e+05    9.15e+04\n",
            "City_Morrisville          -4.508e+04   7.15e+04     -0.631      0.529   -1.86e+05    9.54e+04\n",
            "City_Mount Laurel          -3.36e+04   6.26e+04     -0.537      0.591   -1.57e+05    8.94e+04\n",
            "City_Mount Vernon         -1.616e-11   3.37e-11     -0.479      0.632   -8.25e-11    5.02e-11\n",
            "City_Mountain View        -1.068e+04      7e+04     -0.152      0.879   -1.48e+05    1.27e+05\n",
            "City_Naperville           -2.321e+04   7.01e+04     -0.331      0.741   -1.61e+05    1.15e+05\n",
            "City_Nashua               -4.421e+04   7.01e+04     -0.631      0.529   -1.82e+05    9.37e+04\n",
            "City_Nashville            -5.303e+04   7.08e+04     -0.749      0.455   -1.92e+05    8.63e+04\n",
            "City_New York             -2.677e+04    5.3e+04     -0.505      0.614   -1.31e+05    7.74e+04\n",
            "City_Newark               -6.315e+04   7.01e+04     -0.901      0.368   -2.01e+05    7.46e+04\n",
            "City_Newtown Square        1.411e+05   7.01e+04      2.014      0.045    3315.251    2.79e+05\n",
            "City_Norcross             -5.098e+04   7.03e+04     -0.725      0.469   -1.89e+05    8.72e+04\n",
            "City_North Reading         4.947e+04   6.13e+04      0.807      0.420   -7.11e+04     1.7e+05\n",
            "City_Northborough         -5.275e+04   7.12e+04     -0.741      0.459   -1.93e+05    8.73e+04\n",
            "City_O Fallon             -4.003e+04      7e+04     -0.572      0.568   -1.78e+05    9.77e+04\n",
            "City_Oakland              -2.114e+04   6.26e+04     -0.338      0.736   -1.44e+05    1.02e+05\n",
            "City_Okemos               -5.175e-10   3.49e-10     -1.485      0.139    -1.2e-09    1.68e-10\n",
            "City_Oklahoma City         2.818e+04    5.8e+04      0.486      0.627   -8.59e+04    1.42e+05\n",
            "City_Olathe               -2.836e+04   6.17e+04     -0.459      0.646    -1.5e+05     9.3e+04\n",
            "City_Onalaska             -1.318e-11    2.5e-11     -0.527      0.598   -6.23e-11     3.6e-11\n",
            "City_Orlando               1643.6485   7.01e+04      0.023      0.981   -1.36e+05    1.39e+05\n",
            "City_Owings Mills         -1.644e+04      7e+04     -0.235      0.815   -1.54e+05    1.21e+05\n",
            "City_Oxford                4.851e-12   2.89e-11      0.168      0.867   -5.21e-11    6.18e-11\n",
            "City_Oyster Bay            2.065e+04    6.8e+04      0.304      0.762   -1.13e+05    1.54e+05\n",
            "City_Palo Alto            -1.056e+04   6.17e+04     -0.171      0.864   -1.32e+05    1.11e+05\n",
            "City_Patrick AFB          -2.186e+04   7.01e+04     -0.312      0.755    -1.6e+05    1.16e+05\n",
            "City_Patuxent River        5233.9679   6.12e+04      0.085      0.932   -1.15e+05    1.26e+05\n",
            "City_Peachtree City       -4.188e+04      7e+04     -0.598      0.550    -1.8e+05    9.58e+04\n",
            "City_Peoria               -3.653e+04      7e+04     -0.522      0.602   -1.74e+05    1.01e+05\n",
            "City_Phoenix               -2.84e+04   5.38e+04     -0.528      0.598   -1.34e+05    7.74e+04\n",
            "City_Pittsburgh           -5131.1552   5.53e+04     -0.093      0.926   -1.14e+05    1.04e+05\n",
            "City_Plainsboro           -2.565e+04   5.89e+04     -0.435      0.663   -1.41e+05    9.02e+04\n",
            "City_Plano                -2.014e+04   7.19e+04     -0.280      0.780   -1.61e+05    1.21e+05\n",
            "City_Plantation           -5.017e+04   7.18e+04     -0.699      0.485   -1.91e+05    9.11e+04\n",
            "City_Point Mugu NAWC       1.291e-11   2.51e-11      0.515      0.607   -3.64e-11    6.22e-11\n",
            "City_Pompano Beach        -3.222e+04   6.12e+04     -0.526      0.599   -1.53e+05    8.82e+04\n",
            "City_Portsmouth            -1.29e-11   2.23e-11     -0.579      0.563   -5.67e-11    3.09e-11\n",
            "City_Pullman              -3.782e+04   7.45e+04     -0.508      0.612   -1.84e+05    1.09e+05\n",
            "City_Quantico             -5.053e+04   6.14e+04     -0.823      0.411   -1.71e+05    7.02e+04\n",
            "City_Quincy               -1840.6049   7.13e+04     -0.026      0.979   -1.42e+05    1.38e+05\n",
            "City_Raleigh               5.812e+04      7e+04      0.830      0.407   -7.96e+04    1.96e+05\n",
            "City_Redmond               3819.1918   5.46e+04      0.070      0.944   -1.04e+05    1.11e+05\n",
            "City_Redwood City           2.62e+04   6.14e+04      0.426      0.670   -9.46e+04    1.47e+05\n",
            "City_Renton               -4.236e+04   7.01e+04     -0.604      0.546    -1.8e+05    9.55e+04\n",
            "City_Richardson            2.071e-11   2.76e-11      0.750      0.454   -3.36e-11     7.5e-11\n",
            "City_Richmond              9807.3988   6.17e+04      0.159      0.874   -1.12e+05    1.31e+05\n",
            "City_Rockville            -2.564e+04   7.03e+04     -0.365      0.715   -1.64e+05    1.13e+05\n",
            "City_Saint Paul            5.738e+04   6.12e+04      0.937      0.349    -6.3e+04    1.78e+05\n",
            "City_Salem                -4.188e+04      7e+04     -0.598      0.550    -1.8e+05    9.58e+04\n",
            "City_San Antonio          -6.691e+04    7.2e+04     -0.930      0.353   -2.08e+05    7.46e+04\n",
            "City_San Bruno            -2.002e-11   2.26e-11     -0.887      0.376   -6.44e-11    2.44e-11\n",
            "City_San Diego             2.197e+04    5.8e+04      0.379      0.705   -9.21e+04    1.36e+05\n",
            "City_San Francisco        -8231.9406   5.23e+04     -0.157      0.875   -1.11e+05    9.46e+04\n",
            "City_San Jose             -2.534e+04   5.22e+04     -0.485      0.628   -1.28e+05    7.74e+04\n",
            "City_San Juan               1.67e+04      7e+04      0.238      0.812   -1.21e+05    1.54e+05\n",
            "City_San Mateo            -2.265e+04   7.01e+04     -0.323      0.747    -1.6e+05    1.15e+05\n",
            "City_Santa Barbara         -505.2648   7.01e+04     -0.007      0.994   -1.38e+05    1.37e+05\n",
            "City_Santa Clara          -1.989e+04   5.44e+04     -0.366      0.715   -1.27e+05     8.7e+04\n",
            "City_Santa Monica          2.047e+04   6.13e+04      0.334      0.739      -1e+05    1.41e+05\n",
            "City_Sayreville             824.2873      7e+04      0.012      0.991   -1.37e+05    1.39e+05\n",
            "City_Scott Air Force Base   -4.1e+04   7.09e+04     -0.578      0.563    -1.8e+05    9.84e+04\n",
            "City_Scottsdale           -4.291e+04   6.27e+04     -0.684      0.494   -1.66e+05    8.04e+04\n",
            "City_Seattle              -5153.8282   5.18e+04     -0.100      0.921   -1.07e+05    9.66e+04\n",
            "City_Secaucus              4.585e+04   7.01e+04      0.654      0.513   -9.19e+04    1.84e+05\n",
            "City_Seguin               -4.276e+04   7.01e+04     -0.610      0.542   -1.81e+05    9.51e+04\n",
            "City_Sherman                7.04e-10    5.6e-10      1.257      0.210   -3.97e-10    1.81e-09\n",
            "City_Shippensburg         -2.477e+04    6.8e+04     -0.364      0.716   -1.59e+05    1.09e+05\n",
            "City_Solon                 1.926e+04      7e+04      0.275      0.783   -1.18e+05    1.57e+05\n",
            "City_Somerset              2.806e+04   5.95e+04      0.472      0.637   -8.89e+04    1.45e+05\n",
            "City_Southern Pines       -5.236e+04   7.01e+04     -0.747      0.456    -1.9e+05    8.55e+04\n",
            "City_Spartanburg            -3.1e+04   7.01e+04     -0.442      0.658   -1.69e+05    1.07e+05\n",
            "City_Spring                -3.64e-10   4.45e-10     -0.818      0.414   -1.24e-09    5.11e-10\n",
            "City_Springfield          -7.465e+04   7.01e+04     -1.066      0.287   -2.12e+05    6.31e+04\n",
            "City_Stennis Space Center  -6.09e+04    5.8e+04     -1.050      0.294   -1.75e+05    5.31e+04\n",
            "City_Sterling Heights      3.406e+04      7e+04      0.486      0.627   -1.04e+05    1.72e+05\n",
            "City_Suffolk               -4.53e+04      7e+04     -0.647      0.518   -1.83e+05    9.24e+04\n",
            "City_Sunrise              -2.766e+04   6.33e+04     -0.437      0.662   -1.52e+05    9.68e+04\n",
            "City_Suwanee              -9.748e-12   1.88e-11     -0.520      0.604   -4.66e-11    2.71e-11\n",
            "City_Sylmar                2.832e+04      7e+04      0.404      0.686   -1.09e+05    1.66e+05\n",
            "City_Syracuse              -7.91e-12   1.64e-11     -0.483      0.629   -4.01e-11    2.43e-11\n",
            "City_Tampa                -1.815e+04   6.13e+04     -0.296      0.767   -1.39e+05    1.02e+05\n",
            "City_Tempe                -2.318e+04      7e+04     -0.331      0.741   -1.61e+05    1.15e+05\n",
            "City_Troy                 -4.594e+04      7e+04     -0.656      0.512   -1.84e+05    9.18e+04\n",
            "City_Tysons Corner        -3.887e-12   2.19e-11     -0.177      0.859    -4.7e-11    3.92e-11\n",
            "City_Unknown              -1.326e+04   2.55e+04     -0.520      0.604   -6.34e+04    3.69e+04\n",
            "City_Vienna               -3.178e+04   6.15e+04     -0.517      0.605   -1.53e+05    8.91e+04\n",
            "City_Waltham               1.568e-11   1.97e-11      0.798      0.425    -2.3e-11    5.43e-11\n",
            "City_Warren                2497.0528   7.01e+04      0.036      0.972   -1.35e+05     1.4e+05\n",
            "City_Warrenton             -9.28e+04      7e+04     -1.325      0.186   -2.31e+05    4.49e+04\n",
            "City_Washington           -2697.6995   5.34e+04     -0.051      0.960   -1.08e+05    1.02e+05\n",
            "City_Waterford            -6.981e+04   7.09e+04     -0.984      0.326   -2.09e+05    6.97e+04\n",
            "City_Wauwatosa            -1.592e+05   7.15e+04     -2.227      0.027      -3e+05   -1.86e+04\n",
            "City_West Bend            -6.203e+04   6.17e+04     -1.005      0.315   -1.83e+05    5.93e+04\n",
            "City_Westlake              2.204e-10   5.79e-10      0.381      0.703   -9.18e-10    1.36e-09\n",
            "City_Westlake Village      6.208e+04    7.1e+04      0.874      0.383   -7.76e+04    2.02e+05\n",
            "City_White Plains         -7.821e-12    1.6e-11     -0.488      0.626   -3.94e-11    2.37e-11\n",
            "City_Whitehouse Station    -4.22e+04   7.18e+04     -0.587      0.557   -1.83e+05    9.91e+04\n",
            "City_Wilmington           -5.131e+04   6.14e+04     -0.836      0.403   -1.72e+05    6.93e+04\n",
            "City_Wilton Woods         -2.741e+04   7.01e+04     -0.391      0.696   -1.65e+05     1.1e+05\n",
            "City_Woonsocket           -6.617e+04   6.33e+04     -1.046      0.296   -1.91e+05    5.83e+04\n",
            "Specialization_C#          1.782e+04   2.51e+04      0.711      0.477   -3.14e+04    6.71e+04\n",
            "Specialization_Data       -2.719e+04   2.24e+04     -1.216      0.225   -7.12e+04    1.68e+04\n",
            "Specialization_Frontend   -2.751e+04   3.02e+04     -0.910      0.363   -8.69e+04    3.19e+04\n",
            "Specialization_Fullstack  -1.632e+04   3.26e+04     -0.501      0.616   -8.04e+04    4.77e+04\n",
            "Specialization_Java        1.434e+04   2.18e+04      0.658      0.511   -2.85e+04    5.72e+04\n",
            "Specialization_Python     -6272.1461   2.58e+04     -0.243      0.808    -5.7e+04    4.45e+04\n",
            "Specialization_Unknown    -5533.7770   1.56e+04     -0.354      0.724   -3.63e+04    2.52e+04\n",
            "Role_Engineer             -7001.2208   1.16e+04     -0.603      0.547   -2.98e+04    1.58e+04\n",
            "Role_Unknown              -1.588e+04   1.99e+04     -0.799      0.425    -5.5e+04    2.32e+04\n",
            "==============================================================================\n",
            "Omnibus:                      327.581   Durbin-Watson:                   1.903\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5633.261\n",
            "Skew:                           1.971   Prob(JB):                         0.00\n",
            "Kurtosis:                      17.343   Cond. No.                     1.12e+19\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 1.97e-34. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n",
            "\n",
            "Test Mean Absolute Error is: 40339.443123367746\n",
            "Train Mean Absolute Error is: 23472.453825487686\n",
            "\n",
            "Model R^2 is: 0.3718392896287275\n"
          ]
        }
      ],
      "source": [
        "# Ensure compatibility with statsmodels\n",
        "X = X.astype(float)\n",
        "y = y.astype(int)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "# Add constants to the feature data\n",
        "X_train = sm.add_constant(X_train)\n",
        "X_test = sm.add_constant(X_test)\n",
        "\n",
        "linear_model = sm.OLS(y_train, X_train).fit()\n",
        "print(f'Model Summary:\\n{linear_model.summary()}')\n",
        "\n",
        "y_pred_te = linear_model.predict(X_test)\n",
        "mae_te_lr = mean_absolute_error(y_pred_te, y_test)\n",
        "print(f'\\nTest Mean Absolute Error is: {mae_te_lr}')\n",
        "\n",
        "y_pred_tr = linear_model.predict(X_train)\n",
        "mae_tr_lr = mean_absolute_error(y_pred_tr, y_train)\n",
        "print(f'Train Mean Absolute Error is: {mae_tr_lr}\\n')\n",
        "\n",
        "r2_lr = linear_model.rsquared\n",
        "print(f'Model R^2 is: {r2_lr}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f70bb531-efe8-400d-8079-e7a827d8dc48",
      "metadata": {
        "id": "f70bb531-efe8-400d-8079-e7a827d8dc48"
      },
      "source": [
        "## Forward Selection Method\n",
        "Here I will use forward selection to attempt to improve the R^2 and MAE value from the model that included all the features. I will compare this feature reduction technique with the PCA feature reduction technique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "30df7455-6590-4fbe-b1e9-744296b3dabe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "30df7455-6590-4fbe-b1e9-744296b3dabe",
        "outputId": "535981e3-a6fe-4c4b-bef4-d58f961182b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features: ['const', 'Specialization_Frontend', 'City_Boston', 'City_Seattle', 'City_Melbourne', 'Seniority', 'City_Deerfield', 'City_Alpharetta', 'City_Pittsburgh', 'City_Newtown Square', 'City_Atlanta', 'City_Lenexa', 'City_Moorpark', 'City_Palo Alto', 'City_Cary', 'Specialization_C#', 'City_Saint Paul', 'City_Burr Ridge', 'City_Lincoln', 'City_North Reading', 'Specialization_Java', 'City_Redmond', 'City_Oklahoma City', 'City_Lexington', 'City_Annapolis Junction', 'City_San Diego', 'City_Chatsworth', 'City_Mountain View', 'City_Foxborough', 'City_Redwood City', 'City_Colony', 'City_Westlake Village', 'City_McKinney', 'City_Baltimore', 'City_Mason', 'City_Somerset', 'City_Greenwood Village', 'City_Raleigh', 'City_Santa Monica', 'City_Irvine', 'Specialization_Unknown', 'City_Richmond', 'City_Hillsboro', 'City_Cambridge', 'City_Secaucus', 'City_Cincinnati', 'City_Edison', 'City_Canoga Park', 'City_Greensboro', 'City_Chicago', 'City_Kennedy Space Center', 'City_Bellevue', 'City_Bridgewater', 'City_Sterling Heights', 'City_Santa Clara', 'City_Patuxent River', 'City_Woonsocket', 'Company Score', 'City_Sylmar', 'City_Dallas', 'City_Eugene', 'City_El Segundo', 'City_Maplewood', 'City_Germantown', 'City_Highlands Ranch', 'City_Solon', 'City_Burlingame', 'City_Cheshire', 'City_San Juan', 'City_Linthicum', 'City_Oyster Bay', 'Role_Unknown', 'City_Washington', 'City_Irving', 'City_Georgetown', 'City_New York', 'City_Carlsbad', 'City_Idaho Falls', 'City_Honolulu', 'City_Frederick', 'City_Exton', 'City_Hill AFB', 'City_Sayreville', 'City_Lexington Park', 'City_Whitehouse Station', 'City_Englewood Cliffs', 'City_San Jose', 'City_Aurora', 'City_Indianola', 'City_Johnston', 'City_McLean', 'City_Morrisville', 'City_Oakland', 'City_Warren', 'City_Ann Arbor', 'City_Monument', 'City_Franklin', 'City_Cedar Rapids', 'City_Carlisle', 'City_Orlando', 'City_Belmont', 'City_Lansing', 'City_Pullman', 'City_Tampa', 'City_Bolingbrook', 'City_Northborough', 'City_Fort Wayne', 'City_Duluth', 'City_Havre de Grace', 'City_Owings Mills', 'City_Eden Prairie', 'City_Chantilly', 'City_Sunrise', 'City_Phoenix', 'City_Culver City', 'City_Tempe', 'City_Everett', 'City_Lorton', 'City_Largo', 'City_Fort Belvoir']\n",
            "best mae: 31435.3201\n",
            "best r2: 0.8662\n"
          ]
        }
      ],
      "source": [
        "# Convert to DataFrame for feature selection\n",
        "# Initialize an empty model with only the intercept\n",
        "initial_features = []\n",
        "remaining_features = X_train.columns.tolist()\n",
        "best_mae_lrfs = np.inf  # Initialize with a large value\n",
        "best_r2_lrfs = -np.inf\n",
        "\n",
        "# Forward selection process\n",
        "while remaining_features:\n",
        "    mae_list = []\n",
        "    r2_list = []\n",
        "    for feature in remaining_features:\n",
        "        # Try adding each feature one by one\n",
        "        current_features = initial_features + [feature]\n",
        "        X_train_subset = X_train[current_features]\n",
        "\n",
        "        # Fit the model with the current set of features\n",
        "        model = sm.OLS(y_train, X_train_subset).fit()\n",
        "        y_pred = model.predict(X_test[current_features])\n",
        "\n",
        "        # Compute MAE for the test set\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        mae_list.append((feature, mae))\n",
        "        r2_list.append(model.rsquared)\n",
        "\n",
        "    # Find the feature that provides the lowest MAE\n",
        "    best_feature, best_feature_mae = min(mae_list, key=lambda x: x[1])\n",
        "    best_feature_r2 = max(r2_list)\n",
        "\n",
        "    if best_feature_r2 > best_r2_lrfs:\n",
        "        best_r2_lrfs = best_feature_r2\n",
        "\n",
        "    if best_feature_mae < best_mae_lrfs:\n",
        "        # Add this feature to the model\n",
        "        initial_features.append(best_feature)\n",
        "        remaining_features.remove(best_feature)\n",
        "        best_mae_lrfs = best_feature_mae\n",
        "    else:\n",
        "        # Stop if adding more features does not improve the model\n",
        "        break\n",
        "\n",
        "print(f\"Selected features: {initial_features}\")\n",
        "print(f'best mae: {best_mae_lrfs:.4f}')\n",
        "print(f'best r2: {best_r2_lrfs:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85b286ec-650e-41d6-8045-ce8f03aa983c",
      "metadata": {
        "id": "85b286ec-650e-41d6-8045-ce8f03aa983c"
      },
      "source": [
        "## PCA Model\n",
        "Here I create the unsupervised PCA model and store the principal components into a vector that will be used to find the best parameters for each supervised model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ae40bf74-1b29-4aac-9699-3589780a3b03",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "ae40bf74-1b29-4aac-9699-3589780a3b03",
        "outputId": "d6d9f96a-9fd6-43b1-fbfb-7e291fd4f6be"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Use PCA to reduce the feature space to improve the models\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n",
        "# Use a loop to test how many Prnicipal components to keep with the model\n",
        "principal_components_tr = []\n",
        "principal_components_te = []\n",
        "for num_comp in range(1, 154):\n",
        "    pca = PCA(n_components=num_comp)\n",
        "    principal_components_tr.append(pca.fit_transform(X_train))\n",
        "    principal_components_te.append(pca.transform(X_test))\n",
        "\n",
        "# Plot the cumulative explained variance\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, 154), np.cumsum(pca.explained_variance_ratio_), marker='o', linestyle='-', color='b')\n",
        "plt.title('Cumulative Explained Variance by Number of Principal Components')\n",
        "plt.xlabel('Number of Principal Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c310a24-99aa-4681-806f-09bd52086bdb",
      "metadata": {
        "id": "2c310a24-99aa-4681-806f-09bd52086bdb"
      },
      "source": [
        "## Explained Var Ratio\n",
        "\n",
        "The cumulative explained variance can be seen above. While it looks like at around 90 components that 90% of the variability is explained in the data, which is a good benchmark to use for the number of components to include in the models, I will nonetheless loop through all of the components, building each model and seeing which models produce the best results, effectively tailoring the number of components to each model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1e948c0-c3dc-441d-9412-460b59f60495",
      "metadata": {
        "id": "f1e948c0-c3dc-441d-9412-460b59f60495"
      },
      "source": [
        "## Using PCA on the Linear Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "80d82eae-a43e-452a-ac9d-197a3079f2ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "80d82eae-a43e-452a-ac9d-197a3079f2ef",
        "outputId": "85504c65-a5f1-4ca5-9147-043fdb094522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min training MAE is 29290.20884874445 at 150 number of components\n",
            "min testing MAE is 34991.4834222554 at 150 number of components\n",
            "max r2 is 0.2563848110407635 at 152 number of components\n"
          ]
        }
      ],
      "source": [
        "# Test how PCA compares with Forward Selection test on all Principal Components on the data and find the best params\n",
        "best_mae_tr_lr_w_pca = np.inf\n",
        "best_mae_te_lr_w_pca = np.inf\n",
        "best_number_of_components_tr = 0\n",
        "best_number_of_components_te = 0\n",
        "best_r2 = -np.inf\n",
        "best_r2_feat = 0\n",
        "\n",
        "for feature_idx in range(len(principal_components_tr)):\n",
        "    X_train_pca_const = sm.add_constant(principal_components_tr[feature_idx])\n",
        "    X_test_pca_const = sm.add_constant(principal_components_te[feature_idx])\n",
        "    linear_model_pca = sm.OLS(y_train, X_train_pca_const).fit()\n",
        "    y_pred_tr = linear_model_pca.predict(X_train_pca_const)\n",
        "    y_pred_te = linear_model_pca.predict(X_test_pca_const)\n",
        "\n",
        "    mae_tr_lr_w_pca = mean_absolute_error(y_train, y_pred_tr)\n",
        "    mae_te_lr_w_pca = mean_absolute_error(y_test, y_pred_te)\n",
        "\n",
        "    if linear_model_pca.rsquared > best_r2:\n",
        "        best_r2 = linear_model_pca.rsquared\n",
        "        best_r2_feat = feature_idx\n",
        "\n",
        "    if mae_tr_lr_w_pca < best_mae_tr_lr_w_pca:\n",
        "        best_mae_tr_lr_w_pca = mae_tr_lr_w_pca\n",
        "        best_number_of_components_tr = feature_idx\n",
        "\n",
        "    if mae_te_lr_w_pca < best_mae_te_lr_w_pca:\n",
        "        best_mae_te_lr_w_pca = mae_te_lr_w_pca\n",
        "        best_number_of_components_te = feature_idx\n",
        "\n",
        "print(f'min training MAE is {best_mae_tr_lr_w_pca:.4f} at {best_number_of_components_tr} number of components')\n",
        "print(f'min testing MAE is {best_mae_te_lr_w_pca:.4f} at {best_number_of_components_tr} number of components')\n",
        "print(f'max r2 is {best_r2:.4f} at {best_r2_feat:.4f} number of components')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c71354c8-02eb-4119-a27b-6dbc31ac9ffe",
      "metadata": {
        "id": "c71354c8-02eb-4119-a27b-6dbc31ac9ffe"
      },
      "source": [
        "## Construct base SVM, RF, and GB Supervised Models\n",
        "Here I create base models for SVM, RF, and Gradient Boosting to compare the results of these models using the original feature space to these models using the PCA feature space"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f51bb58-3ac4-4305-b87f-e1384318cbcd",
      "metadata": {
        "id": "0f51bb58-3ac4-4305-b87f-e1384318cbcd"
      },
      "source": [
        "### Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "71cc6f7a-7210-479c-86c0-ae7596d8671f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "71cc6f7a-7210-479c-86c0-ae7596d8671f",
        "outputId": "0c4b88c3-5a97-48eb-d70b-1d39b3cea170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error is: 33568.391104084956\n",
            "SVM R² Score: -0.0426\n"
          ]
        }
      ],
      "source": [
        "# Use a Support Vector Machine Classifier to see if there is better performance\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create and fit the SVM model\n",
        "svm_model = SVR(kernel='poly')\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "\n",
        "# Calculate mean absolute error\n",
        "mae_svm = mean_absolute_error(y_test, y_pred_svm)\n",
        "print(f'Mean Absolute Error is: {mae_svm}')\n",
        "\n",
        "# Calculate R^2\n",
        "r2_svm = r2_score(y_test, y_pred_svm)\n",
        "print(f'SVM R² Score: {r2_svm:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f20ff5ca-6eb0-41ee-aa02-290fc95ee848",
      "metadata": {
        "id": "f20ff5ca-6eb0-41ee-aa02-290fc95ee848"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "833f84fa-50c0-49df-8388-e82df68849c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "833f84fa-50c0-49df-8388-e82df68849c0",
        "outputId": "40acdca4-2283-4b7f-e1ad-b81254ef6845"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Mean Absolute Error: 40503.92291563738\n",
            "RF R² Score: -0.3819\n"
          ]
        }
      ],
      "source": [
        "# Random Forest Predictor\n",
        "# Initialize the Random Forest Regressor\n",
        "random_forest = RandomForestRegressor(n_estimators=500, random_state=42)\n",
        "\n",
        "# Fit the model on training data\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_rf = random_forest.predict(X_test)\n",
        "\n",
        "# Calculate Mean Absolute Error\n",
        "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
        "print(f'Random Forest Mean Absolute Error: {mae_rf}')\n",
        "\n",
        "# Calculate R^2\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "print(f'RF R² Score: {r2_rf:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77d6f5f5-1938-4369-abff-50963b471a86",
      "metadata": {
        "id": "77d6f5f5-1938-4369-abff-50963b471a86"
      },
      "source": [
        "### Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "3b14c133-d604-4ada-83a3-b86569e20450",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3b14c133-d604-4ada-83a3-b86569e20450",
        "outputId": "33d4f38b-be03-4c3e-987b-05ec3021dd39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Regressor Mean Absolute Error: 35089.7115\n",
            "Gradient Boosting Regressor R² Score: 0.0003\n"
          ]
        }
      ],
      "source": [
        "# Gradient Boost Regressor\n",
        "# Initialize the Gradient Boosting Regressor\n",
        "gb_rg = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.00001, max_depth=7, random_state=42)\n",
        "\n",
        "# Fit the model on training data\n",
        "gb_rg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_gb = gb_rg.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mae_gbr = mean_absolute_error(y_test, y_pred_gb)\n",
        "r2_gbr = r2_score(y_test, y_pred_gb)\n",
        "\n",
        "print(f'Gradient Boosting Regressor Mean Absolute Error: {mae_gbr:.4f}')\n",
        "print(f'Gradient Boosting Regressor R² Score: {r2_gbr:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01a59ebe-1cb5-4677-8d85-73dd2849600f",
      "metadata": {
        "id": "01a59ebe-1cb5-4677-8d85-73dd2849600f"
      },
      "source": [
        "## Using PCA feat reduction on the SVM, RF, and GB models\n",
        "Here I use the PCA model/features I created, but will implement them into the SVM, Random Forest, and Gradient Booting methods to compare them with the base models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "81bbc96b-dd97-43d1-80af-cc1595e5ef6c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "81bbc96b-dd97-43d1-80af-cc1595e5ef6c",
        "outputId": "e19234b6-4b9f-48d3-b74c-9b751743ed8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing results at 1 components\n",
            "Analyzing results at 2 components\n",
            "Analyzing results at 3 components\n",
            "Analyzing results at 4 components\n",
            "Analyzing results at 5 components\n",
            "Analyzing results at 6 components\n",
            "Analyzing results at 7 components\n",
            "Analyzing results at 8 components\n",
            "Analyzing results at 9 components\n",
            "Analyzing results at 10 components\n",
            "Analyzing results at 11 components\n",
            "Analyzing results at 12 components\n",
            "Analyzing results at 13 components\n",
            "Analyzing results at 14 components\n",
            "Analyzing results at 15 components\n",
            "Analyzing results at 16 components\n",
            "Analyzing results at 17 components\n",
            "Analyzing results at 18 components\n",
            "Analyzing results at 19 components\n",
            "Analyzing results at 20 components\n",
            "Analyzing results at 21 components\n",
            "Analyzing results at 22 components\n",
            "Analyzing results at 23 components\n",
            "Analyzing results at 24 components\n",
            "Analyzing results at 25 components\n",
            "Analyzing results at 26 components\n",
            "Analyzing results at 27 components\n",
            "Analyzing results at 28 components\n",
            "Analyzing results at 29 components\n",
            "Analyzing results at 30 components\n",
            "Analyzing results at 31 components\n",
            "Analyzing results at 32 components\n",
            "Analyzing results at 33 components\n",
            "Analyzing results at 34 components\n",
            "Analyzing results at 35 components\n",
            "Analyzing results at 36 components\n",
            "Analyzing results at 37 components\n",
            "Analyzing results at 38 components\n",
            "Analyzing results at 39 components\n",
            "Analyzing results at 40 components\n",
            "Analyzing results at 41 components\n",
            "Analyzing results at 42 components\n",
            "Analyzing results at 43 components\n",
            "Analyzing results at 44 components\n",
            "Analyzing results at 45 components\n",
            "Analyzing results at 46 components\n",
            "Analyzing results at 47 components\n",
            "Analyzing results at 48 components\n",
            "Analyzing results at 49 components\n",
            "Analyzing results at 50 components\n",
            "Analyzing results at 51 components\n",
            "Analyzing results at 52 components\n",
            "Analyzing results at 53 components\n",
            "Analyzing results at 54 components\n",
            "Analyzing results at 55 components\n",
            "Analyzing results at 56 components\n",
            "Analyzing results at 57 components\n",
            "Analyzing results at 58 components\n",
            "Analyzing results at 59 components\n",
            "Analyzing results at 60 components\n",
            "Analyzing results at 61 components\n",
            "Analyzing results at 62 components\n",
            "Analyzing results at 63 components\n",
            "Analyzing results at 64 components\n",
            "Analyzing results at 65 components\n",
            "Analyzing results at 66 components\n",
            "Analyzing results at 67 components\n",
            "Analyzing results at 68 components\n",
            "Analyzing results at 69 components\n",
            "Analyzing results at 70 components\n",
            "Analyzing results at 71 components\n",
            "Analyzing results at 72 components\n",
            "Analyzing results at 73 components\n",
            "Analyzing results at 74 components\n",
            "Analyzing results at 75 components\n",
            "Analyzing results at 76 components\n",
            "Analyzing results at 77 components\n",
            "Analyzing results at 78 components\n",
            "Analyzing results at 79 components\n",
            "Analyzing results at 80 components\n",
            "Analyzing results at 81 components\n",
            "Analyzing results at 82 components\n",
            "Analyzing results at 83 components\n",
            "Analyzing results at 84 components\n",
            "Analyzing results at 85 components\n",
            "Analyzing results at 86 components\n",
            "Analyzing results at 87 components\n",
            "Analyzing results at 88 components\n",
            "Analyzing results at 89 components\n",
            "Analyzing results at 90 components\n",
            "Analyzing results at 91 components\n",
            "Analyzing results at 92 components\n",
            "Analyzing results at 93 components\n",
            "Analyzing results at 94 components\n",
            "Analyzing results at 95 components\n",
            "Analyzing results at 96 components\n",
            "Analyzing results at 97 components\n",
            "Analyzing results at 98 components\n",
            "Analyzing results at 99 components\n",
            "Analyzing results at 100 components\n",
            "Analyzing results at 101 components\n",
            "Analyzing results at 102 components\n",
            "Analyzing results at 103 components\n",
            "Analyzing results at 104 components\n",
            "Analyzing results at 105 components\n",
            "Analyzing results at 106 components\n",
            "Analyzing results at 107 components\n",
            "Analyzing results at 108 components\n",
            "Analyzing results at 109 components\n",
            "Analyzing results at 110 components\n",
            "Analyzing results at 111 components\n",
            "Analyzing results at 112 components\n",
            "Analyzing results at 113 components\n",
            "Analyzing results at 114 components\n",
            "Analyzing results at 115 components\n",
            "Analyzing results at 116 components\n",
            "Analyzing results at 117 components\n",
            "Analyzing results at 118 components\n",
            "Analyzing results at 119 components\n",
            "Analyzing results at 120 components\n",
            "Analyzing results at 121 components\n",
            "Analyzing results at 122 components\n",
            "Analyzing results at 123 components\n",
            "Analyzing results at 124 components\n",
            "Analyzing results at 125 components\n",
            "Analyzing results at 126 components\n",
            "Analyzing results at 127 components\n",
            "Analyzing results at 128 components\n",
            "Analyzing results at 129 components\n",
            "Analyzing results at 130 components\n",
            "Analyzing results at 131 components\n",
            "Analyzing results at 132 components\n",
            "Analyzing results at 133 components\n",
            "Analyzing results at 134 components\n",
            "Analyzing results at 135 components\n",
            "Analyzing results at 136 components\n",
            "Analyzing results at 137 components\n",
            "Analyzing results at 138 components\n",
            "Analyzing results at 139 components\n",
            "Analyzing results at 140 components\n",
            "Analyzing results at 141 components\n",
            "Analyzing results at 142 components\n",
            "Analyzing results at 143 components\n",
            "Analyzing results at 144 components\n",
            "Analyzing results at 145 components\n",
            "Analyzing results at 146 components\n",
            "Analyzing results at 147 components\n",
            "Analyzing results at 148 components\n",
            "Analyzing results at 149 components\n",
            "Analyzing results at 150 components\n",
            "Analyzing results at 151 components\n",
            "Analyzing results at 152 components\n",
            "Analyzing results at 153 components\n",
            "min MAE for SVM is 33570.878988984565 at 142 number of components. Best r2 is -0.0425538979997373 at 6 number of components\n",
            "min MAE for RF is 36513.82561907047 at 22 number of components. Best r2 is -0.08447233307123758 at 28 number of components\n",
            "min MAE for GB is 35062.692557525756 at 0 number of components. Best r2 is 0.0011092463638481265 at 30 number of components\n"
          ]
        }
      ],
      "source": [
        "## Test each model on the PCA features and determine best MAE\n",
        "scaler = StandardScaler()\n",
        "models = [SVR(kernel='poly'), RandomForestRegressor(n_estimators=500, random_state=42), GradientBoostingRegressor(n_estimators=1000, learning_rate=0.00001, max_depth=7, random_state=42)]\n",
        "best_mae_svr_w_pca = np.inf\n",
        "best_mae_rf_w_pca = np.inf\n",
        "best_mae_gb_w_pca = np.inf\n",
        "best_number_of_components_svr = 0\n",
        "best_number_of_components_rf = 0\n",
        "best_number_of_components_gb = 0\n",
        "best_r2_svr = -np.inf\n",
        "best_r2_rf = -np.inf\n",
        "best_r2_gb = -np.inf\n",
        "best_r2_feat_svr = -np.inf\n",
        "best_r2_feat_rf = -np.inf\n",
        "best_r2_feat_gb = -np.inf\n",
        "for feature_idx in range(len(principal_components_tr)):\n",
        "    print(f'Analyzing results at {feature_idx+1} components')\n",
        "    for i, model in enumerate(models):\n",
        "        model.fit(principal_components_tr[feature_idx], y_train)\n",
        "        y_pred = model.predict(principal_components_te[feature_idx])\n",
        "        current_r2 = r2_score(y_test, y_pred)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        if i == 0:\n",
        "            if mae < best_mae_svr_w_pca:\n",
        "                best_mae_svr_w_pca = mae\n",
        "                best_number_of_components_svr = feature_idx\n",
        "            if current_r2 > best_r2_svr:\n",
        "               best_r2_svr = current_r2\n",
        "               best_r2_feat_svr = feature_idx\n",
        "        elif i == 1:\n",
        "            if mae < best_mae_rf_w_pca:\n",
        "                best_mae_rf_w_pca = mae\n",
        "                best_number_of_components_rf = feature_idx\n",
        "            if current_r2 > best_r2_rf:\n",
        "               best_r2_rf = current_r2\n",
        "               best_r2_feat_rf = feature_idx\n",
        "        else:\n",
        "            if mae < best_mae_gb_w_pca:\n",
        "                best_mae_gb_w_pca = mae\n",
        "                best_number_of_components_gb = feature_idx\n",
        "            if current_r2 > best_r2_gb:\n",
        "                best_r2_gb = current_r2\n",
        "                best_r2_feat_gb = feature_idx\n",
        "print(f'min MAE for SVM is {best_mae_svr_w_pca} at {best_number_of_components_svr} number of components. Best r2 is {best_r2_svr} at {best_r2_feat_svr} number of components')\n",
        "print(f'min MAE for RF is {best_mae_rf_w_pca} at {best_number_of_components_rf} number of components. Best r2 is {best_r2_rf} at {best_r2_feat_rf} number of components')\n",
        "print(f'min MAE for GB is {best_mae_gb_w_pca} at {best_number_of_components_gb} number of components. Best r2 is {best_r2_gb} at {best_r2_feat_gb} number of components')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multilayer Perceptron\n",
        "\n",
        "Below I create a simple MLP. The architecture contains 3 dense layers with decreasing number of neurons for each layer. Every perceptron uses a relu activation function. Finally, the output contains one perceptron with no activation function. The omission of the activation function is due to the nature of the problem being a regression problem which typically requires the raw output score (e.g. predicted salary in thousands of dollars). We run the model over 1000 epochs with a batch size of 32 to thoroughly train the model.  "
      ],
      "metadata": {
        "id": "9rnMAtSw1JQ_"
      },
      "id": "9rnMAtSw1JQ_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the MLP model\n",
        "inputs = Input(shape=(X_train.shape[1],))\n",
        "x = Dense(64, activation='relu')(inputs)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "x = Dense(16, activation='relu')(x)\n",
        "\n",
        "outputs = Dense(1)(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=1000, validation_split=0.1, batch_size=32)\n",
        "\n",
        "# Evaluate\n",
        "mlp_loss, mlp_mae = model.evaluate(X_test, y_test)\n",
        "print(f\"MLP MAE: {mlp_mae}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6bfZn9fOerHy",
        "outputId": "625f289d-c7ed-4c02-8d77-ac4bd94e5844"
      },
      "id": "6bfZn9fOerHy",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - loss: 18678013952.0000 - mae: 127742.1172 - val_loss: 17785892864.0000 - val_mae: 125553.6641\n",
            "Epoch 2/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 17838006272.0000 - mae: 126008.8125 - val_loss: 17784977408.0000 - val_mae: 125549.9531\n",
            "Epoch 3/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19175520256.0000 - mae: 128940.1172 - val_loss: 17783019520.0000 - val_mae: 125541.8672\n",
            "Epoch 4/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 18983174144.0000 - mae: 129373.0469 - val_loss: 17779087360.0000 - val_mae: 125525.4844\n",
            "Epoch 5/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 18274971648.0000 - mae: 127212.2031 - val_loss: 17771749376.0000 - val_mae: 125494.8203\n",
            "Epoch 6/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17480673280.0000 - mae: 125134.3281 - val_loss: 17758410752.0000 - val_mae: 125438.9531\n",
            "Epoch 7/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18732171264.0000 - mae: 128122.2969 - val_loss: 17734465536.0000 - val_mae: 125339.4062\n",
            "Epoch 8/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 18927878144.0000 - mae: 128016.6172 - val_loss: 17694722048.0000 - val_mae: 125174.1797\n",
            "Epoch 9/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17759803392.0000 - mae: 124435.6719 - val_loss: 17633038336.0000 - val_mae: 124917.8047\n",
            "Epoch 10/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17612519424.0000 - mae: 124451.1562 - val_loss: 17542068224.0000 - val_mae: 124538.6875\n",
            "Epoch 11/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18145069056.0000 - mae: 126429.1406 - val_loss: 17413007360.0000 - val_mae: 123998.6562\n",
            "Epoch 12/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17919549440.0000 - mae: 125476.1328 - val_loss: 17239283712.0000 - val_mae: 123264.3047\n",
            "Epoch 13/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18640351232.0000 - mae: 125410.5156 - val_loss: 17012384768.0000 - val_mae: 122297.6172\n",
            "Epoch 14/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17049117696.0000 - mae: 122791.3594 - val_loss: 16725260288.0000 - val_mae: 121056.2344\n",
            "Epoch 15/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18396217344.0000 - mae: 123434.7188 - val_loss: 16375372800.0000 - val_mae: 119512.0703\n",
            "Epoch 16/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 15490358272.0000 - mae: 115759.0234 - val_loss: 15952300032.0000 - val_mae: 117600.1641\n",
            "Epoch 17/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 14004051968.0000 - mae: 109913.2266 - val_loss: 15450617856.0000 - val_mae: 115259.2578\n",
            "Epoch 18/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13557747712.0000 - mae: 108126.9062 - val_loss: 14883552256.0000 - val_mae: 112511.9375\n",
            "Epoch 19/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13549969408.0000 - mae: 106772.6094 - val_loss: 14244086784.0000 - val_mae: 109245.0938\n",
            "Epoch 20/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12397242368.0000 - mae: 100886.3672 - val_loss: 13562833920.0000 - val_mae: 105567.7109\n",
            "Epoch 21/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10906070016.0000 - mae: 94381.5781 - val_loss: 12843899904.0000 - val_mae: 101389.6328\n",
            "Epoch 22/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10381617152.0000 - mae: 90192.9375 - val_loss: 12115054592.0000 - val_mae: 97026.1094\n",
            "Epoch 23/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9148027904.0000 - mae: 82933.1641 - val_loss: 11401589760.0000 - val_mae: 92390.0469\n",
            "Epoch 24/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7675742720.0000 - mae: 73599.3203 - val_loss: 10724808704.0000 - val_mae: 87441.0703\n",
            "Epoch 25/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7085520384.0000 - mae: 68074.5391 - val_loss: 10117899264.0000 - val_mae: 82796.7266\n",
            "Epoch 26/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5654581760.0000 - mae: 59008.7188 - val_loss: 9597601792.0000 - val_mae: 78711.3203\n",
            "Epoch 27/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4936937984.0000 - mae: 54523.4766 - val_loss: 9159730176.0000 - val_mae: 75242.0234\n",
            "Epoch 28/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3905858048.0000 - mae: 46779.6211 - val_loss: 8826873856.0000 - val_mae: 72020.5938\n",
            "Epoch 29/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3643469824.0000 - mae: 44159.3242 - val_loss: 8573020160.0000 - val_mae: 69499.6719\n",
            "Epoch 30/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3295844096.0000 - mae: 42046.0234 - val_loss: 8387485184.0000 - val_mae: 67769.2266\n",
            "Epoch 31/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2649539584.0000 - mae: 37397.6406 - val_loss: 8248427008.0000 - val_mae: 66340.5547\n",
            "Epoch 32/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2667067648.0000 - mae: 35943.1758 - val_loss: 8146333184.0000 - val_mae: 65061.1680\n",
            "Epoch 33/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2367376896.0000 - mae: 34725.5273 - val_loss: 8070707712.0000 - val_mae: 64167.8555\n",
            "Epoch 34/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2978702848.0000 - mae: 36097.1641 - val_loss: 8007751680.0000 - val_mae: 63566.4766\n",
            "Epoch 35/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2271440128.0000 - mae: 33372.6133 - val_loss: 7960264704.0000 - val_mae: 63148.8242\n",
            "Epoch 36/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2310973184.0000 - mae: 33689.4805 - val_loss: 7917122048.0000 - val_mae: 62895.7383\n",
            "Epoch 37/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2218887936.0000 - mae: 32868.8672 - val_loss: 7880356352.0000 - val_mae: 62733.5391\n",
            "Epoch 38/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1730624640.0000 - mae: 29295.5469 - val_loss: 7846861824.0000 - val_mae: 62702.3633\n",
            "Epoch 39/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1980448512.0000 - mae: 31677.8027 - val_loss: 7818408960.0000 - val_mae: 62551.3633\n",
            "Epoch 40/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1639556736.0000 - mae: 30243.0723 - val_loss: 7796194304.0000 - val_mae: 62447.9609\n",
            "Epoch 41/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1625678208.0000 - mae: 28787.0117 - val_loss: 7774572032.0000 - val_mae: 62359.0547\n",
            "Epoch 42/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1905127936.0000 - mae: 29895.2500 - val_loss: 7759050752.0000 - val_mae: 62266.0820\n",
            "Epoch 43/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2002400640.0000 - mae: 30353.1113 - val_loss: 7744727552.0000 - val_mae: 62271.7422\n",
            "Epoch 44/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1702474880.0000 - mae: 29025.3145 - val_loss: 7732824064.0000 - val_mae: 62316.6484\n",
            "Epoch 45/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1861045376.0000 - mae: 29917.7012 - val_loss: 7723415552.0000 - val_mae: 62310.6836\n",
            "Epoch 46/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1765071872.0000 - mae: 27921.7207 - val_loss: 7711913472.0000 - val_mae: 62207.0977\n",
            "Epoch 47/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1847081984.0000 - mae: 29310.9727 - val_loss: 7705076736.0000 - val_mae: 62164.8828\n",
            "Epoch 48/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2116056320.0000 - mae: 29972.9492 - val_loss: 7702903296.0000 - val_mae: 62196.1680\n",
            "Epoch 49/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1928783744.0000 - mae: 29120.4512 - val_loss: 7698655744.0000 - val_mae: 62203.0820\n",
            "Epoch 50/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1479593088.0000 - mae: 26686.8086 - val_loss: 7696640000.0000 - val_mae: 62206.6602\n",
            "Epoch 51/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1403363968.0000 - mae: 26796.0840 - val_loss: 7693969920.0000 - val_mae: 62184.4141\n",
            "Epoch 52/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1491035776.0000 - mae: 25753.1426 - val_loss: 7691931648.0000 - val_mae: 62179.0820\n",
            "Epoch 53/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1652703744.0000 - mae: 27094.9238 - val_loss: 7692794368.0000 - val_mae: 62242.5000\n",
            "Epoch 54/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1747245056.0000 - mae: 27982.3027 - val_loss: 7690151936.0000 - val_mae: 62172.5391\n",
            "Epoch 55/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1492386688.0000 - mae: 25676.7246 - val_loss: 7690645504.0000 - val_mae: 62192.0469\n",
            "Epoch 56/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1735492608.0000 - mae: 25685.6680 - val_loss: 7696018944.0000 - val_mae: 62264.7812\n",
            "Epoch 57/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1709339008.0000 - mae: 26591.0039 - val_loss: 7697511936.0000 - val_mae: 62381.1797\n",
            "Epoch 58/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1444678016.0000 - mae: 25540.6719 - val_loss: 7701551616.0000 - val_mae: 62438.9961\n",
            "Epoch 59/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1432493952.0000 - mae: 25783.4570 - val_loss: 7704946176.0000 - val_mae: 62446.9492\n",
            "Epoch 60/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1324875136.0000 - mae: 23823.4766 - val_loss: 7704565248.0000 - val_mae: 62471.7656\n",
            "Epoch 61/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1301821440.0000 - mae: 24307.3750 - val_loss: 7709005312.0000 - val_mae: 62573.2500\n",
            "Epoch 62/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1569022976.0000 - mae: 24552.5996 - val_loss: 7716114432.0000 - val_mae: 62705.1172\n",
            "Epoch 63/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1762079360.0000 - mae: 26036.4824 - val_loss: 7717610496.0000 - val_mae: 62726.3711\n",
            "Epoch 64/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1604910336.0000 - mae: 26422.7168 - val_loss: 7720541696.0000 - val_mae: 62765.0391\n",
            "Epoch 65/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1570392576.0000 - mae: 26821.4941 - val_loss: 7727181824.0000 - val_mae: 62837.4023\n",
            "Epoch 66/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1583592064.0000 - mae: 25970.2441 - val_loss: 7733997568.0000 - val_mae: 62978.5977\n",
            "Epoch 67/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1375979520.0000 - mae: 23550.5469 - val_loss: 7737721344.0000 - val_mae: 62987.9336\n",
            "Epoch 68/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1607629568.0000 - mae: 25851.3652 - val_loss: 7742769664.0000 - val_mae: 63091.1602\n",
            "Epoch 69/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1557430912.0000 - mae: 24972.8926 - val_loss: 7751979520.0000 - val_mae: 63215.3359\n",
            "Epoch 70/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1942531072.0000 - mae: 25788.3965 - val_loss: 7759224320.0000 - val_mae: 63285.6445\n",
            "Epoch 71/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1622551680.0000 - mae: 26755.8359 - val_loss: 7767455744.0000 - val_mae: 63387.5391\n",
            "Epoch 72/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1350497152.0000 - mae: 24732.9570 - val_loss: 7768653312.0000 - val_mae: 63401.7500\n",
            "Epoch 73/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1403110528.0000 - mae: 23461.4727 - val_loss: 7778320896.0000 - val_mae: 63544.6523\n",
            "Epoch 74/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1487259136.0000 - mae: 24500.7930 - val_loss: 7784869376.0000 - val_mae: 63627.1719\n",
            "Epoch 75/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1445460096.0000 - mae: 25206.3691 - val_loss: 7795327488.0000 - val_mae: 63725.5977\n",
            "Epoch 76/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1346414592.0000 - mae: 23404.1074 - val_loss: 7804701696.0000 - val_mae: 63844.7656\n",
            "Epoch 77/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1445838208.0000 - mae: 24412.3379 - val_loss: 7813476864.0000 - val_mae: 63961.5586\n",
            "Epoch 78/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1408295296.0000 - mae: 23985.1289 - val_loss: 7822287872.0000 - val_mae: 64019.8477\n",
            "Epoch 79/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1191273984.0000 - mae: 22864.9980 - val_loss: 7829509632.0000 - val_mae: 64090.2031\n",
            "Epoch 80/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1582405120.0000 - mae: 23392.5703 - val_loss: 7832468480.0000 - val_mae: 64107.2812\n",
            "Epoch 81/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1918354048.0000 - mae: 25605.1094 - val_loss: 7836407808.0000 - val_mae: 64095.1914\n",
            "Epoch 82/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1728979840.0000 - mae: 25524.1270 - val_loss: 7846737408.0000 - val_mae: 64260.2500\n",
            "Epoch 83/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1299899008.0000 - mae: 23550.6836 - val_loss: 7850063360.0000 - val_mae: 64256.6211\n",
            "Epoch 84/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1513742976.0000 - mae: 24172.3359 - val_loss: 7857520128.0000 - val_mae: 64355.6211\n",
            "Epoch 85/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1319930368.0000 - mae: 22920.0703 - val_loss: 7862028288.0000 - val_mae: 64396.0977\n",
            "Epoch 86/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1100839168.0000 - mae: 21865.6836 - val_loss: 7860738560.0000 - val_mae: 64335.4922\n",
            "Epoch 87/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2086447872.0000 - mae: 26900.1621 - val_loss: 7868516352.0000 - val_mae: 64466.0859\n",
            "Epoch 88/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1907405952.0000 - mae: 24439.5488 - val_loss: 7875004928.0000 - val_mae: 64517.7930\n",
            "Epoch 89/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1229295872.0000 - mae: 22395.5430 - val_loss: 7876950528.0000 - val_mae: 64495.0547\n",
            "Epoch 90/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1177331328.0000 - mae: 20796.8223 - val_loss: 7886455296.0000 - val_mae: 64610.9688\n",
            "Epoch 91/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1510338688.0000 - mae: 24815.4258 - val_loss: 7898648064.0000 - val_mae: 64787.6328\n",
            "Epoch 92/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1260716544.0000 - mae: 22850.0078 - val_loss: 7898447872.0000 - val_mae: 64720.2852\n",
            "Epoch 93/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1253850752.0000 - mae: 22075.3828 - val_loss: 7910323200.0000 - val_mae: 64850.4531\n",
            "Epoch 94/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1388996480.0000 - mae: 23255.5742 - val_loss: 7918623232.0000 - val_mae: 64914.5664\n",
            "Epoch 95/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1251747968.0000 - mae: 23496.0117 - val_loss: 7921064448.0000 - val_mae: 64896.9023\n",
            "Epoch 96/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1080951552.0000 - mae: 21988.9531 - val_loss: 7927203840.0000 - val_mae: 64960.8242\n",
            "Epoch 97/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1216710656.0000 - mae: 22919.7637 - val_loss: 7959589376.0000 - val_mae: 65402.8242\n",
            "Epoch 98/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1275856000.0000 - mae: 23596.4258 - val_loss: 7955090432.0000 - val_mae: 65277.8906\n",
            "Epoch 99/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1269370112.0000 - mae: 22090.6582 - val_loss: 7957982720.0000 - val_mae: 65262.6680\n",
            "Epoch 100/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1189516672.0000 - mae: 22595.9199 - val_loss: 7963118080.0000 - val_mae: 65290.5117\n",
            "Epoch 101/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1697275392.0000 - mae: 24644.9219 - val_loss: 7975143936.0000 - val_mae: 65443.5469\n",
            "Epoch 102/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1219719168.0000 - mae: 23025.9629 - val_loss: 7976250368.0000 - val_mae: 65423.5469\n",
            "Epoch 103/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1567532800.0000 - mae: 23684.0918 - val_loss: 7974746112.0000 - val_mae: 65367.8008\n",
            "Epoch 104/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1425427968.0000 - mae: 23799.0312 - val_loss: 7972681728.0000 - val_mae: 65243.7031\n",
            "Epoch 105/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1432998272.0000 - mae: 23736.3828 - val_loss: 7981442560.0000 - val_mae: 65349.4102\n",
            "Epoch 106/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1501427840.0000 - mae: 24495.0488 - val_loss: 7989476864.0000 - val_mae: 65424.0391\n",
            "Epoch 107/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1336573312.0000 - mae: 23137.4961 - val_loss: 7989732864.0000 - val_mae: 65397.8633\n",
            "Epoch 108/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1338696704.0000 - mae: 22799.9199 - val_loss: 8006697984.0000 - val_mae: 65588.6875\n",
            "Epoch 109/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1180947840.0000 - mae: 22562.2188 - val_loss: 8008817664.0000 - val_mae: 65569.7109\n",
            "Epoch 110/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1327879808.0000 - mae: 24099.4941 - val_loss: 8013955584.0000 - val_mae: 65596.1172\n",
            "Epoch 111/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1438356992.0000 - mae: 23008.4785 - val_loss: 8036639744.0000 - val_mae: 65894.6875\n",
            "Epoch 112/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1707497728.0000 - mae: 24781.2656 - val_loss: 8027166720.0000 - val_mae: 65765.7109\n",
            "Epoch 113/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1482203008.0000 - mae: 21762.1602 - val_loss: 8016239104.0000 - val_mae: 65592.6172\n",
            "Epoch 114/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1592254208.0000 - mae: 23993.8398 - val_loss: 8030009856.0000 - val_mae: 65765.2656\n",
            "Epoch 115/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1300533120.0000 - mae: 22337.8594 - val_loss: 8028796416.0000 - val_mae: 65717.2344\n",
            "Epoch 116/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1400857216.0000 - mae: 23474.4746 - val_loss: 8035774976.0000 - val_mae: 65788.6016\n",
            "Epoch 117/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1387946368.0000 - mae: 23300.9414 - val_loss: 8047950848.0000 - val_mae: 65920.8047\n",
            "Epoch 118/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1412616832.0000 - mae: 23490.0918 - val_loss: 8056837120.0000 - val_mae: 66008.3672\n",
            "Epoch 119/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1434812800.0000 - mae: 23491.4297 - val_loss: 8069944832.0000 - val_mae: 66088.3125\n",
            "Epoch 120/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1195156352.0000 - mae: 21787.8945 - val_loss: 8075398656.0000 - val_mae: 66127.2344\n",
            "Epoch 121/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1178669568.0000 - mae: 22979.0371 - val_loss: 8072428032.0000 - val_mae: 66052.0625\n",
            "Epoch 122/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1360993920.0000 - mae: 22605.8320 - val_loss: 8080078336.0000 - val_mae: 66144.4609\n",
            "Epoch 123/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1635769984.0000 - mae: 24345.9414 - val_loss: 8082180608.0000 - val_mae: 66186.5547\n",
            "Epoch 124/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1530765568.0000 - mae: 22976.7695 - val_loss: 8078988288.0000 - val_mae: 66089.4766\n",
            "Epoch 125/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1342906496.0000 - mae: 23452.1074 - val_loss: 8082750464.0000 - val_mae: 66137.9062\n",
            "Epoch 126/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1416518400.0000 - mae: 22849.4395 - val_loss: 8099407360.0000 - val_mae: 66344.0469\n",
            "Epoch 127/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1460181760.0000 - mae: 24101.0098 - val_loss: 8100367872.0000 - val_mae: 66351.4453\n",
            "Epoch 128/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1345555584.0000 - mae: 22833.8027 - val_loss: 8101277184.0000 - val_mae: 66338.6250\n",
            "Epoch 129/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1638363264.0000 - mae: 24273.8301 - val_loss: 8105502208.0000 - val_mae: 66369.4297\n",
            "Epoch 130/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1479608320.0000 - mae: 23588.5781 - val_loss: 8119234048.0000 - val_mae: 66526.4531\n",
            "Epoch 131/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1703792640.0000 - mae: 25415.4512 - val_loss: 8118965248.0000 - val_mae: 66480.3359\n",
            "Epoch 132/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1167562880.0000 - mae: 22141.1328 - val_loss: 8117152256.0000 - val_mae: 66468.9922\n",
            "Epoch 133/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1225515264.0000 - mae: 22639.4961 - val_loss: 8120287744.0000 - val_mae: 66476.3672\n",
            "Epoch 134/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1181826944.0000 - mae: 20964.3359 - val_loss: 8129074688.0000 - val_mae: 66601.0000\n",
            "Epoch 135/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1237262848.0000 - mae: 21952.2207 - val_loss: 8140506112.0000 - val_mae: 66714.0078\n",
            "Epoch 136/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1472397568.0000 - mae: 23865.6465 - val_loss: 8136915968.0000 - val_mae: 66648.6641\n",
            "Epoch 137/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1324281088.0000 - mae: 21670.1738 - val_loss: 8141400576.0000 - val_mae: 66685.6484\n",
            "Epoch 138/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1502542848.0000 - mae: 21818.4258 - val_loss: 8141494784.0000 - val_mae: 66679.9453\n",
            "Epoch 139/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1251533440.0000 - mae: 22345.2949 - val_loss: 8159837696.0000 - val_mae: 66908.0547\n",
            "Epoch 140/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1223943552.0000 - mae: 22786.1836 - val_loss: 8149381632.0000 - val_mae: 66760.9062\n",
            "Epoch 141/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1415782400.0000 - mae: 23772.7910 - val_loss: 8148857344.0000 - val_mae: 66721.5469\n",
            "Epoch 142/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1513857280.0000 - mae: 22248.8301 - val_loss: 8157091328.0000 - val_mae: 66788.0938\n",
            "Epoch 143/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1716258304.0000 - mae: 23603.6875 - val_loss: 8153688576.0000 - val_mae: 66711.7188\n",
            "Epoch 144/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1478974976.0000 - mae: 24760.3926 - val_loss: 8164338688.0000 - val_mae: 66846.4766\n",
            "Epoch 145/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1193526528.0000 - mae: 22109.3809 - val_loss: 8167916544.0000 - val_mae: 66856.6328\n",
            "Epoch 146/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1316473088.0000 - mae: 22746.4473 - val_loss: 8170426368.0000 - val_mae: 66868.8438\n",
            "Epoch 147/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1396688512.0000 - mae: 22039.8594 - val_loss: 8184128512.0000 - val_mae: 67024.9141\n",
            "Epoch 148/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1241121792.0000 - mae: 22244.2734 - val_loss: 8189002240.0000 - val_mae: 67136.5859\n",
            "Epoch 149/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1481773184.0000 - mae: 22942.9062 - val_loss: 8190652416.0000 - val_mae: 67124.9297\n",
            "Epoch 150/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1647904000.0000 - mae: 23810.4766 - val_loss: 8185015296.0000 - val_mae: 67029.8906\n",
            "Epoch 151/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1357961344.0000 - mae: 23040.8008 - val_loss: 8186691584.0000 - val_mae: 67028.6250\n",
            "Epoch 152/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1322343168.0000 - mae: 22443.2500 - val_loss: 8192347648.0000 - val_mae: 67095.1172\n",
            "Epoch 153/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1189432320.0000 - mae: 22395.9961 - val_loss: 8200296448.0000 - val_mae: 67180.0781\n",
            "Epoch 154/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1341015296.0000 - mae: 23201.9883 - val_loss: 8215547904.0000 - val_mae: 67347.3516\n",
            "Epoch 155/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1380640512.0000 - mae: 22779.0195 - val_loss: 8218034688.0000 - val_mae: 67380.9453\n",
            "Epoch 156/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1364241536.0000 - mae: 22365.2734 - val_loss: 8220367360.0000 - val_mae: 67374.3984\n",
            "Epoch 157/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1578234496.0000 - mae: 22798.6172 - val_loss: 8224236544.0000 - val_mae: 67403.3516\n",
            "Epoch 158/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1272510848.0000 - mae: 23219.9414 - val_loss: 8214476288.0000 - val_mae: 67245.0859\n",
            "Epoch 159/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1037442752.0000 - mae: 20615.6191 - val_loss: 8210193920.0000 - val_mae: 67203.1797\n",
            "Epoch 160/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1174450560.0000 - mae: 21021.4336 - val_loss: 8210627072.0000 - val_mae: 67169.2109\n",
            "Epoch 161/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1240108288.0000 - mae: 22296.1543 - val_loss: 8221160448.0000 - val_mae: 67345.6641\n",
            "Epoch 162/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1331205760.0000 - mae: 22948.7363 - val_loss: 8216579584.0000 - val_mae: 67293.5938\n",
            "Epoch 163/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1887854976.0000 - mae: 23529.5840 - val_loss: 8224882176.0000 - val_mae: 67379.9688\n",
            "Epoch 164/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1492892160.0000 - mae: 23334.1758 - val_loss: 8217353728.0000 - val_mae: 67299.8594\n",
            "Epoch 165/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1111379968.0000 - mae: 21438.0879 - val_loss: 8216113664.0000 - val_mae: 67245.3516\n",
            "Epoch 166/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1666795648.0000 - mae: 23999.5137 - val_loss: 8228649984.0000 - val_mae: 67375.8438\n",
            "Epoch 167/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1277408512.0000 - mae: 22487.7090 - val_loss: 8225349120.0000 - val_mae: 67262.9062\n",
            "Epoch 168/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1408190336.0000 - mae: 21842.0488 - val_loss: 8253655040.0000 - val_mae: 67567.5000\n",
            "Epoch 169/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1272162176.0000 - mae: 22427.6621 - val_loss: 8250300928.0000 - val_mae: 67500.2656\n",
            "Epoch 170/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1168297856.0000 - mae: 21525.1270 - val_loss: 8246630400.0000 - val_mae: 67426.3906\n",
            "Epoch 171/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1161261824.0000 - mae: 21292.8320 - val_loss: 8253965312.0000 - val_mae: 67511.9219\n",
            "Epoch 172/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1297625600.0000 - mae: 22792.9395 - val_loss: 8255845376.0000 - val_mae: 67519.8594\n",
            "Epoch 173/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1354758784.0000 - mae: 21813.9023 - val_loss: 8268943360.0000 - val_mae: 67664.5547\n",
            "Epoch 174/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1409756288.0000 - mae: 23438.4746 - val_loss: 8249481728.0000 - val_mae: 67425.5547\n",
            "Epoch 175/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1497893888.0000 - mae: 24279.1113 - val_loss: 8260673024.0000 - val_mae: 67540.4766\n",
            "Epoch 176/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 985110848.0000 - mae: 19972.2168 - val_loss: 8262773760.0000 - val_mae: 67547.1328\n",
            "Epoch 177/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1549753088.0000 - mae: 23335.7070 - val_loss: 8282677760.0000 - val_mae: 67703.3281\n",
            "Epoch 178/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1149841664.0000 - mae: 20883.8789 - val_loss: 8279592960.0000 - val_mae: 67645.6719\n",
            "Epoch 179/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1179216512.0000 - mae: 21424.6562 - val_loss: 8270701568.0000 - val_mae: 67503.3828\n",
            "Epoch 180/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1824246656.0000 - mae: 24188.0176 - val_loss: 8290492928.0000 - val_mae: 67728.3203\n",
            "Epoch 181/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1178283392.0000 - mae: 21011.1094 - val_loss: 8286127616.0000 - val_mae: 67663.8906\n",
            "Epoch 182/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1481577600.0000 - mae: 23540.7871 - val_loss: 8300485632.0000 - val_mae: 67833.4141\n",
            "Epoch 183/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1517487744.0000 - mae: 23789.3359 - val_loss: 8301283328.0000 - val_mae: 67833.9609\n",
            "Epoch 184/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1547125248.0000 - mae: 23456.4375 - val_loss: 8317364224.0000 - val_mae: 68027.5000\n",
            "Epoch 185/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1133494528.0000 - mae: 21790.0312 - val_loss: 8295180288.0000 - val_mae: 67763.6016\n",
            "Epoch 186/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1317725056.0000 - mae: 21660.2402 - val_loss: 8295339520.0000 - val_mae: 67753.3047\n",
            "Epoch 187/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1226953984.0000 - mae: 21605.3613 - val_loss: 8296033280.0000 - val_mae: 67745.7031\n",
            "Epoch 188/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1433021952.0000 - mae: 22998.0859 - val_loss: 8315758592.0000 - val_mae: 67966.4219\n",
            "Epoch 189/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1140108928.0000 - mae: 21373.6895 - val_loss: 8304469504.0000 - val_mae: 67827.8906\n",
            "Epoch 190/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1748962048.0000 - mae: 22947.0176 - val_loss: 8301948928.0000 - val_mae: 67786.5312\n",
            "Epoch 191/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1087498624.0000 - mae: 20465.0078 - val_loss: 8307781120.0000 - val_mae: 67843.0859\n",
            "Epoch 192/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1616921856.0000 - mae: 23489.4648 - val_loss: 8316408320.0000 - val_mae: 67950.3594\n",
            "Epoch 193/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1234519168.0000 - mae: 21975.0918 - val_loss: 8324495872.0000 - val_mae: 68035.0469\n",
            "Epoch 194/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1540491648.0000 - mae: 23075.7969 - val_loss: 8323963904.0000 - val_mae: 68014.1328\n",
            "Epoch 195/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1336369280.0000 - mae: 22691.0938 - val_loss: 8312656384.0000 - val_mae: 67889.6875\n",
            "Epoch 196/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1570155008.0000 - mae: 22921.8555 - val_loss: 8303802368.0000 - val_mae: 67754.7031\n",
            "Epoch 197/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1171096704.0000 - mae: 20537.2285 - val_loss: 8296068096.0000 - val_mae: 67660.5234\n",
            "Epoch 198/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1410794496.0000 - mae: 23052.4688 - val_loss: 8311376384.0000 - val_mae: 67829.9609\n",
            "Epoch 199/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1301275520.0000 - mae: 22752.3105 - val_loss: 8311879680.0000 - val_mae: 67821.6719\n",
            "Epoch 200/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1577971456.0000 - mae: 23551.8398 - val_loss: 8316294144.0000 - val_mae: 67901.3047\n",
            "Epoch 201/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1922272768.0000 - mae: 24852.4297 - val_loss: 8330644480.0000 - val_mae: 68041.2188\n",
            "Epoch 202/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1182543616.0000 - mae: 20936.5996 - val_loss: 8327068672.0000 - val_mae: 67995.4922\n",
            "Epoch 203/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1296838656.0000 - mae: 21748.1504 - val_loss: 8343054336.0000 - val_mae: 68175.4531\n",
            "Epoch 204/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1316294016.0000 - mae: 22046.2090 - val_loss: 8353356800.0000 - val_mae: 68247.4297\n",
            "Epoch 205/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1349366144.0000 - mae: 21919.6133 - val_loss: 8352892928.0000 - val_mae: 68233.9375\n",
            "Epoch 206/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1544506368.0000 - mae: 22193.7246 - val_loss: 8340262400.0000 - val_mae: 68076.9531\n",
            "Epoch 207/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1617933568.0000 - mae: 22357.5859 - val_loss: 8338013184.0000 - val_mae: 68015.6484\n",
            "Epoch 208/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1152927360.0000 - mae: 21448.8086 - val_loss: 8346600448.0000 - val_mae: 68103.5469\n",
            "Epoch 209/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1589876608.0000 - mae: 24000.0391 - val_loss: 8371231232.0000 - val_mae: 68370.9766\n",
            "Epoch 210/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1506804736.0000 - mae: 23157.3438 - val_loss: 8350087680.0000 - val_mae: 68129.3594\n",
            "Epoch 211/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1195865984.0000 - mae: 21064.9199 - val_loss: 8362362880.0000 - val_mae: 68260.5625\n",
            "Epoch 212/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1464877824.0000 - mae: 22090.9023 - val_loss: 8355628544.0000 - val_mae: 68171.7500\n",
            "Epoch 213/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1204452736.0000 - mae: 21605.7734 - val_loss: 8350225920.0000 - val_mae: 68091.2109\n",
            "Epoch 214/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1290425088.0000 - mae: 23021.4609 - val_loss: 8376123392.0000 - val_mae: 68409.2031\n",
            "Epoch 215/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1304105088.0000 - mae: 23126.4141 - val_loss: 8380475392.0000 - val_mae: 68437.2344\n",
            "Epoch 216/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1256534272.0000 - mae: 21930.6016 - val_loss: 8361416192.0000 - val_mae: 68216.9453\n",
            "Epoch 217/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1117228032.0000 - mae: 20999.1113 - val_loss: 8356664320.0000 - val_mae: 68170.4766\n",
            "Epoch 218/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1391446656.0000 - mae: 23037.3047 - val_loss: 8360126976.0000 - val_mae: 68199.6328\n",
            "Epoch 219/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1336676480.0000 - mae: 22513.9004 - val_loss: 8376768000.0000 - val_mae: 68400.4453\n",
            "Epoch 220/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1114816128.0000 - mae: 21202.7012 - val_loss: 8380977664.0000 - val_mae: 68441.7891\n",
            "Epoch 221/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1362905728.0000 - mae: 23054.6445 - val_loss: 8369597952.0000 - val_mae: 68299.4766\n",
            "Epoch 222/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1197901184.0000 - mae: 21430.6660 - val_loss: 8353237504.0000 - val_mae: 68114.4219\n",
            "Epoch 223/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1029289792.0000 - mae: 19862.2246 - val_loss: 8351890944.0000 - val_mae: 68059.1719\n",
            "Epoch 224/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1342746752.0000 - mae: 23137.0195 - val_loss: 8373110272.0000 - val_mae: 68329.5703\n",
            "Epoch 225/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1185143680.0000 - mae: 21758.6973 - val_loss: 8377814016.0000 - val_mae: 68347.1484\n",
            "Epoch 226/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1345730432.0000 - mae: 21939.8652 - val_loss: 8374982144.0000 - val_mae: 68305.4375\n",
            "Epoch 227/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1323984896.0000 - mae: 23287.2285 - val_loss: 8369083904.0000 - val_mae: 68245.6484\n",
            "Epoch 228/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1112023936.0000 - mae: 21100.3633 - val_loss: 8379792384.0000 - val_mae: 68359.0469\n",
            "Epoch 229/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1078172416.0000 - mae: 21297.7461 - val_loss: 8378131968.0000 - val_mae: 68340.8203\n",
            "Epoch 230/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1290467712.0000 - mae: 21655.6719 - val_loss: 8385302528.0000 - val_mae: 68433.5156\n",
            "Epoch 231/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1401306496.0000 - mae: 22785.2266 - val_loss: 8369533952.0000 - val_mae: 68208.8906\n",
            "Epoch 232/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1631485696.0000 - mae: 23717.8984 - val_loss: 8381627392.0000 - val_mae: 68365.9219\n",
            "Epoch 233/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1148551936.0000 - mae: 21587.7305 - val_loss: 8381775872.0000 - val_mae: 68338.8359\n",
            "Epoch 234/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1322475008.0000 - mae: 21659.0605 - val_loss: 8390178816.0000 - val_mae: 68428.0000\n",
            "Epoch 235/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1059017280.0000 - mae: 20543.2305 - val_loss: 8387792896.0000 - val_mae: 68400.7109\n",
            "Epoch 236/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1388841600.0000 - mae: 22891.8770 - val_loss: 8385214976.0000 - val_mae: 68350.8516\n",
            "Epoch 237/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1624294400.0000 - mae: 22988.0703 - val_loss: 8391401984.0000 - val_mae: 68399.6094\n",
            "Epoch 238/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1386827904.0000 - mae: 22523.6484 - val_loss: 8381514240.0000 - val_mae: 68295.0469\n",
            "Epoch 239/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1278927360.0000 - mae: 21102.0215 - val_loss: 8385274368.0000 - val_mae: 68326.5156\n",
            "Epoch 240/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1366527232.0000 - mae: 22622.9414 - val_loss: 8388028416.0000 - val_mae: 68362.0312\n",
            "Epoch 241/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1212435712.0000 - mae: 20983.1270 - val_loss: 8387979776.0000 - val_mae: 68375.7578\n",
            "Epoch 242/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1145448064.0000 - mae: 20624.1172 - val_loss: 8383918080.0000 - val_mae: 68326.2578\n",
            "Epoch 243/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1218418560.0000 - mae: 21328.3926 - val_loss: 8395640832.0000 - val_mae: 68451.7969\n",
            "Epoch 244/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1582043904.0000 - mae: 23053.0664 - val_loss: 8393888768.0000 - val_mae: 68417.9141\n",
            "Epoch 245/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1651137024.0000 - mae: 22902.1680 - val_loss: 8387017728.0000 - val_mae: 68337.3906\n",
            "Epoch 246/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1210287744.0000 - mae: 22273.0527 - val_loss: 8381021696.0000 - val_mae: 68276.1094\n",
            "Epoch 247/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1355229568.0000 - mae: 22739.7930 - val_loss: 8392098304.0000 - val_mae: 68399.9141\n",
            "Epoch 248/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1094001792.0000 - mae: 20998.0586 - val_loss: 8375342080.0000 - val_mae: 68199.7734\n",
            "Epoch 249/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1332958208.0000 - mae: 23381.3535 - val_loss: 8390374400.0000 - val_mae: 68334.6328\n",
            "Epoch 250/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1290098560.0000 - mae: 22309.9570 - val_loss: 8404712960.0000 - val_mae: 68478.0859\n",
            "Epoch 251/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1577468672.0000 - mae: 23008.3594 - val_loss: 8374190080.0000 - val_mae: 68126.6172\n",
            "Epoch 252/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1256486400.0000 - mae: 21460.2539 - val_loss: 8378088448.0000 - val_mae: 68208.7422\n",
            "Epoch 253/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1295169920.0000 - mae: 21394.5430 - val_loss: 8397492224.0000 - val_mae: 68432.7891\n",
            "Epoch 254/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1395016704.0000 - mae: 22025.0449 - val_loss: 8387730432.0000 - val_mae: 68330.6719\n",
            "Epoch 255/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1464641536.0000 - mae: 22561.9414 - val_loss: 8399346176.0000 - val_mae: 68471.1484\n",
            "Epoch 256/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1270003584.0000 - mae: 22924.6660 - val_loss: 8389129216.0000 - val_mae: 68329.1953\n",
            "Epoch 257/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1538565248.0000 - mae: 22901.0410 - val_loss: 8410805760.0000 - val_mae: 68554.3203\n",
            "Epoch 258/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1254265088.0000 - mae: 21242.7637 - val_loss: 8411448320.0000 - val_mae: 68529.1953\n",
            "Epoch 259/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1196583040.0000 - mae: 21133.3945 - val_loss: 8414005248.0000 - val_mae: 68566.2188\n",
            "Epoch 260/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1202950528.0000 - mae: 21014.4102 - val_loss: 8406259712.0000 - val_mae: 68475.2109\n",
            "Epoch 261/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1352414720.0000 - mae: 22382.5469 - val_loss: 8410733568.0000 - val_mae: 68494.0938\n",
            "Epoch 262/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1437909120.0000 - mae: 22155.7539 - val_loss: 8424925696.0000 - val_mae: 68667.2500\n",
            "Epoch 263/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1134002560.0000 - mae: 20580.5195 - val_loss: 8412902912.0000 - val_mae: 68527.9297\n",
            "Epoch 264/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1596801280.0000 - mae: 22762.6797 - val_loss: 8416408064.0000 - val_mae: 68570.0469\n",
            "Epoch 265/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1232620800.0000 - mae: 21278.2539 - val_loss: 8411481600.0000 - val_mae: 68517.9062\n",
            "Epoch 266/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1193303040.0000 - mae: 21796.4785 - val_loss: 8405742592.0000 - val_mae: 68439.8203\n",
            "Epoch 267/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1064336512.0000 - mae: 20825.4551 - val_loss: 8430559744.0000 - val_mae: 68698.8281\n",
            "Epoch 268/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1367122560.0000 - mae: 22780.7422 - val_loss: 8427170816.0000 - val_mae: 68666.2422\n",
            "Epoch 269/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1190867200.0000 - mae: 21522.1895 - val_loss: 8416203776.0000 - val_mae: 68558.9688\n",
            "Epoch 270/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1566850944.0000 - mae: 23163.8906 - val_loss: 8424682496.0000 - val_mae: 68668.7734\n",
            "Epoch 271/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1123428608.0000 - mae: 21040.3906 - val_loss: 8402525696.0000 - val_mae: 68407.9453\n",
            "Epoch 272/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1108710528.0000 - mae: 21318.6934 - val_loss: 8410126848.0000 - val_mae: 68492.0469\n",
            "Epoch 273/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1387284096.0000 - mae: 22045.6445 - val_loss: 8421943296.0000 - val_mae: 68614.7422\n",
            "Epoch 274/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1544608768.0000 - mae: 22799.3281 - val_loss: 8431772160.0000 - val_mae: 68726.6719\n",
            "Epoch 275/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1130449280.0000 - mae: 21472.1953 - val_loss: 8423209984.0000 - val_mae: 68633.8906\n",
            "Epoch 276/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1220680960.0000 - mae: 22168.3535 - val_loss: 8421071360.0000 - val_mae: 68600.0234\n",
            "Epoch 277/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1650775552.0000 - mae: 22301.0059 - val_loss: 8427729920.0000 - val_mae: 68677.7266\n",
            "Epoch 278/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1190171264.0000 - mae: 21559.7637 - val_loss: 8415067136.0000 - val_mae: 68556.0625\n",
            "Epoch 279/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1157538560.0000 - mae: 20416.5938 - val_loss: 8409214976.0000 - val_mae: 68473.8359\n",
            "Epoch 280/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1065282240.0000 - mae: 21177.5918 - val_loss: 8397568000.0000 - val_mae: 68340.9922\n",
            "Epoch 281/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1104259328.0000 - mae: 20336.5312 - val_loss: 8436845056.0000 - val_mae: 68793.0156\n",
            "Epoch 282/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1187426048.0000 - mae: 21566.7910 - val_loss: 8417252352.0000 - val_mae: 68597.0156\n",
            "Epoch 283/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1312694784.0000 - mae: 21539.4180 - val_loss: 8404449792.0000 - val_mae: 68456.3359\n",
            "Epoch 284/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1334527232.0000 - mae: 20990.3066 - val_loss: 8415385600.0000 - val_mae: 68574.2031\n",
            "Epoch 285/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1697565184.0000 - mae: 23847.7012 - val_loss: 8414246400.0000 - val_mae: 68568.3984\n",
            "Epoch 286/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 963313344.0000 - mae: 19777.1172 - val_loss: 8413308928.0000 - val_mae: 68563.8125\n",
            "Epoch 287/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1142210560.0000 - mae: 21308.4922 - val_loss: 8431772672.0000 - val_mae: 68748.3125\n",
            "Epoch 288/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1146551936.0000 - mae: 21772.4746 - val_loss: 8428771328.0000 - val_mae: 68721.6875\n",
            "Epoch 289/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1296632576.0000 - mae: 22142.6484 - val_loss: 8414648832.0000 - val_mae: 68485.2422\n",
            "Epoch 290/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1427603200.0000 - mae: 22880.2188 - val_loss: 8421252608.0000 - val_mae: 68536.5469\n",
            "Epoch 291/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1314954112.0000 - mae: 22132.4590 - val_loss: 8418056704.0000 - val_mae: 68494.9609\n",
            "Epoch 292/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1417261184.0000 - mae: 22749.5332 - val_loss: 8412292096.0000 - val_mae: 68414.1797\n",
            "Epoch 293/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1248212608.0000 - mae: 21554.0430 - val_loss: 8424737280.0000 - val_mae: 68575.4219\n",
            "Epoch 294/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1193042304.0000 - mae: 21201.8535 - val_loss: 8406371328.0000 - val_mae: 68394.7344\n",
            "Epoch 295/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1494172928.0000 - mae: 22843.8770 - val_loss: 8424067072.0000 - val_mae: 68609.9688\n",
            "Epoch 296/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1134923392.0000 - mae: 22327.4258 - val_loss: 8420020736.0000 - val_mae: 68598.2812\n",
            "Epoch 297/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1055275328.0000 - mae: 20126.0156 - val_loss: 8427804672.0000 - val_mae: 68692.0078\n",
            "Epoch 298/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1474418048.0000 - mae: 22706.6797 - val_loss: 8437109760.0000 - val_mae: 68793.3047\n",
            "Epoch 299/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1564658048.0000 - mae: 22550.2227 - val_loss: 8475217920.0000 - val_mae: 69200.6172\n",
            "Epoch 300/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1294488320.0000 - mae: 22833.4551 - val_loss: 8422297600.0000 - val_mae: 68664.5234\n",
            "Epoch 301/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1456763264.0000 - mae: 22283.5410 - val_loss: 8407802880.0000 - val_mae: 68479.0000\n",
            "Epoch 302/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1194798592.0000 - mae: 21725.1367 - val_loss: 8418871808.0000 - val_mae: 68609.0078\n",
            "Epoch 303/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1305870080.0000 - mae: 22785.7852 - val_loss: 8415225856.0000 - val_mae: 68563.6406\n",
            "Epoch 304/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1290755712.0000 - mae: 22735.7637 - val_loss: 8426959360.0000 - val_mae: 68705.4219\n",
            "Epoch 305/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1103540480.0000 - mae: 20727.5918 - val_loss: 8421687808.0000 - val_mae: 68665.9922\n",
            "Epoch 306/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1176148864.0000 - mae: 21505.4746 - val_loss: 8430542336.0000 - val_mae: 68766.0234\n",
            "Epoch 307/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1290123648.0000 - mae: 21870.4141 - val_loss: 8430517248.0000 - val_mae: 68759.1328\n",
            "Epoch 308/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1215981184.0000 - mae: 22088.9297 - val_loss: 8425078784.0000 - val_mae: 68729.5469\n",
            "Epoch 309/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1321884032.0000 - mae: 21987.9160 - val_loss: 8415200768.0000 - val_mae: 68604.9219\n",
            "Epoch 310/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1494030208.0000 - mae: 22751.0957 - val_loss: 8428035072.0000 - val_mae: 68738.2891\n",
            "Epoch 311/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1114582912.0000 - mae: 20279.6523 - val_loss: 8427814400.0000 - val_mae: 68740.4219\n",
            "Epoch 312/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1121318144.0000 - mae: 20883.2520 - val_loss: 8425936384.0000 - val_mae: 68793.4375\n",
            "Epoch 313/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1076626816.0000 - mae: 20124.5059 - val_loss: 8419453440.0000 - val_mae: 68720.5625\n",
            "Epoch 314/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1164184192.0000 - mae: 20388.7871 - val_loss: 8420424704.0000 - val_mae: 68708.3594\n",
            "Epoch 315/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1065783488.0000 - mae: 20016.0781 - val_loss: 8423740928.0000 - val_mae: 68759.7500\n",
            "Epoch 316/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1423705856.0000 - mae: 23021.0039 - val_loss: 8444839424.0000 - val_mae: 69003.3125\n",
            "Epoch 317/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1140169600.0000 - mae: 21778.1914 - val_loss: 8434779136.0000 - val_mae: 68884.8438\n",
            "Epoch 318/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1030421248.0000 - mae: 20595.7344 - val_loss: 8433935360.0000 - val_mae: 68872.6172\n",
            "Epoch 319/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1367148288.0000 - mae: 21347.3828 - val_loss: 8422457856.0000 - val_mae: 68718.6953\n",
            "Epoch 320/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1240391168.0000 - mae: 21188.7402 - val_loss: 8432884736.0000 - val_mae: 68842.4844\n",
            "Epoch 321/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1186569984.0000 - mae: 21263.9688 - val_loss: 8429218304.0000 - val_mae: 68797.3203\n",
            "Epoch 322/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1342519936.0000 - mae: 22501.6641 - val_loss: 8436303360.0000 - val_mae: 68877.0703\n",
            "Epoch 323/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1189098368.0000 - mae: 22067.4629 - val_loss: 8431948288.0000 - val_mae: 68822.1016\n",
            "Epoch 324/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1432375808.0000 - mae: 21984.5176 - val_loss: 8434457600.0000 - val_mae: 68868.6094\n",
            "Epoch 325/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1418418432.0000 - mae: 22964.9473 - val_loss: 8424534528.0000 - val_mae: 68747.8672\n",
            "Epoch 326/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1637710208.0000 - mae: 22211.3125 - val_loss: 8431273984.0000 - val_mae: 68810.8984\n",
            "Epoch 327/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1183958144.0000 - mae: 21657.9785 - val_loss: 8423024128.0000 - val_mae: 68670.0078\n",
            "Epoch 328/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1393007616.0000 - mae: 22392.5000 - val_loss: 8431354880.0000 - val_mae: 68757.5703\n",
            "Epoch 329/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1314451712.0000 - mae: 21586.1152 - val_loss: 8450231808.0000 - val_mae: 68962.9844\n",
            "Epoch 330/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1391310336.0000 - mae: 23426.6836 - val_loss: 8426485760.0000 - val_mae: 68728.0156\n",
            "Epoch 331/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1152992256.0000 - mae: 21363.9980 - val_loss: 8431801344.0000 - val_mae: 68768.0625\n",
            "Epoch 332/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1080918272.0000 - mae: 20669.3965 - val_loss: 8431094272.0000 - val_mae: 68758.1484\n",
            "Epoch 333/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1146512640.0000 - mae: 21019.2539 - val_loss: 8443369472.0000 - val_mae: 68898.6641\n",
            "Epoch 334/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1394990720.0000 - mae: 23494.3652 - val_loss: 8442705920.0000 - val_mae: 68900.2344\n",
            "Epoch 335/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1059712512.0000 - mae: 20696.4277 - val_loss: 8438135296.0000 - val_mae: 68834.8828\n",
            "Epoch 336/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1357214208.0000 - mae: 22505.0254 - val_loss: 8457022464.0000 - val_mae: 69053.9375\n",
            "Epoch 337/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1625422848.0000 - mae: 23754.5215 - val_loss: 8446887424.0000 - val_mae: 68933.6797\n",
            "Epoch 338/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1319811072.0000 - mae: 20959.4141 - val_loss: 8430578176.0000 - val_mae: 68717.9219\n",
            "Epoch 339/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1065898560.0000 - mae: 20870.0059 - val_loss: 8434410496.0000 - val_mae: 68759.8203\n",
            "Epoch 340/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1364686080.0000 - mae: 21334.9590 - val_loss: 8463958016.0000 - val_mae: 69086.4141\n",
            "Epoch 341/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1301577344.0000 - mae: 22317.3125 - val_loss: 8467106304.0000 - val_mae: 69139.5625\n",
            "Epoch 342/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1335939328.0000 - mae: 21895.8555 - val_loss: 8454554112.0000 - val_mae: 69020.3047\n",
            "Epoch 343/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1270801536.0000 - mae: 21144.5898 - val_loss: 8449882112.0000 - val_mae: 68935.4531\n",
            "Epoch 344/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1281794688.0000 - mae: 20877.9355 - val_loss: 8444636160.0000 - val_mae: 68874.2109\n",
            "Epoch 345/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1520835328.0000 - mae: 22579.3965 - val_loss: 8448396800.0000 - val_mae: 68928.2266\n",
            "Epoch 346/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1065762816.0000 - mae: 19811.1699 - val_loss: 8441419264.0000 - val_mae: 68850.4844\n",
            "Epoch 347/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1378596480.0000 - mae: 21605.6250 - val_loss: 8439810560.0000 - val_mae: 68823.9609\n",
            "Epoch 348/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1160259712.0000 - mae: 21023.2598 - val_loss: 8436896256.0000 - val_mae: 68779.6406\n",
            "Epoch 349/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1159635712.0000 - mae: 20812.6348 - val_loss: 8450044928.0000 - val_mae: 68933.2500\n",
            "Epoch 350/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1133102848.0000 - mae: 21254.3789 - val_loss: 8448110592.0000 - val_mae: 68902.1484\n",
            "Epoch 351/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1230327424.0000 - mae: 20869.9688 - val_loss: 8450283520.0000 - val_mae: 68919.6562\n",
            "Epoch 352/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1299817728.0000 - mae: 22522.0996 - val_loss: 8445450752.0000 - val_mae: 68856.8906\n",
            "Epoch 353/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1410259200.0000 - mae: 21866.0762 - val_loss: 8452068352.0000 - val_mae: 68933.9688\n",
            "Epoch 354/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1359564672.0000 - mae: 21809.9004 - val_loss: 8450087936.0000 - val_mae: 68887.2422\n",
            "Epoch 355/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1211483392.0000 - mae: 21858.3477 - val_loss: 8451179520.0000 - val_mae: 68943.2734\n",
            "Epoch 356/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1194965504.0000 - mae: 22133.3711 - val_loss: 8484960768.0000 - val_mae: 69274.2500\n",
            "Epoch 357/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1450729216.0000 - mae: 22416.8086 - val_loss: 8484625408.0000 - val_mae: 69235.7188\n",
            "Epoch 358/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1241474176.0000 - mae: 22127.8926 - val_loss: 8466703360.0000 - val_mae: 69044.7422\n",
            "Epoch 359/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1124830976.0000 - mae: 20294.0625 - val_loss: 8469188608.0000 - val_mae: 69055.3359\n",
            "Epoch 360/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1199510272.0000 - mae: 21534.5566 - val_loss: 8465293824.0000 - val_mae: 69033.0000\n",
            "Epoch 361/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1333914240.0000 - mae: 21964.9082 - val_loss: 8463107072.0000 - val_mae: 69005.2422\n",
            "Epoch 362/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1384878080.0000 - mae: 21305.9570 - val_loss: 8456923136.0000 - val_mae: 68921.6328\n",
            "Epoch 363/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1317909504.0000 - mae: 21270.3301 - val_loss: 8464834048.0000 - val_mae: 69025.4375\n",
            "Epoch 364/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1514761088.0000 - mae: 22651.4844 - val_loss: 8469073408.0000 - val_mae: 69081.7500\n",
            "Epoch 365/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1116783232.0000 - mae: 20611.1875 - val_loss: 8456242176.0000 - val_mae: 68949.2812\n",
            "Epoch 366/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1259474688.0000 - mae: 21992.0273 - val_loss: 8452476416.0000 - val_mae: 68894.8438\n",
            "Epoch 367/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1249427328.0000 - mae: 21342.7930 - val_loss: 8455442944.0000 - val_mae: 68925.4531\n",
            "Epoch 368/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1206003840.0000 - mae: 20903.5840 - val_loss: 8454227456.0000 - val_mae: 68934.0625\n",
            "Epoch 369/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1528689024.0000 - mae: 22433.3008 - val_loss: 8454998016.0000 - val_mae: 68952.7109\n",
            "Epoch 370/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1699509504.0000 - mae: 22920.8906 - val_loss: 8456208384.0000 - val_mae: 69039.2656\n",
            "Epoch 371/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1240374528.0000 - mae: 21731.6602 - val_loss: 8442380288.0000 - val_mae: 68905.6953\n",
            "Epoch 372/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1353352832.0000 - mae: 21250.2656 - val_loss: 8449424896.0000 - val_mae: 69029.5625\n",
            "Epoch 373/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1240685952.0000 - mae: 22007.2168 - val_loss: 8445107200.0000 - val_mae: 68977.6172\n",
            "Epoch 374/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1651958912.0000 - mae: 22847.6719 - val_loss: 8440780800.0000 - val_mae: 68909.2422\n",
            "Epoch 375/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1009073344.0000 - mae: 19359.1074 - val_loss: 8441759744.0000 - val_mae: 68909.0391\n",
            "Epoch 376/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1100458368.0000 - mae: 20641.7109 - val_loss: 8458152448.0000 - val_mae: 69085.6484\n",
            "Epoch 377/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1286125696.0000 - mae: 21956.7031 - val_loss: 8446085120.0000 - val_mae: 68904.0312\n",
            "Epoch 378/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1669637504.0000 - mae: 23033.6406 - val_loss: 8438945792.0000 - val_mae: 68834.6641\n",
            "Epoch 379/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1254102656.0000 - mae: 21934.2344 - val_loss: 8440151040.0000 - val_mae: 68854.0859\n",
            "Epoch 380/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1091944320.0000 - mae: 20077.1309 - val_loss: 8431043584.0000 - val_mae: 68722.9531\n",
            "Epoch 381/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1161341312.0000 - mae: 21209.7148 - val_loss: 8442898432.0000 - val_mae: 68838.1406\n",
            "Epoch 382/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1122359680.0000 - mae: 21061.0840 - val_loss: 8457747968.0000 - val_mae: 69019.8047\n",
            "Epoch 383/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1171454720.0000 - mae: 20996.1934 - val_loss: 8460993536.0000 - val_mae: 69033.4609\n",
            "Epoch 384/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1377346944.0000 - mae: 22113.2988 - val_loss: 8447723520.0000 - val_mae: 68858.7891\n",
            "Epoch 385/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1314407040.0000 - mae: 20641.5879 - val_loss: 8451755008.0000 - val_mae: 68909.8359\n",
            "Epoch 386/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1534571648.0000 - mae: 22027.8418 - val_loss: 8460155904.0000 - val_mae: 69007.7500\n",
            "Epoch 387/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1347572224.0000 - mae: 20790.0332 - val_loss: 8470139904.0000 - val_mae: 69189.4375\n",
            "Epoch 388/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1181656960.0000 - mae: 21314.9062 - val_loss: 8437280256.0000 - val_mae: 68837.8281\n",
            "Epoch 389/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1398289152.0000 - mae: 21003.4219 - val_loss: 8455987712.0000 - val_mae: 69038.6797\n",
            "Epoch 390/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1431863296.0000 - mae: 21536.1680 - val_loss: 8454789632.0000 - val_mae: 69010.4844\n",
            "Epoch 391/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1447577472.0000 - mae: 21198.2734 - val_loss: 8449718272.0000 - val_mae: 68948.4531\n",
            "Epoch 392/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1236235648.0000 - mae: 22603.0762 - val_loss: 8435959808.0000 - val_mae: 68810.6719\n",
            "Epoch 393/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 992611200.0000 - mae: 20330.6992 - val_loss: 8442868736.0000 - val_mae: 68844.1406\n",
            "Epoch 394/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1091775744.0000 - mae: 20991.6719 - val_loss: 8461825024.0000 - val_mae: 69062.0781\n",
            "Epoch 395/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1011953984.0000 - mae: 19818.3262 - val_loss: 8457105408.0000 - val_mae: 69019.2188\n",
            "Epoch 396/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1056144512.0000 - mae: 20496.9141 - val_loss: 8457022976.0000 - val_mae: 68987.4062\n",
            "Epoch 397/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 973671872.0000 - mae: 18901.2012 - val_loss: 8472745472.0000 - val_mae: 69225.3359\n",
            "Epoch 398/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1226878208.0000 - mae: 21831.5215 - val_loss: 8472918016.0000 - val_mae: 69242.3594\n",
            "Epoch 399/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1395430784.0000 - mae: 22634.3164 - val_loss: 8461100544.0000 - val_mae: 69164.3359\n",
            "Epoch 400/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1154375296.0000 - mae: 20399.3770 - val_loss: 8448569856.0000 - val_mae: 69036.0312\n",
            "Epoch 401/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1419619328.0000 - mae: 23020.7500 - val_loss: 8441632256.0000 - val_mae: 68929.3984\n",
            "Epoch 402/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1378705664.0000 - mae: 21766.5527 - val_loss: 8449333248.0000 - val_mae: 69005.2812\n",
            "Epoch 403/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1246590720.0000 - mae: 21666.0254 - val_loss: 8451650048.0000 - val_mae: 69004.0156\n",
            "Epoch 404/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1246846336.0000 - mae: 21617.6270 - val_loss: 8451855360.0000 - val_mae: 68995.8594\n",
            "Epoch 405/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1483713280.0000 - mae: 23653.1953 - val_loss: 8446955008.0000 - val_mae: 68928.1719\n",
            "Epoch 406/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1086432768.0000 - mae: 19731.6074 - val_loss: 8455633920.0000 - val_mae: 69007.1328\n",
            "Epoch 407/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1637866496.0000 - mae: 23157.5137 - val_loss: 8467545600.0000 - val_mae: 69128.4141\n",
            "Epoch 408/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1563295616.0000 - mae: 23114.0312 - val_loss: 8467798528.0000 - val_mae: 69153.4141\n",
            "Epoch 409/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1195082752.0000 - mae: 21120.1953 - val_loss: 8478020096.0000 - val_mae: 69274.5234\n",
            "Epoch 410/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1533004160.0000 - mae: 23767.9102 - val_loss: 8472479232.0000 - val_mae: 69204.8672\n",
            "Epoch 411/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1196362368.0000 - mae: 22075.3379 - val_loss: 8453678080.0000 - val_mae: 69004.1016\n",
            "Epoch 412/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1059063680.0000 - mae: 20160.5703 - val_loss: 8448916992.0000 - val_mae: 68946.6328\n",
            "Epoch 413/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1110410496.0000 - mae: 20942.4668 - val_loss: 8444205568.0000 - val_mae: 68834.4297\n",
            "Epoch 414/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1229047552.0000 - mae: 20199.4844 - val_loss: 8462986240.0000 - val_mae: 69021.0312\n",
            "Epoch 415/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1105382656.0000 - mae: 21026.5410 - val_loss: 8464262656.0000 - val_mae: 69050.8984\n",
            "Epoch 416/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1446671232.0000 - mae: 22069.5430 - val_loss: 8454268416.0000 - val_mae: 68931.5234\n",
            "Epoch 417/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1178152832.0000 - mae: 21039.5449 - val_loss: 8461501952.0000 - val_mae: 69012.0938\n",
            "Epoch 418/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1267054464.0000 - mae: 21713.0879 - val_loss: 8465782784.0000 - val_mae: 69097.6953\n",
            "Epoch 419/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1275344896.0000 - mae: 21514.5293 - val_loss: 8464297984.0000 - val_mae: 69079.4531\n",
            "Epoch 420/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1459364352.0000 - mae: 22653.6602 - val_loss: 8466799104.0000 - val_mae: 69110.4141\n",
            "Epoch 421/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1192027008.0000 - mae: 22062.6758 - val_loss: 8455136256.0000 - val_mae: 68974.8359\n",
            "Epoch 422/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1436693760.0000 - mae: 22305.2383 - val_loss: 8460685824.0000 - val_mae: 69038.5391\n",
            "Epoch 423/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1416167936.0000 - mae: 21909.1270 - val_loss: 8460977664.0000 - val_mae: 69030.6172\n",
            "Epoch 424/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1371825920.0000 - mae: 22293.0195 - val_loss: 8464463872.0000 - val_mae: 69080.0703\n",
            "Epoch 425/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1270931200.0000 - mae: 21533.4512 - val_loss: 8461200896.0000 - val_mae: 69032.2656\n",
            "Epoch 426/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1709151232.0000 - mae: 23896.8574 - val_loss: 8453046784.0000 - val_mae: 68943.6406\n",
            "Epoch 427/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1147227776.0000 - mae: 20195.8086 - val_loss: 8459699200.0000 - val_mae: 69027.7891\n",
            "Epoch 428/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1253166336.0000 - mae: 21524.1426 - val_loss: 8471468544.0000 - val_mae: 69143.9062\n",
            "Epoch 429/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1687207296.0000 - mae: 22357.2930 - val_loss: 8463140352.0000 - val_mae: 69064.6797\n",
            "Epoch 430/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1108629120.0000 - mae: 20485.8008 - val_loss: 8447236096.0000 - val_mae: 68860.4844\n",
            "Epoch 431/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1195137408.0000 - mae: 21780.0684 - val_loss: 8451740672.0000 - val_mae: 68940.9922\n",
            "Epoch 432/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1000121280.0000 - mae: 19517.3223 - val_loss: 8468154368.0000 - val_mae: 69064.3984\n",
            "Epoch 433/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1103995648.0000 - mae: 20893.8086 - val_loss: 8464665600.0000 - val_mae: 68981.7031\n",
            "Epoch 434/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1222864640.0000 - mae: 20765.9590 - val_loss: 8473963008.0000 - val_mae: 69121.1094\n",
            "Epoch 435/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1286098816.0000 - mae: 21824.1816 - val_loss: 8475869184.0000 - val_mae: 69114.2500\n",
            "Epoch 436/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1259206784.0000 - mae: 21068.1758 - val_loss: 8475174912.0000 - val_mae: 69094.2422\n",
            "Epoch 437/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1115456640.0000 - mae: 20676.2461 - val_loss: 8467994624.0000 - val_mae: 68992.1797\n",
            "Epoch 438/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1293015168.0000 - mae: 22246.8145 - val_loss: 8466742272.0000 - val_mae: 68991.0000\n",
            "Epoch 439/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1162393984.0000 - mae: 21276.2598 - val_loss: 8469017600.0000 - val_mae: 68979.0938\n",
            "Epoch 440/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 951138944.0000 - mae: 19613.8457 - val_loss: 8473752576.0000 - val_mae: 69040.5469\n",
            "Epoch 441/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1576662144.0000 - mae: 21563.6738 - val_loss: 8469940224.0000 - val_mae: 69003.3516\n",
            "Epoch 442/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1183746944.0000 - mae: 20549.5996 - val_loss: 8473675776.0000 - val_mae: 68987.7969\n",
            "Epoch 443/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1536480896.0000 - mae: 21384.1875 - val_loss: 8493189632.0000 - val_mae: 69268.8438\n",
            "Epoch 444/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1097948928.0000 - mae: 20494.7012 - val_loss: 8489516544.0000 - val_mae: 69247.8516\n",
            "Epoch 445/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1452655616.0000 - mae: 21523.5840 - val_loss: 8478151168.0000 - val_mae: 69150.0000\n",
            "Epoch 446/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1474491392.0000 - mae: 21536.8027 - val_loss: 8470131712.0000 - val_mae: 69058.2266\n",
            "Epoch 447/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1227135488.0000 - mae: 21868.3516 - val_loss: 8467388416.0000 - val_mae: 69033.8672\n",
            "Epoch 448/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1585444352.0000 - mae: 21876.3457 - val_loss: 8487717888.0000 - val_mae: 69252.4219\n",
            "Epoch 449/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1230791808.0000 - mae: 20998.1758 - val_loss: 8479037952.0000 - val_mae: 69202.0156\n",
            "Epoch 450/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1310012288.0000 - mae: 21866.0176 - val_loss: 8478094336.0000 - val_mae: 69165.9922\n",
            "Epoch 451/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1158521728.0000 - mae: 20626.7227 - val_loss: 8476085248.0000 - val_mae: 69149.4219\n",
            "Epoch 452/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1422615552.0000 - mae: 22665.2148 - val_loss: 8470850048.0000 - val_mae: 69104.0078\n",
            "Epoch 453/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1329710336.0000 - mae: 20504.2285 - val_loss: 8468702720.0000 - val_mae: 69076.6172\n",
            "Epoch 454/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1344696320.0000 - mae: 22079.0020 - val_loss: 8460274688.0000 - val_mae: 68967.9609\n",
            "Epoch 455/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1206566784.0000 - mae: 21779.5195 - val_loss: 8455306752.0000 - val_mae: 68893.8672\n",
            "Epoch 456/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1286531712.0000 - mae: 21207.2070 - val_loss: 8477769728.0000 - val_mae: 69136.8672\n",
            "Epoch 457/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1260332800.0000 - mae: 21218.2441 - val_loss: 8473342976.0000 - val_mae: 69077.2109\n",
            "Epoch 458/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1221382656.0000 - mae: 20090.1172 - val_loss: 8472562176.0000 - val_mae: 69041.8359\n",
            "Epoch 459/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1452080128.0000 - mae: 23189.3438 - val_loss: 8473675776.0000 - val_mae: 69067.4062\n",
            "Epoch 460/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1403281024.0000 - mae: 22036.5605 - val_loss: 8472127488.0000 - val_mae: 69030.4844\n",
            "Epoch 461/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1486134400.0000 - mae: 22197.5762 - val_loss: 8485451264.0000 - val_mae: 69152.9688\n",
            "Epoch 462/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1112137984.0000 - mae: 20329.3203 - val_loss: 8472119808.0000 - val_mae: 69011.5781\n",
            "Epoch 463/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1223127936.0000 - mae: 21869.2949 - val_loss: 8480433664.0000 - val_mae: 69078.5000\n",
            "Epoch 464/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1290109568.0000 - mae: 22565.3770 - val_loss: 8487985664.0000 - val_mae: 69174.2734\n",
            "Epoch 465/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 976423936.0000 - mae: 19557.2383 - val_loss: 8485604352.0000 - val_mae: 69179.7656\n",
            "Epoch 466/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1105704832.0000 - mae: 20953.2812 - val_loss: 8485506048.0000 - val_mae: 69159.7031\n",
            "Epoch 467/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1267753216.0000 - mae: 21553.1719 - val_loss: 8496808448.0000 - val_mae: 69283.5938\n",
            "Epoch 468/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1578196480.0000 - mae: 21989.8887 - val_loss: 8485022208.0000 - val_mae: 69153.1094\n",
            "Epoch 469/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1947636608.0000 - mae: 24732.9004 - val_loss: 8484958720.0000 - val_mae: 69179.4531\n",
            "Epoch 470/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1616517760.0000 - mae: 23188.7402 - val_loss: 8483538944.0000 - val_mae: 69165.7422\n",
            "Epoch 471/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1471398144.0000 - mae: 21727.4629 - val_loss: 8487899136.0000 - val_mae: 69208.2266\n",
            "Epoch 472/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1094318720.0000 - mae: 20319.2578 - val_loss: 8481798144.0000 - val_mae: 69113.1328\n",
            "Epoch 473/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1003719360.0000 - mae: 20020.9922 - val_loss: 8474661888.0000 - val_mae: 69012.6172\n",
            "Epoch 474/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1700436352.0000 - mae: 22958.9512 - val_loss: 8491672064.0000 - val_mae: 69209.0391\n",
            "Epoch 475/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1221676288.0000 - mae: 19510.2227 - val_loss: 8498851840.0000 - val_mae: 69313.0938\n",
            "Epoch 476/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1077334016.0000 - mae: 20080.6426 - val_loss: 8492743680.0000 - val_mae: 69221.9766\n",
            "Epoch 477/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1063763648.0000 - mae: 20460.0391 - val_loss: 8502450688.0000 - val_mae: 69393.5938\n",
            "Epoch 478/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1152866432.0000 - mae: 20160.9219 - val_loss: 8495671808.0000 - val_mae: 69308.5234\n",
            "Epoch 479/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 932100224.0000 - mae: 19517.6230 - val_loss: 8497520128.0000 - val_mae: 69363.7578\n",
            "Epoch 480/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1202548736.0000 - mae: 21300.9531 - val_loss: 8494871040.0000 - val_mae: 69367.9453\n",
            "Epoch 481/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1052964416.0000 - mae: 20518.9648 - val_loss: 8493215232.0000 - val_mae: 69325.4297\n",
            "Epoch 482/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1373379328.0000 - mae: 22018.7891 - val_loss: 8489690112.0000 - val_mae: 69290.1328\n",
            "Epoch 483/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1438017152.0000 - mae: 21380.8379 - val_loss: 8488176640.0000 - val_mae: 69263.9375\n",
            "Epoch 484/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1104487680.0000 - mae: 20183.8613 - val_loss: 8492590592.0000 - val_mae: 69267.8047\n",
            "Epoch 485/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1066518528.0000 - mae: 20242.8809 - val_loss: 8495941632.0000 - val_mae: 69329.3672\n",
            "Epoch 486/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1228444928.0000 - mae: 21073.8398 - val_loss: 8496051200.0000 - val_mae: 69315.9844\n",
            "Epoch 487/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1256140160.0000 - mae: 22594.2031 - val_loss: 8492037632.0000 - val_mae: 69293.1953\n",
            "Epoch 488/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1848648960.0000 - mae: 23554.9746 - val_loss: 8496031232.0000 - val_mae: 69306.0234\n",
            "Epoch 489/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1612265600.0000 - mae: 21858.3984 - val_loss: 8488288256.0000 - val_mae: 69200.8672\n",
            "Epoch 490/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1120036864.0000 - mae: 20862.5840 - val_loss: 8494388224.0000 - val_mae: 69301.9922\n",
            "Epoch 491/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1246194944.0000 - mae: 20847.7070 - val_loss: 8496513024.0000 - val_mae: 69331.9766\n",
            "Epoch 492/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1376884096.0000 - mae: 21062.5176 - val_loss: 8491830272.0000 - val_mae: 69250.1562\n",
            "Epoch 493/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1453568896.0000 - mae: 21613.3047 - val_loss: 8488619008.0000 - val_mae: 69235.1562\n",
            "Epoch 494/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1139339520.0000 - mae: 20796.8516 - val_loss: 8480706560.0000 - val_mae: 69143.6797\n",
            "Epoch 495/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 912095168.0000 - mae: 18137.0977 - val_loss: 8488544768.0000 - val_mae: 69212.5391\n",
            "Epoch 496/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1196841472.0000 - mae: 19861.3301 - val_loss: 8506512384.0000 - val_mae: 69462.2812\n",
            "Epoch 497/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1062795200.0000 - mae: 20294.1680 - val_loss: 8481598464.0000 - val_mae: 69197.7266\n",
            "Epoch 498/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1382054784.0000 - mae: 22924.5625 - val_loss: 8475556352.0000 - val_mae: 69156.0234\n",
            "Epoch 499/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1194581504.0000 - mae: 20358.8555 - val_loss: 8481200640.0000 - val_mae: 69200.4766\n",
            "Epoch 500/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1522327680.0000 - mae: 21725.3262 - val_loss: 8479417856.0000 - val_mae: 69169.8906\n",
            "Epoch 501/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1427643008.0000 - mae: 21712.8066 - val_loss: 8491075584.0000 - val_mae: 69300.0234\n",
            "Epoch 502/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1080609408.0000 - mae: 19208.4414 - val_loss: 8491013120.0000 - val_mae: 69260.7656\n",
            "Epoch 503/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1146281472.0000 - mae: 20817.1250 - val_loss: 8493685248.0000 - val_mae: 69297.4531\n",
            "Epoch 504/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1237689728.0000 - mae: 22014.8066 - val_loss: 8533153792.0000 - val_mae: 69679.1328\n",
            "Epoch 505/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1117572992.0000 - mae: 20330.8906 - val_loss: 8497520128.0000 - val_mae: 69343.3594\n",
            "Epoch 506/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1188089088.0000 - mae: 21811.2305 - val_loss: 8483166208.0000 - val_mae: 69171.2734\n",
            "Epoch 507/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1749292160.0000 - mae: 22838.1445 - val_loss: 8492219392.0000 - val_mae: 69232.8594\n",
            "Epoch 508/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1045662976.0000 - mae: 19789.6270 - val_loss: 8493369344.0000 - val_mae: 69261.9453\n",
            "Epoch 509/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 935729280.0000 - mae: 18757.7422 - val_loss: 8484732416.0000 - val_mae: 69122.9219\n",
            "Epoch 510/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1340078976.0000 - mae: 20951.3652 - val_loss: 8485318656.0000 - val_mae: 69126.7891\n",
            "Epoch 511/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1194820864.0000 - mae: 20716.3203 - val_loss: 8483995136.0000 - val_mae: 69111.5781\n",
            "Epoch 512/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1388222720.0000 - mae: 22104.6758 - val_loss: 8495853056.0000 - val_mae: 69252.6016\n",
            "Epoch 513/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1066772416.0000 - mae: 19934.4219 - val_loss: 8492425728.0000 - val_mae: 69163.6875\n",
            "Epoch 514/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1381310976.0000 - mae: 22366.2305 - val_loss: 8515398144.0000 - val_mae: 69401.1328\n",
            "Epoch 515/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1165128320.0000 - mae: 21471.6680 - val_loss: 8503880704.0000 - val_mae: 69306.0078\n",
            "Epoch 516/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1274422912.0000 - mae: 20698.5918 - val_loss: 8498129408.0000 - val_mae: 69215.5547\n",
            "Epoch 517/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1178798976.0000 - mae: 20700.5547 - val_loss: 8497392640.0000 - val_mae: 69233.9062\n",
            "Epoch 518/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1007741440.0000 - mae: 20096.3516 - val_loss: 8496970752.0000 - val_mae: 69243.1094\n",
            "Epoch 519/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1076404992.0000 - mae: 20244.4609 - val_loss: 8503512576.0000 - val_mae: 69283.4531\n",
            "Epoch 520/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1253993984.0000 - mae: 20703.8359 - val_loss: 8512241664.0000 - val_mae: 69403.3984\n",
            "Epoch 521/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1155662976.0000 - mae: 20533.7422 - val_loss: 8506732032.0000 - val_mae: 69361.1484\n",
            "Epoch 522/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1100568704.0000 - mae: 20072.2148 - val_loss: 8486476288.0000 - val_mae: 69083.9531\n",
            "Epoch 523/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1234049280.0000 - mae: 20493.8613 - val_loss: 8495542784.0000 - val_mae: 69172.5234\n",
            "Epoch 524/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1508917248.0000 - mae: 20752.7871 - val_loss: 8503682048.0000 - val_mae: 69318.0859\n",
            "Epoch 525/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 928579840.0000 - mae: 18528.6758 - val_loss: 8509044224.0000 - val_mae: 69365.0000\n",
            "Epoch 526/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1349416192.0000 - mae: 21067.9492 - val_loss: 8490851328.0000 - val_mae: 69113.5234\n",
            "Epoch 527/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1252139008.0000 - mae: 20760.7871 - val_loss: 8487107584.0000 - val_mae: 69088.2109\n",
            "Epoch 528/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1431510144.0000 - mae: 23612.7949 - val_loss: 8498308096.0000 - val_mae: 69198.7266\n",
            "Epoch 529/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1170843904.0000 - mae: 20337.0859 - val_loss: 8502629888.0000 - val_mae: 69203.5938\n",
            "Epoch 530/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1389389056.0000 - mae: 22493.6992 - val_loss: 8506287616.0000 - val_mae: 69244.3438\n",
            "Epoch 531/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1092048768.0000 - mae: 20279.1250 - val_loss: 8515273216.0000 - val_mae: 69357.3906\n",
            "Epoch 532/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1322967296.0000 - mae: 21898.1328 - val_loss: 8504817152.0000 - val_mae: 69280.6641\n",
            "Epoch 533/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1324340864.0000 - mae: 21558.4453 - val_loss: 8495408640.0000 - val_mae: 69207.9688\n",
            "Epoch 534/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1272262016.0000 - mae: 22215.0254 - val_loss: 8501364224.0000 - val_mae: 69252.2109\n",
            "Epoch 535/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1200070784.0000 - mae: 20506.2969 - val_loss: 8506407424.0000 - val_mae: 69303.3516\n",
            "Epoch 536/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1081114368.0000 - mae: 19544.1602 - val_loss: 8487402496.0000 - val_mae: 69112.0703\n",
            "Epoch 537/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1100479872.0000 - mae: 20114.6992 - val_loss: 8501908992.0000 - val_mae: 69254.1953\n",
            "Epoch 538/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1109554816.0000 - mae: 20133.5312 - val_loss: 8494417920.0000 - val_mae: 69167.8672\n",
            "Epoch 539/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1747710592.0000 - mae: 23406.6895 - val_loss: 8503382528.0000 - val_mae: 69266.0547\n",
            "Epoch 540/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1529904384.0000 - mae: 21698.8887 - val_loss: 8497639936.0000 - val_mae: 69175.1094\n",
            "Epoch 541/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1340222080.0000 - mae: 21981.2266 - val_loss: 8498135040.0000 - val_mae: 69207.7109\n",
            "Epoch 542/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1249274240.0000 - mae: 21034.7305 - val_loss: 8498425344.0000 - val_mae: 69228.1484\n",
            "Epoch 543/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1012690496.0000 - mae: 19588.9824 - val_loss: 8485890048.0000 - val_mae: 69081.9922\n",
            "Epoch 544/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1717409920.0000 - mae: 23419.6445 - val_loss: 8492271104.0000 - val_mae: 69137.2734\n",
            "Epoch 545/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1234016256.0000 - mae: 20209.4570 - val_loss: 8498913792.0000 - val_mae: 69202.1094\n",
            "Epoch 546/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1189177472.0000 - mae: 20531.7012 - val_loss: 8506201600.0000 - val_mae: 69306.6484\n",
            "Epoch 547/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1183822592.0000 - mae: 19621.8340 - val_loss: 8499820544.0000 - val_mae: 69221.2578\n",
            "Epoch 548/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1052758784.0000 - mae: 20258.4082 - val_loss: 8492791296.0000 - val_mae: 69144.3828\n",
            "Epoch 549/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1520046848.0000 - mae: 22802.0781 - val_loss: 8503168512.0000 - val_mae: 69251.0625\n",
            "Epoch 550/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1271565184.0000 - mae: 20742.4316 - val_loss: 8501456896.0000 - val_mae: 69243.3984\n",
            "Epoch 551/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1266421632.0000 - mae: 21585.8652 - val_loss: 8497701376.0000 - val_mae: 69240.1172\n",
            "Epoch 552/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1288109952.0000 - mae: 22508.0938 - val_loss: 8485329408.0000 - val_mae: 69093.7266\n",
            "Epoch 553/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1290360448.0000 - mae: 21407.8242 - val_loss: 8490355712.0000 - val_mae: 69125.2422\n",
            "Epoch 554/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1261916544.0000 - mae: 21357.8828 - val_loss: 8499446784.0000 - val_mae: 69210.1562\n",
            "Epoch 555/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1144584320.0000 - mae: 20183.1777 - val_loss: 8496058368.0000 - val_mae: 69176.2578\n",
            "Epoch 556/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1192062848.0000 - mae: 20906.7988 - val_loss: 8498137600.0000 - val_mae: 69183.5781\n",
            "Epoch 557/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1014655872.0000 - mae: 19646.6504 - val_loss: 8500718080.0000 - val_mae: 69217.2969\n",
            "Epoch 558/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1388024832.0000 - mae: 21962.3203 - val_loss: 8504948224.0000 - val_mae: 69255.4062\n",
            "Epoch 559/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1072915136.0000 - mae: 19313.3496 - val_loss: 8494575616.0000 - val_mae: 69155.7031\n",
            "Epoch 560/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1028019264.0000 - mae: 19629.0254 - val_loss: 8497543168.0000 - val_mae: 69189.3359\n",
            "Epoch 561/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1191864320.0000 - mae: 20182.3457 - val_loss: 8492615680.0000 - val_mae: 69189.0391\n",
            "Epoch 562/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1267645568.0000 - mae: 21191.7246 - val_loss: 8508557824.0000 - val_mae: 69335.6641\n",
            "Epoch 563/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1336934784.0000 - mae: 21181.3438 - val_loss: 8504514560.0000 - val_mae: 69312.2344\n",
            "Epoch 564/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1243792256.0000 - mae: 21234.9160 - val_loss: 8493503488.0000 - val_mae: 69221.1094\n",
            "Epoch 565/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1167929728.0000 - mae: 20927.5703 - val_loss: 8494697984.0000 - val_mae: 69243.2969\n",
            "Epoch 566/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1165635072.0000 - mae: 19985.5098 - val_loss: 8502738944.0000 - val_mae: 69348.1484\n",
            "Epoch 567/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1023525056.0000 - mae: 20077.2598 - val_loss: 8515714560.0000 - val_mae: 69464.9531\n",
            "Epoch 568/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1118197888.0000 - mae: 20834.4609 - val_loss: 8500467200.0000 - val_mae: 69281.0312\n",
            "Epoch 569/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1058534592.0000 - mae: 19793.4141 - val_loss: 8490976768.0000 - val_mae: 69172.3125\n",
            "Epoch 570/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1243996544.0000 - mae: 22037.1758 - val_loss: 8498944000.0000 - val_mae: 69238.1719\n",
            "Epoch 571/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1220731904.0000 - mae: 20353.1758 - val_loss: 8506911744.0000 - val_mae: 69287.2812\n",
            "Epoch 572/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1097077248.0000 - mae: 20565.6094 - val_loss: 8513046016.0000 - val_mae: 69364.6641\n",
            "Epoch 573/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1471850368.0000 - mae: 21667.0879 - val_loss: 8520075264.0000 - val_mae: 69459.7031\n",
            "Epoch 574/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1115070976.0000 - mae: 20885.9160 - val_loss: 8505653248.0000 - val_mae: 69304.8281\n",
            "Epoch 575/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1181893248.0000 - mae: 19475.1211 - val_loss: 8508838912.0000 - val_mae: 69350.7109\n",
            "Epoch 576/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1008521280.0000 - mae: 19673.5488 - val_loss: 8508680192.0000 - val_mae: 69399.1484\n",
            "Epoch 577/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1218979712.0000 - mae: 21581.7773 - val_loss: 8499812864.0000 - val_mae: 69287.2578\n",
            "Epoch 578/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1385869056.0000 - mae: 21645.8965 - val_loss: 8514610688.0000 - val_mae: 69439.1953\n",
            "Epoch 579/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1494147840.0000 - mae: 22228.0469 - val_loss: 8511112704.0000 - val_mae: 69403.3672\n",
            "Epoch 580/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1391746560.0000 - mae: 22227.3184 - val_loss: 8526073856.0000 - val_mae: 69584.4297\n",
            "Epoch 581/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1170518656.0000 - mae: 20410.6953 - val_loss: 8496777216.0000 - val_mae: 69235.5000\n",
            "Epoch 582/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1126255360.0000 - mae: 20254.9219 - val_loss: 8495024128.0000 - val_mae: 69197.8203\n",
            "Epoch 583/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1929210624.0000 - mae: 25265.3887 - val_loss: 8518665216.0000 - val_mae: 69474.3359\n",
            "Epoch 584/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1088572544.0000 - mae: 19686.9102 - val_loss: 8502916608.0000 - val_mae: 69274.1094\n",
            "Epoch 585/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1188998272.0000 - mae: 20637.9258 - val_loss: 8511461888.0000 - val_mae: 69364.6953\n",
            "Epoch 586/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1247683072.0000 - mae: 21144.3203 - val_loss: 8518503424.0000 - val_mae: 69417.8594\n",
            "Epoch 587/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1366759424.0000 - mae: 21295.0762 - val_loss: 8518636544.0000 - val_mae: 69433.0781\n",
            "Epoch 588/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1063079872.0000 - mae: 20476.8574 - val_loss: 8511895040.0000 - val_mae: 69369.0625\n",
            "Epoch 589/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1445276928.0000 - mae: 21970.6230 - val_loss: 8524119040.0000 - val_mae: 69529.7188\n",
            "Epoch 590/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1245003008.0000 - mae: 21079.1660 - val_loss: 8520422912.0000 - val_mae: 69499.0234\n",
            "Epoch 591/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1216540032.0000 - mae: 20149.5410 - val_loss: 8507964928.0000 - val_mae: 69348.7578\n",
            "Epoch 592/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1380257920.0000 - mae: 21210.4766 - val_loss: 8509521920.0000 - val_mae: 69348.4297\n",
            "Epoch 593/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1232046336.0000 - mae: 20114.6836 - val_loss: 8513717248.0000 - val_mae: 69399.3281\n",
            "Epoch 594/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1106596352.0000 - mae: 20170.6172 - val_loss: 8508870656.0000 - val_mae: 69352.8203\n",
            "Epoch 595/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1047690560.0000 - mae: 20007.5566 - val_loss: 8491543040.0000 - val_mae: 69120.0000\n",
            "Epoch 596/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1211053952.0000 - mae: 21977.1836 - val_loss: 8493246976.0000 - val_mae: 69151.8125\n",
            "Epoch 597/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1153619712.0000 - mae: 19967.2090 - val_loss: 8513833472.0000 - val_mae: 69370.0781\n",
            "Epoch 598/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1552937088.0000 - mae: 22901.3848 - val_loss: 8533722624.0000 - val_mae: 69601.1953\n",
            "Epoch 599/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1152551168.0000 - mae: 20154.6738 - val_loss: 8514482176.0000 - val_mae: 69376.0234\n",
            "Epoch 600/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1350117760.0000 - mae: 21067.2383 - val_loss: 8517550080.0000 - val_mae: 69375.7266\n",
            "Epoch 601/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1176394496.0000 - mae: 19838.1348 - val_loss: 8528852992.0000 - val_mae: 69519.4531\n",
            "Epoch 602/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1034783552.0000 - mae: 19689.1113 - val_loss: 8519676928.0000 - val_mae: 69426.1094\n",
            "Epoch 603/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 875820672.0000 - mae: 18301.4648 - val_loss: 8533199872.0000 - val_mae: 69651.3359\n",
            "Epoch 604/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1232087936.0000 - mae: 20454.2773 - val_loss: 8527268864.0000 - val_mae: 69626.3594\n",
            "Epoch 605/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1053974720.0000 - mae: 19040.4531 - val_loss: 8495995904.0000 - val_mae: 69275.7812\n",
            "Epoch 606/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1032274752.0000 - mae: 19566.2500 - val_loss: 8498731520.0000 - val_mae: 69320.7969\n",
            "Epoch 607/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1397233152.0000 - mae: 21696.7734 - val_loss: 8499103744.0000 - val_mae: 69284.4219\n",
            "Epoch 608/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1320384384.0000 - mae: 20703.5137 - val_loss: 8495338496.0000 - val_mae: 69264.8672\n",
            "Epoch 609/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1235402496.0000 - mae: 21330.6152 - val_loss: 8496835584.0000 - val_mae: 69202.3828\n",
            "Epoch 610/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1200584704.0000 - mae: 19887.8887 - val_loss: 8511580160.0000 - val_mae: 69353.2812\n",
            "Epoch 611/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1372922496.0000 - mae: 21342.9023 - val_loss: 8513464832.0000 - val_mae: 69425.7656\n",
            "Epoch 612/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1256624640.0000 - mae: 19945.0781 - val_loss: 8511234560.0000 - val_mae: 69366.1172\n",
            "Epoch 613/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1329394944.0000 - mae: 21471.3789 - val_loss: 8512565248.0000 - val_mae: 69374.9375\n",
            "Epoch 614/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1496167552.0000 - mae: 21621.0840 - val_loss: 8508345856.0000 - val_mae: 69367.0547\n",
            "Epoch 615/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1243135232.0000 - mae: 21215.7676 - val_loss: 8509350912.0000 - val_mae: 69336.8203\n",
            "Epoch 616/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1448326400.0000 - mae: 21797.1719 - val_loss: 8504594944.0000 - val_mae: 69307.2578\n",
            "Epoch 617/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1076180864.0000 - mae: 20606.6016 - val_loss: 8503972352.0000 - val_mae: 69310.2891\n",
            "Epoch 618/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1310206080.0000 - mae: 21355.0078 - val_loss: 8510433792.0000 - val_mae: 69346.4844\n",
            "Epoch 619/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1324743552.0000 - mae: 20978.5215 - val_loss: 8509795328.0000 - val_mae: 69319.0078\n",
            "Epoch 620/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1080094336.0000 - mae: 20151.2109 - val_loss: 8512519168.0000 - val_mae: 69383.8516\n",
            "Epoch 621/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1465257344.0000 - mae: 20999.5195 - val_loss: 8519270400.0000 - val_mae: 69475.3438\n",
            "Epoch 622/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1190928896.0000 - mae: 19715.8770 - val_loss: 8506570752.0000 - val_mae: 69395.9844\n",
            "Epoch 623/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1186777216.0000 - mae: 20377.4121 - val_loss: 8489169920.0000 - val_mae: 69206.8984\n",
            "Epoch 624/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 949238144.0000 - mae: 19089.0859 - val_loss: 8501550592.0000 - val_mae: 69279.1094\n",
            "Epoch 625/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1057203008.0000 - mae: 19751.4941 - val_loss: 8499681792.0000 - val_mae: 69265.9375\n",
            "Epoch 626/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1457028352.0000 - mae: 21190.6562 - val_loss: 8503523328.0000 - val_mae: 69292.4844\n",
            "Epoch 627/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1029921024.0000 - mae: 19284.4941 - val_loss: 8509966336.0000 - val_mae: 69360.0938\n",
            "Epoch 628/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1138258304.0000 - mae: 20362.3223 - val_loss: 8515868160.0000 - val_mae: 69489.1953\n",
            "Epoch 629/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1126719360.0000 - mae: 20396.9141 - val_loss: 8509855744.0000 - val_mae: 69378.5469\n",
            "Epoch 630/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1477165440.0000 - mae: 21640.7461 - val_loss: 8508921344.0000 - val_mae: 69400.3438\n",
            "Epoch 631/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1196078592.0000 - mae: 20638.4141 - val_loss: 8512122368.0000 - val_mae: 69432.2422\n",
            "Epoch 632/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1076276608.0000 - mae: 19749.2930 - val_loss: 8491257344.0000 - val_mae: 69212.3906\n",
            "Epoch 633/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1127648128.0000 - mae: 20047.9180 - val_loss: 8503226368.0000 - val_mae: 69289.8594\n",
            "Epoch 634/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1310635648.0000 - mae: 22616.2637 - val_loss: 8502361600.0000 - val_mae: 69273.6328\n",
            "Epoch 635/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1381788928.0000 - mae: 21468.9219 - val_loss: 8514239488.0000 - val_mae: 69411.8828\n",
            "Epoch 636/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1067788288.0000 - mae: 18997.5898 - val_loss: 8509206528.0000 - val_mae: 69336.7891\n",
            "Epoch 637/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 916012736.0000 - mae: 18596.8848 - val_loss: 8499672576.0000 - val_mae: 69239.7109\n",
            "Epoch 638/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1107218560.0000 - mae: 20679.0195 - val_loss: 8517798400.0000 - val_mae: 69455.3516\n",
            "Epoch 639/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1114802176.0000 - mae: 20341.5391 - val_loss: 8511376896.0000 - val_mae: 69380.7734\n",
            "Epoch 640/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1116358144.0000 - mae: 19336.9570 - val_loss: 8530607616.0000 - val_mae: 69567.4531\n",
            "Epoch 641/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1302513536.0000 - mae: 21582.2207 - val_loss: 8511717376.0000 - val_mae: 69406.9766\n",
            "Epoch 642/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1144036352.0000 - mae: 19889.5039 - val_loss: 8507087360.0000 - val_mae: 69368.0000\n",
            "Epoch 643/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1539472384.0000 - mae: 21637.6641 - val_loss: 8506227200.0000 - val_mae: 69356.0859\n",
            "Epoch 644/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1411951616.0000 - mae: 22954.5332 - val_loss: 8509849600.0000 - val_mae: 69406.0156\n",
            "Epoch 645/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1201944064.0000 - mae: 19727.3301 - val_loss: 8489931264.0000 - val_mae: 69136.3672\n",
            "Epoch 646/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 959780672.0000 - mae: 19217.7754 - val_loss: 8490868224.0000 - val_mae: 69138.7266\n",
            "Epoch 647/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1210893952.0000 - mae: 20034.6699 - val_loss: 8497894400.0000 - val_mae: 69176.3906\n",
            "Epoch 648/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1120829184.0000 - mae: 20424.8145 - val_loss: 8504948224.0000 - val_mae: 69251.4844\n",
            "Epoch 649/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1115348864.0000 - mae: 19488.8906 - val_loss: 8513574400.0000 - val_mae: 69348.3359\n",
            "Epoch 650/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1270905216.0000 - mae: 21458.4004 - val_loss: 8533217792.0000 - val_mae: 69587.7578\n",
            "Epoch 651/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1218850560.0000 - mae: 21141.4258 - val_loss: 8518807552.0000 - val_mae: 69455.4766\n",
            "Epoch 652/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1228894720.0000 - mae: 21144.6621 - val_loss: 8499431424.0000 - val_mae: 69221.0391\n",
            "Epoch 653/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1230428032.0000 - mae: 21032.6289 - val_loss: 8495252992.0000 - val_mae: 69082.2734\n",
            "Epoch 654/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1248285184.0000 - mae: 20822.3789 - val_loss: 8513276416.0000 - val_mae: 69311.4922\n",
            "Epoch 655/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1155424640.0000 - mae: 19969.2168 - val_loss: 8503644672.0000 - val_mae: 69227.7188\n",
            "Epoch 656/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1144311936.0000 - mae: 19828.2148 - val_loss: 8501687296.0000 - val_mae: 69210.2656\n",
            "Epoch 657/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 984780800.0000 - mae: 18630.7617 - val_loss: 8493790208.0000 - val_mae: 69117.4844\n",
            "Epoch 658/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1018612352.0000 - mae: 19435.7969 - val_loss: 8504474624.0000 - val_mae: 69219.1406\n",
            "Epoch 659/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1011112448.0000 - mae: 19031.4219 - val_loss: 8508712960.0000 - val_mae: 69279.3672\n",
            "Epoch 660/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1187875840.0000 - mae: 20302.4961 - val_loss: 8511684608.0000 - val_mae: 69260.9766\n",
            "Epoch 661/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1211441152.0000 - mae: 20010.7148 - val_loss: 8522035200.0000 - val_mae: 69387.7812\n",
            "Epoch 662/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 941913216.0000 - mae: 18856.9316 - val_loss: 8504699904.0000 - val_mae: 69166.9531\n",
            "Epoch 663/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1156643840.0000 - mae: 19955.2148 - val_loss: 8512873472.0000 - val_mae: 69277.3203\n",
            "Epoch 664/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1189065472.0000 - mae: 20415.2910 - val_loss: 8512487424.0000 - val_mae: 69271.9062\n",
            "Epoch 665/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1289864320.0000 - mae: 20704.4160 - val_loss: 8508054528.0000 - val_mae: 69213.5938\n",
            "Epoch 666/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1245577344.0000 - mae: 20111.4238 - val_loss: 8515752960.0000 - val_mae: 69299.8125\n",
            "Epoch 667/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1048138944.0000 - mae: 19633.7383 - val_loss: 8497824768.0000 - val_mae: 69151.8359\n",
            "Epoch 668/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1221728000.0000 - mae: 20931.5723 - val_loss: 8500389376.0000 - val_mae: 69180.2031\n",
            "Epoch 669/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1234931840.0000 - mae: 20969.8105 - val_loss: 8508531712.0000 - val_mae: 69184.3984\n",
            "Epoch 670/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1232499968.0000 - mae: 20848.2715 - val_loss: 8516909568.0000 - val_mae: 69301.6016\n",
            "Epoch 671/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1596908160.0000 - mae: 21442.8164 - val_loss: 8512638976.0000 - val_mae: 69227.6562\n",
            "Epoch 672/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1001637504.0000 - mae: 19623.4023 - val_loss: 8515156992.0000 - val_mae: 69281.8906\n",
            "Epoch 673/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1054222208.0000 - mae: 19987.6797 - val_loss: 8521193472.0000 - val_mae: 69323.4531\n",
            "Epoch 674/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1150301696.0000 - mae: 20285.4668 - val_loss: 8522119168.0000 - val_mae: 69393.3516\n",
            "Epoch 675/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1227932672.0000 - mae: 20511.1074 - val_loss: 8530148352.0000 - val_mae: 69458.2266\n",
            "Epoch 676/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1112931328.0000 - mae: 19344.2285 - val_loss: 8514529280.0000 - val_mae: 69305.6094\n",
            "Epoch 677/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1086515584.0000 - mae: 19879.8438 - val_loss: 8514807296.0000 - val_mae: 69310.9531\n",
            "Epoch 678/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1419457024.0000 - mae: 20830.0176 - val_loss: 8518615552.0000 - val_mae: 69360.0000\n",
            "Epoch 679/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1456338816.0000 - mae: 22281.0293 - val_loss: 8513159680.0000 - val_mae: 69356.1328\n",
            "Epoch 680/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 876170112.0000 - mae: 18488.5547 - val_loss: 8510598144.0000 - val_mae: 69321.6953\n",
            "Epoch 681/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1286952448.0000 - mae: 21760.0176 - val_loss: 8515440128.0000 - val_mae: 69337.4844\n",
            "Epoch 682/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1383430656.0000 - mae: 20049.4941 - val_loss: 8520722944.0000 - val_mae: 69451.2266\n",
            "Epoch 683/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1187730304.0000 - mae: 19043.8145 - val_loss: 8516449792.0000 - val_mae: 69392.0312\n",
            "Epoch 684/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1105284864.0000 - mae: 20287.2344 - val_loss: 8511613952.0000 - val_mae: 69326.1484\n",
            "Epoch 685/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1350559616.0000 - mae: 20282.5488 - val_loss: 8518392832.0000 - val_mae: 69393.1094\n",
            "Epoch 686/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1110519936.0000 - mae: 20147.9121 - val_loss: 8509551616.0000 - val_mae: 69311.2344\n",
            "Epoch 687/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1385155840.0000 - mae: 20653.0117 - val_loss: 8517786624.0000 - val_mae: 69381.6953\n",
            "Epoch 688/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1180589952.0000 - mae: 20334.8945 - val_loss: 8513960448.0000 - val_mae: 69369.4609\n",
            "Epoch 689/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1190411520.0000 - mae: 20239.2637 - val_loss: 8511749120.0000 - val_mae: 69363.7812\n",
            "Epoch 690/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1671304960.0000 - mae: 21791.3066 - val_loss: 8514446336.0000 - val_mae: 69403.6406\n",
            "Epoch 691/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1466414464.0000 - mae: 21380.8496 - val_loss: 8516602880.0000 - val_mae: 69451.8516\n",
            "Epoch 692/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1043444288.0000 - mae: 18679.4336 - val_loss: 8512634880.0000 - val_mae: 69394.1953\n",
            "Epoch 693/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1338759552.0000 - mae: 21436.9355 - val_loss: 8513217024.0000 - val_mae: 69362.6875\n",
            "Epoch 694/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1248775040.0000 - mae: 20854.4395 - val_loss: 8507004928.0000 - val_mae: 69296.9062\n",
            "Epoch 695/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1027413824.0000 - mae: 19379.3223 - val_loss: 8502442496.0000 - val_mae: 69226.4688\n",
            "Epoch 696/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1617850496.0000 - mae: 21949.9355 - val_loss: 8506636288.0000 - val_mae: 69251.5000\n",
            "Epoch 697/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1233034496.0000 - mae: 20902.9336 - val_loss: 8505791488.0000 - val_mae: 69248.3047\n",
            "Epoch 698/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1263438080.0000 - mae: 20236.0898 - val_loss: 8504668160.0000 - val_mae: 69235.7578\n",
            "Epoch 699/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1116863616.0000 - mae: 19614.9727 - val_loss: 8514754048.0000 - val_mae: 69339.8984\n",
            "Epoch 700/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1076783232.0000 - mae: 19989.9766 - val_loss: 8517520384.0000 - val_mae: 69407.5625\n",
            "Epoch 701/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1033495936.0000 - mae: 19699.1934 - val_loss: 8541955072.0000 - val_mae: 69630.6797\n",
            "Epoch 702/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 903573888.0000 - mae: 18618.4141 - val_loss: 8522614272.0000 - val_mae: 69444.6016\n",
            "Epoch 703/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1228213376.0000 - mae: 20882.8555 - val_loss: 8510230016.0000 - val_mae: 69321.8516\n",
            "Epoch 704/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1589092352.0000 - mae: 21350.2227 - val_loss: 8515504128.0000 - val_mae: 69366.2266\n",
            "Epoch 705/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1151600896.0000 - mae: 18851.9707 - val_loss: 8507741696.0000 - val_mae: 69291.3203\n",
            "Epoch 706/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1067319232.0000 - mae: 19784.6680 - val_loss: 8512509952.0000 - val_mae: 69383.7969\n",
            "Epoch 707/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1088675328.0000 - mae: 19319.8184 - val_loss: 8512690688.0000 - val_mae: 69370.6094\n",
            "Epoch 708/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1122439424.0000 - mae: 20553.2734 - val_loss: 8507921920.0000 - val_mae: 69305.0625\n",
            "Epoch 709/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1094220544.0000 - mae: 19487.0195 - val_loss: 8523782144.0000 - val_mae: 69475.4688\n",
            "Epoch 710/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1576908800.0000 - mae: 22292.4121 - val_loss: 8521897984.0000 - val_mae: 69463.1875\n",
            "Epoch 711/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1022111936.0000 - mae: 19053.5117 - val_loss: 8514745856.0000 - val_mae: 69445.0625\n",
            "Epoch 712/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1051294912.0000 - mae: 19596.3242 - val_loss: 8512141312.0000 - val_mae: 69413.9141\n",
            "Epoch 713/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1077956480.0000 - mae: 19630.4980 - val_loss: 8495196160.0000 - val_mae: 69205.5781\n",
            "Epoch 714/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1164814720.0000 - mae: 19633.2891 - val_loss: 8501324800.0000 - val_mae: 69225.3672\n",
            "Epoch 715/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1405084672.0000 - mae: 21315.6777 - val_loss: 8507454464.0000 - val_mae: 69321.8281\n",
            "Epoch 716/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1188963456.0000 - mae: 19371.7871 - val_loss: 8498652672.0000 - val_mae: 69138.7812\n",
            "Epoch 717/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1190088192.0000 - mae: 20027.8672 - val_loss: 8503864832.0000 - val_mae: 69242.6641\n",
            "Epoch 718/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 938410880.0000 - mae: 18251.5723 - val_loss: 8498111488.0000 - val_mae: 69199.3828\n",
            "Epoch 719/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1154065152.0000 - mae: 20267.3477 - val_loss: 8499676672.0000 - val_mae: 69219.7656\n",
            "Epoch 720/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1358631296.0000 - mae: 20941.9375 - val_loss: 8511067136.0000 - val_mae: 69332.9922\n",
            "Epoch 721/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1281141760.0000 - mae: 19589.6094 - val_loss: 8502391808.0000 - val_mae: 69267.2891\n",
            "Epoch 722/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1111067904.0000 - mae: 19492.4707 - val_loss: 8494192640.0000 - val_mae: 69153.6094\n",
            "Epoch 723/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1193565440.0000 - mae: 19719.2773 - val_loss: 8500044800.0000 - val_mae: 69208.8203\n",
            "Epoch 724/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1180616960.0000 - mae: 19831.6504 - val_loss: 8514994688.0000 - val_mae: 69390.7578\n",
            "Epoch 725/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1148667520.0000 - mae: 20915.5410 - val_loss: 8516113408.0000 - val_mae: 69404.3047\n",
            "Epoch 726/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1421019008.0000 - mae: 20126.0117 - val_loss: 8542376448.0000 - val_mae: 69708.7734\n",
            "Epoch 727/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1156953344.0000 - mae: 19753.3438 - val_loss: 8517863936.0000 - val_mae: 69432.2891\n",
            "Epoch 728/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1079257472.0000 - mae: 19405.1172 - val_loss: 8511699456.0000 - val_mae: 69390.4375\n",
            "Epoch 729/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1073923968.0000 - mae: 19941.6895 - val_loss: 8500641280.0000 - val_mae: 69276.0312\n",
            "Epoch 730/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 958315968.0000 - mae: 19126.0840 - val_loss: 8499938304.0000 - val_mae: 69273.5312\n",
            "Epoch 731/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1113796480.0000 - mae: 19908.4297 - val_loss: 8503777280.0000 - val_mae: 69287.8281\n",
            "Epoch 732/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1070246080.0000 - mae: 20415.1641 - val_loss: 8503687168.0000 - val_mae: 69290.3203\n",
            "Epoch 733/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1192091520.0000 - mae: 20665.2090 - val_loss: 8512666624.0000 - val_mae: 69395.7500\n",
            "Epoch 734/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1154956928.0000 - mae: 19697.3984 - val_loss: 8514827264.0000 - val_mae: 69432.2500\n",
            "Epoch 735/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1286215296.0000 - mae: 20024.1035 - val_loss: 8504475648.0000 - val_mae: 69319.1328\n",
            "Epoch 736/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1090612352.0000 - mae: 19829.2852 - val_loss: 8501843456.0000 - val_mae: 69304.5391\n",
            "Epoch 737/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 998724352.0000 - mae: 20038.9746 - val_loss: 8499518464.0000 - val_mae: 69256.4375\n",
            "Epoch 738/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1134001536.0000 - mae: 20610.3086 - val_loss: 8500908544.0000 - val_mae: 69318.4297\n",
            "Epoch 739/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1141557760.0000 - mae: 20190.0645 - val_loss: 8505135104.0000 - val_mae: 69344.7422\n",
            "Epoch 740/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1128671360.0000 - mae: 18907.1875 - val_loss: 8502547456.0000 - val_mae: 69256.3359\n",
            "Epoch 741/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1142367360.0000 - mae: 19882.1309 - val_loss: 8486235648.0000 - val_mae: 69091.0312\n",
            "Epoch 742/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1191898240.0000 - mae: 20008.2637 - val_loss: 8500597248.0000 - val_mae: 69287.6172\n",
            "Epoch 743/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1047831872.0000 - mae: 19344.3691 - val_loss: 8511313920.0000 - val_mae: 69423.6484\n",
            "Epoch 744/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 993261184.0000 - mae: 19044.6426 - val_loss: 8491337728.0000 - val_mae: 69216.5234\n",
            "Epoch 745/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1253613184.0000 - mae: 21281.5547 - val_loss: 8499403776.0000 - val_mae: 69332.4531\n",
            "Epoch 746/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1393958272.0000 - mae: 19898.7207 - val_loss: 8501323776.0000 - val_mae: 69323.4531\n",
            "Epoch 747/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1058599872.0000 - mae: 19756.7812 - val_loss: 8515082752.0000 - val_mae: 69504.2109\n",
            "Epoch 748/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1086426624.0000 - mae: 18664.9180 - val_loss: 8510774272.0000 - val_mae: 69469.4062\n",
            "Epoch 749/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1184848256.0000 - mae: 19540.4414 - val_loss: 8515382784.0000 - val_mae: 69498.5391\n",
            "Epoch 750/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1144513920.0000 - mae: 19091.9336 - val_loss: 8506868224.0000 - val_mae: 69458.3828\n",
            "Epoch 751/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1310087936.0000 - mae: 20715.3438 - val_loss: 8489762816.0000 - val_mae: 69263.0000\n",
            "Epoch 752/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1102630400.0000 - mae: 19136.9727 - val_loss: 8490234880.0000 - val_mae: 69265.5625\n",
            "Epoch 753/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1146962944.0000 - mae: 20338.5762 - val_loss: 8494606336.0000 - val_mae: 69276.4531\n",
            "Epoch 754/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1174818944.0000 - mae: 20260.7559 - val_loss: 8508798976.0000 - val_mae: 69451.0078\n",
            "Epoch 755/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1167687168.0000 - mae: 20457.8418 - val_loss: 8496047104.0000 - val_mae: 69367.2266\n",
            "Epoch 756/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1429172736.0000 - mae: 21064.3398 - val_loss: 8496525824.0000 - val_mae: 69371.4531\n",
            "Epoch 757/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1050425792.0000 - mae: 19293.4414 - val_loss: 8494430720.0000 - val_mae: 69345.3672\n",
            "Epoch 758/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1244037120.0000 - mae: 20414.4824 - val_loss: 8491469824.0000 - val_mae: 69336.5547\n",
            "Epoch 759/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1094098816.0000 - mae: 19077.5234 - val_loss: 8489131008.0000 - val_mae: 69294.2578\n",
            "Epoch 760/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1055354816.0000 - mae: 20065.1602 - val_loss: 8489879040.0000 - val_mae: 69258.6797\n",
            "Epoch 761/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1103808128.0000 - mae: 19860.3379 - val_loss: 8489085952.0000 - val_mae: 69278.0156\n",
            "Epoch 762/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1692972928.0000 - mae: 22333.0527 - val_loss: 8510381056.0000 - val_mae: 69559.8047\n",
            "Epoch 763/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1253055616.0000 - mae: 20700.6699 - val_loss: 8478951424.0000 - val_mae: 69246.6719\n",
            "Epoch 764/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1064592768.0000 - mae: 20619.5840 - val_loss: 8473479168.0000 - val_mae: 69159.7266\n",
            "Epoch 765/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1351450496.0000 - mae: 19477.9062 - val_loss: 8483533312.0000 - val_mae: 69267.7578\n",
            "Epoch 766/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 973738112.0000 - mae: 19637.1973 - val_loss: 8491052544.0000 - val_mae: 69387.7109\n",
            "Epoch 767/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1031156032.0000 - mae: 19817.4941 - val_loss: 8509998592.0000 - val_mae: 69603.1406\n",
            "Epoch 768/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1051500160.0000 - mae: 19602.9355 - val_loss: 8501219328.0000 - val_mae: 69556.8438\n",
            "Epoch 769/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1076248704.0000 - mae: 19754.3535 - val_loss: 8476563456.0000 - val_mae: 69353.3828\n",
            "Epoch 770/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1211848064.0000 - mae: 20085.7656 - val_loss: 8483989504.0000 - val_mae: 69438.9688\n",
            "Epoch 771/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1299096064.0000 - mae: 19889.8125 - val_loss: 8482207232.0000 - val_mae: 69414.1484\n",
            "Epoch 772/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 939190208.0000 - mae: 18281.1387 - val_loss: 8474542592.0000 - val_mae: 69318.2812\n",
            "Epoch 773/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1328387456.0000 - mae: 20818.3789 - val_loss: 8487982592.0000 - val_mae: 69438.6562\n",
            "Epoch 774/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 947547584.0000 - mae: 18977.2969 - val_loss: 8482230272.0000 - val_mae: 69366.0000\n",
            "Epoch 775/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 982543552.0000 - mae: 18804.5332 - val_loss: 8487704576.0000 - val_mae: 69411.3438\n",
            "Epoch 776/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 954724352.0000 - mae: 18297.2969 - val_loss: 8488882176.0000 - val_mae: 69448.2266\n",
            "Epoch 777/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1101007488.0000 - mae: 19101.8145 - val_loss: 8487539712.0000 - val_mae: 69446.0000\n",
            "Epoch 778/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1338962432.0000 - mae: 20049.5801 - val_loss: 8490670592.0000 - val_mae: 69489.9297\n",
            "Epoch 779/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1105404160.0000 - mae: 20086.8613 - val_loss: 8473883136.0000 - val_mae: 69302.4297\n",
            "Epoch 780/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1274613760.0000 - mae: 20417.7539 - val_loss: 8482161664.0000 - val_mae: 69373.1016\n",
            "Epoch 781/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1051206528.0000 - mae: 19184.2109 - val_loss: 8482610688.0000 - val_mae: 69379.8203\n",
            "Epoch 782/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1205229952.0000 - mae: 19827.0156 - val_loss: 8483739136.0000 - val_mae: 69463.9844\n",
            "Epoch 783/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1119711616.0000 - mae: 19617.3711 - val_loss: 8478209536.0000 - val_mae: 69410.6641\n",
            "Epoch 784/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1273485824.0000 - mae: 21012.7598 - val_loss: 8480238080.0000 - val_mae: 69414.5469\n",
            "Epoch 785/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1389214720.0000 - mae: 20923.5488 - val_loss: 8482513408.0000 - val_mae: 69447.3906\n",
            "Epoch 786/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1321197312.0000 - mae: 20075.1055 - val_loss: 8481181696.0000 - val_mae: 69381.6797\n",
            "Epoch 787/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1193334144.0000 - mae: 19479.1172 - val_loss: 8484971008.0000 - val_mae: 69444.2266\n",
            "Epoch 788/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1136941696.0000 - mae: 19989.3750 - val_loss: 8479010816.0000 - val_mae: 69381.5625\n",
            "Epoch 789/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1093646592.0000 - mae: 19509.6172 - val_loss: 8479698944.0000 - val_mae: 69431.6328\n",
            "Epoch 790/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 980235200.0000 - mae: 19463.6543 - val_loss: 8480812032.0000 - val_mae: 69462.9219\n",
            "Epoch 791/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 949809408.0000 - mae: 19337.6836 - val_loss: 8465040896.0000 - val_mae: 69289.5000\n",
            "Epoch 792/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1456181760.0000 - mae: 20742.1914 - val_loss: 8472747520.0000 - val_mae: 69388.9375\n",
            "Epoch 793/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1329750400.0000 - mae: 20467.3633 - val_loss: 8475596288.0000 - val_mae: 69391.7031\n",
            "Epoch 794/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1256580224.0000 - mae: 20278.3652 - val_loss: 8470048256.0000 - val_mae: 69365.2891\n",
            "Epoch 795/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1259522688.0000 - mae: 19667.8789 - val_loss: 8469218304.0000 - val_mae: 69358.1953\n",
            "Epoch 796/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1158401152.0000 - mae: 18284.8555 - val_loss: 8465652736.0000 - val_mae: 69265.3359\n",
            "Epoch 797/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1312577280.0000 - mae: 20677.6641 - val_loss: 8458552832.0000 - val_mae: 69204.1953\n",
            "Epoch 798/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1530221952.0000 - mae: 21313.7637 - val_loss: 8464182272.0000 - val_mae: 69262.8438\n",
            "Epoch 799/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1050189184.0000 - mae: 19271.4414 - val_loss: 8464566272.0000 - val_mae: 69275.5547\n",
            "Epoch 800/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1191287168.0000 - mae: 19780.5703 - val_loss: 8480916480.0000 - val_mae: 69481.7109\n",
            "Epoch 801/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1045836608.0000 - mae: 18870.9766 - val_loss: 8470095872.0000 - val_mae: 69362.9062\n",
            "Epoch 802/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1271028992.0000 - mae: 20312.5332 - val_loss: 8472912384.0000 - val_mae: 69414.9062\n",
            "Epoch 803/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1002062144.0000 - mae: 19001.8008 - val_loss: 8459122688.0000 - val_mae: 69267.1719\n",
            "Epoch 804/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 903995904.0000 - mae: 18183.8535 - val_loss: 8460327936.0000 - val_mae: 69291.6094\n",
            "Epoch 805/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1315867648.0000 - mae: 19782.4824 - val_loss: 8470697984.0000 - val_mae: 69418.0156\n",
            "Epoch 806/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1245723520.0000 - mae: 20273.1680 - val_loss: 8463519744.0000 - val_mae: 69390.7031\n",
            "Epoch 807/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1207696000.0000 - mae: 21137.2461 - val_loss: 8450156032.0000 - val_mae: 69238.5391\n",
            "Epoch 808/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1249690240.0000 - mae: 20787.4004 - val_loss: 8459529216.0000 - val_mae: 69360.6641\n",
            "Epoch 809/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1156526592.0000 - mae: 20048.3418 - val_loss: 8465381376.0000 - val_mae: 69454.3203\n",
            "Epoch 810/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1175175168.0000 - mae: 20128.0645 - val_loss: 8452547072.0000 - val_mae: 69328.7266\n",
            "Epoch 811/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1233141120.0000 - mae: 20398.6855 - val_loss: 8451115008.0000 - val_mae: 69325.3516\n",
            "Epoch 812/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1065509056.0000 - mae: 19250.5391 - val_loss: 8461915136.0000 - val_mae: 69420.2109\n",
            "Epoch 813/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1177924736.0000 - mae: 18918.4668 - val_loss: 8445390848.0000 - val_mae: 69249.8516\n",
            "Epoch 814/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1010451648.0000 - mae: 18651.1484 - val_loss: 8444579840.0000 - val_mae: 69259.4531\n",
            "Epoch 815/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1220901888.0000 - mae: 20809.5742 - val_loss: 8449316864.0000 - val_mae: 69320.5625\n",
            "Epoch 816/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1054139200.0000 - mae: 18843.3398 - val_loss: 8447554560.0000 - val_mae: 69320.8438\n",
            "Epoch 817/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1040124608.0000 - mae: 18947.6074 - val_loss: 8437442048.0000 - val_mae: 69210.5156\n",
            "Epoch 818/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1007472640.0000 - mae: 18456.8867 - val_loss: 8444993024.0000 - val_mae: 69279.2969\n",
            "Epoch 819/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1121261696.0000 - mae: 19145.0977 - val_loss: 8441462272.0000 - val_mae: 69273.8672\n",
            "Epoch 820/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1138689920.0000 - mae: 19790.7930 - val_loss: 8451960832.0000 - val_mae: 69372.5000\n",
            "Epoch 821/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1288301440.0000 - mae: 19993.8281 - val_loss: 8448201728.0000 - val_mae: 69337.5156\n",
            "Epoch 822/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1303478784.0000 - mae: 19896.1309 - val_loss: 8428035072.0000 - val_mae: 69121.0156\n",
            "Epoch 823/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1554589440.0000 - mae: 21927.6035 - val_loss: 8427798528.0000 - val_mae: 69139.7734\n",
            "Epoch 824/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1179886336.0000 - mae: 19866.5391 - val_loss: 8416022016.0000 - val_mae: 68959.8047\n",
            "Epoch 825/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1173986048.0000 - mae: 20769.7168 - val_loss: 8422724608.0000 - val_mae: 69106.9453\n",
            "Epoch 826/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1011554176.0000 - mae: 18879.8223 - val_loss: 8430577664.0000 - val_mae: 69203.2422\n",
            "Epoch 827/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1085800960.0000 - mae: 19154.4727 - val_loss: 8433057792.0000 - val_mae: 69256.0547\n",
            "Epoch 828/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1209347840.0000 - mae: 19634.9238 - val_loss: 8419515392.0000 - val_mae: 69110.4531\n",
            "Epoch 829/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1324726784.0000 - mae: 20480.3906 - val_loss: 8419496448.0000 - val_mae: 69087.9062\n",
            "Epoch 830/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1013100608.0000 - mae: 18721.6777 - val_loss: 8419490304.0000 - val_mae: 69116.1406\n",
            "Epoch 831/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1106244608.0000 - mae: 19825.2266 - val_loss: 8422168576.0000 - val_mae: 69133.5312\n",
            "Epoch 832/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 875060672.0000 - mae: 17808.0410 - val_loss: 8409636352.0000 - val_mae: 69009.1094\n",
            "Epoch 833/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1179936256.0000 - mae: 19851.0000 - val_loss: 8426161152.0000 - val_mae: 69225.6094\n",
            "Epoch 834/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1578565248.0000 - mae: 21386.3652 - val_loss: 8439236608.0000 - val_mae: 69406.7578\n",
            "Epoch 835/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1263209472.0000 - mae: 20242.5137 - val_loss: 8419537920.0000 - val_mae: 69227.3203\n",
            "Epoch 836/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 870064384.0000 - mae: 17982.1055 - val_loss: 8409191424.0000 - val_mae: 69112.5156\n",
            "Epoch 837/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1287242368.0000 - mae: 20040.5137 - val_loss: 8422508032.0000 - val_mae: 69320.5859\n",
            "Epoch 838/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1293338496.0000 - mae: 19554.6270 - val_loss: 8433626112.0000 - val_mae: 69466.1328\n",
            "Epoch 839/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 995080640.0000 - mae: 17777.7344 - val_loss: 8428554240.0000 - val_mae: 69424.8438\n",
            "Epoch 840/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1260409344.0000 - mae: 20164.4238 - val_loss: 8413133824.0000 - val_mae: 69263.6484\n",
            "Epoch 841/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1063653632.0000 - mae: 19152.7617 - val_loss: 8408119808.0000 - val_mae: 69234.3203\n",
            "Epoch 842/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1057341952.0000 - mae: 19473.6777 - val_loss: 8407932416.0000 - val_mae: 69229.2578\n",
            "Epoch 843/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1075070464.0000 - mae: 20185.5586 - val_loss: 8396453888.0000 - val_mae: 69074.1953\n",
            "Epoch 844/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1051222080.0000 - mae: 19271.0156 - val_loss: 8421984768.0000 - val_mae: 69342.1484\n",
            "Epoch 845/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1004987264.0000 - mae: 19164.1738 - val_loss: 8411074048.0000 - val_mae: 69239.1797\n",
            "Epoch 846/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1011202240.0000 - mae: 19144.4883 - val_loss: 8394651648.0000 - val_mae: 69046.6406\n",
            "Epoch 847/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1187154688.0000 - mae: 19906.2715 - val_loss: 8399965696.0000 - val_mae: 69103.4688\n",
            "Epoch 848/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1153312896.0000 - mae: 20364.3262 - val_loss: 8402428928.0000 - val_mae: 69124.3516\n",
            "Epoch 849/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 928084032.0000 - mae: 17881.1094 - val_loss: 8400574976.0000 - val_mae: 69142.2578\n",
            "Epoch 850/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1189199872.0000 - mae: 21596.3125 - val_loss: 8400353280.0000 - val_mae: 69162.1328\n",
            "Epoch 851/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1060509952.0000 - mae: 19353.5527 - val_loss: 8387726336.0000 - val_mae: 69045.1953\n",
            "Epoch 852/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1139519104.0000 - mae: 19742.2188 - val_loss: 8395506176.0000 - val_mae: 69141.2422\n",
            "Epoch 853/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1003171456.0000 - mae: 19264.6992 - val_loss: 8383171584.0000 - val_mae: 68983.4375\n",
            "Epoch 854/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1557872384.0000 - mae: 20938.8965 - val_loss: 8400473088.0000 - val_mae: 69191.3125\n",
            "Epoch 855/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1240098304.0000 - mae: 20056.0859 - val_loss: 8397686784.0000 - val_mae: 69183.3984\n",
            "Epoch 856/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1001205376.0000 - mae: 19566.3828 - val_loss: 8391034880.0000 - val_mae: 69177.3438\n",
            "Epoch 857/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 864471552.0000 - mae: 18635.4902 - val_loss: 8395234304.0000 - val_mae: 69223.4062\n",
            "Epoch 858/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 940081280.0000 - mae: 18072.8477 - val_loss: 8381618176.0000 - val_mae: 69074.5703\n",
            "Epoch 859/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1394923520.0000 - mae: 22178.6504 - val_loss: 8384411648.0000 - val_mae: 69065.9453\n",
            "Epoch 860/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1026333120.0000 - mae: 18790.5352 - val_loss: 8381917696.0000 - val_mae: 69010.8203\n",
            "Epoch 861/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1397747712.0000 - mae: 20239.5898 - val_loss: 8396209152.0000 - val_mae: 69139.9297\n",
            "Epoch 862/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1100996096.0000 - mae: 18855.7656 - val_loss: 8391209472.0000 - val_mae: 69127.7734\n",
            "Epoch 863/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1389700736.0000 - mae: 21242.3008 - val_loss: 8389950464.0000 - val_mae: 69129.3203\n",
            "Epoch 864/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1070045440.0000 - mae: 18294.7422 - val_loss: 8383610880.0000 - val_mae: 69060.4531\n",
            "Epoch 865/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1042071104.0000 - mae: 19817.1758 - val_loss: 8376247296.0000 - val_mae: 68951.8438\n",
            "Epoch 866/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1249409280.0000 - mae: 20184.8965 - val_loss: 8388143616.0000 - val_mae: 69127.4453\n",
            "Epoch 867/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1180434688.0000 - mae: 18791.8906 - val_loss: 8379057664.0000 - val_mae: 69026.2969\n",
            "Epoch 868/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1421263104.0000 - mae: 20234.6113 - val_loss: 8378459648.0000 - val_mae: 68998.1875\n",
            "Epoch 869/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 970017024.0000 - mae: 18273.8203 - val_loss: 8380969984.0000 - val_mae: 69046.8828\n",
            "Epoch 870/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1347746304.0000 - mae: 20875.7617 - val_loss: 8374979584.0000 - val_mae: 69016.7422\n",
            "Epoch 871/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1458767232.0000 - mae: 20522.4746 - val_loss: 8384077312.0000 - val_mae: 69110.5391\n",
            "Epoch 872/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 902323008.0000 - mae: 18309.2871 - val_loss: 8371556864.0000 - val_mae: 69015.4844\n",
            "Epoch 873/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 981426176.0000 - mae: 17993.1836 - val_loss: 8384137728.0000 - val_mae: 69187.4844\n",
            "Epoch 874/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1371625728.0000 - mae: 20338.5625 - val_loss: 8378194944.0000 - val_mae: 69122.1172\n",
            "Epoch 875/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1031653824.0000 - mae: 19458.5508 - val_loss: 8366073856.0000 - val_mae: 68994.4688\n",
            "Epoch 876/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1038531456.0000 - mae: 18729.4863 - val_loss: 8368169472.0000 - val_mae: 69035.4844\n",
            "Epoch 877/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 982732864.0000 - mae: 18422.7969 - val_loss: 8365978112.0000 - val_mae: 69033.2266\n",
            "Epoch 878/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1183831424.0000 - mae: 19726.4863 - val_loss: 8364816384.0000 - val_mae: 69043.6562\n",
            "Epoch 879/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1236337792.0000 - mae: 19431.5195 - val_loss: 8361930752.0000 - val_mae: 69005.8438\n",
            "Epoch 880/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1278748672.0000 - mae: 19343.6055 - val_loss: 8363570176.0000 - val_mae: 69104.2656\n",
            "Epoch 881/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1419336192.0000 - mae: 20300.2617 - val_loss: 8364983296.0000 - val_mae: 69123.3984\n",
            "Epoch 882/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1036557440.0000 - mae: 19589.3613 - val_loss: 8350192128.0000 - val_mae: 68946.8906\n",
            "Epoch 883/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1047165376.0000 - mae: 18947.3164 - val_loss: 8361273344.0000 - val_mae: 69061.4141\n",
            "Epoch 884/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1055971904.0000 - mae: 19614.3125 - val_loss: 8355389952.0000 - val_mae: 69014.6797\n",
            "Epoch 885/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1051832576.0000 - mae: 17718.0527 - val_loss: 8363900416.0000 - val_mae: 69072.9297\n",
            "Epoch 886/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1020642368.0000 - mae: 18622.2461 - val_loss: 8352652800.0000 - val_mae: 68909.0469\n",
            "Epoch 887/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1062465792.0000 - mae: 17971.4727 - val_loss: 8360298496.0000 - val_mae: 69000.2188\n",
            "Epoch 888/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1538577408.0000 - mae: 21104.2383 - val_loss: 8360513024.0000 - val_mae: 69015.7812\n",
            "Epoch 889/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 942357120.0000 - mae: 17963.2148 - val_loss: 8353096192.0000 - val_mae: 68925.6484\n",
            "Epoch 890/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1226822272.0000 - mae: 19729.4062 - val_loss: 8354091520.0000 - val_mae: 68965.6406\n",
            "Epoch 891/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 996230912.0000 - mae: 18587.6133 - val_loss: 8327623680.0000 - val_mae: 68674.6484\n",
            "Epoch 892/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1002834368.0000 - mae: 18273.7070 - val_loss: 8345199104.0000 - val_mae: 68842.3594\n",
            "Epoch 893/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 944723584.0000 - mae: 18405.5918 - val_loss: 8347245056.0000 - val_mae: 68877.6328\n",
            "Epoch 894/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1197697280.0000 - mae: 20206.0039 - val_loss: 8359248384.0000 - val_mae: 69052.4219\n",
            "Epoch 895/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1004602944.0000 - mae: 18663.8379 - val_loss: 8357727744.0000 - val_mae: 69107.7734\n",
            "Epoch 896/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1011818688.0000 - mae: 18578.1016 - val_loss: 8344745472.0000 - val_mae: 68931.4062\n",
            "Epoch 897/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1053040128.0000 - mae: 18718.5566 - val_loss: 8340279296.0000 - val_mae: 68871.5391\n",
            "Epoch 898/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 880062656.0000 - mae: 16857.4766 - val_loss: 8341936640.0000 - val_mae: 68843.7422\n",
            "Epoch 899/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1146309760.0000 - mae: 18907.9805 - val_loss: 8354608640.0000 - val_mae: 69050.2188\n",
            "Epoch 900/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 952269120.0000 - mae: 18500.3359 - val_loss: 8355661312.0000 - val_mae: 69076.7656\n",
            "Epoch 901/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1096157952.0000 - mae: 18979.6133 - val_loss: 8377813504.0000 - val_mae: 69299.0000\n",
            "Epoch 902/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 974165632.0000 - mae: 18391.0430 - val_loss: 8346322432.0000 - val_mae: 69014.0547\n",
            "Epoch 903/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1042334336.0000 - mae: 19505.6113 - val_loss: 8325807104.0000 - val_mae: 68791.9141\n",
            "Epoch 904/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1114055936.0000 - mae: 19503.6953 - val_loss: 8338840576.0000 - val_mae: 68913.2656\n",
            "Epoch 905/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 958228672.0000 - mae: 19112.9863 - val_loss: 8336361984.0000 - val_mae: 68917.4141\n",
            "Epoch 906/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1531952256.0000 - mae: 20508.0898 - val_loss: 8321162752.0000 - val_mae: 68752.0781\n",
            "Epoch 907/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 959896576.0000 - mae: 18811.0898 - val_loss: 8322208256.0000 - val_mae: 68741.6797\n",
            "Epoch 908/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1023185984.0000 - mae: 18659.9590 - val_loss: 8326804480.0000 - val_mae: 68744.1562\n",
            "Epoch 909/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1135350656.0000 - mae: 19697.3594 - val_loss: 8343032832.0000 - val_mae: 68946.9766\n",
            "Epoch 910/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1225936640.0000 - mae: 19573.3203 - val_loss: 8346104832.0000 - val_mae: 68995.9141\n",
            "Epoch 911/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1122926208.0000 - mae: 19276.3340 - val_loss: 8329398272.0000 - val_mae: 68852.7734\n",
            "Epoch 912/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 954862976.0000 - mae: 18579.8086 - val_loss: 8327052800.0000 - val_mae: 68820.4531\n",
            "Epoch 913/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1242577792.0000 - mae: 19717.3262 - val_loss: 8331582464.0000 - val_mae: 68945.7578\n",
            "Epoch 914/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1116882688.0000 - mae: 19637.0312 - val_loss: 8324414464.0000 - val_mae: 68905.8672\n",
            "Epoch 915/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1231654912.0000 - mae: 20167.1250 - val_loss: 8325332480.0000 - val_mae: 68936.2891\n",
            "Epoch 916/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1455614336.0000 - mae: 20585.4121 - val_loss: 8320859648.0000 - val_mae: 68880.9531\n",
            "Epoch 917/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1007146560.0000 - mae: 18494.4922 - val_loss: 8315249664.0000 - val_mae: 68831.9297\n",
            "Epoch 918/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1102911360.0000 - mae: 19060.1484 - val_loss: 8322229760.0000 - val_mae: 68887.4688\n",
            "Epoch 919/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1531249408.0000 - mae: 20417.5215 - val_loss: 8320618496.0000 - val_mae: 68868.9375\n",
            "Epoch 920/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1010478720.0000 - mae: 19143.5781 - val_loss: 8307687424.0000 - val_mae: 68756.2656\n",
            "Epoch 921/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1257985792.0000 - mae: 19893.7539 - val_loss: 8309271552.0000 - val_mae: 68786.6328\n",
            "Epoch 922/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 991433024.0000 - mae: 18640.4062 - val_loss: 8310394368.0000 - val_mae: 68789.6328\n",
            "Epoch 923/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1101953280.0000 - mae: 18523.8359 - val_loss: 8303571968.0000 - val_mae: 68757.6562\n",
            "Epoch 924/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1327429632.0000 - mae: 19457.1523 - val_loss: 8316231168.0000 - val_mae: 68887.5078\n",
            "Epoch 925/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 901820544.0000 - mae: 17816.3828 - val_loss: 8308941824.0000 - val_mae: 68831.0078\n",
            "Epoch 926/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1257467392.0000 - mae: 19963.3574 - val_loss: 8311897088.0000 - val_mae: 68865.2188\n",
            "Epoch 927/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 837495168.0000 - mae: 17677.0020 - val_loss: 8291238400.0000 - val_mae: 68662.0703\n",
            "Epoch 928/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 988396352.0000 - mae: 17984.3301 - val_loss: 8304337408.0000 - val_mae: 68804.7500\n",
            "Epoch 929/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1109645696.0000 - mae: 19412.6777 - val_loss: 8282734592.0000 - val_mae: 68567.8125\n",
            "Epoch 930/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1030354688.0000 - mae: 19326.1133 - val_loss: 8288299008.0000 - val_mae: 68641.0156\n",
            "Epoch 931/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1073961216.0000 - mae: 19705.3535 - val_loss: 8294451200.0000 - val_mae: 68710.7188\n",
            "Epoch 932/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1454848384.0000 - mae: 19658.4453 - val_loss: 8299708416.0000 - val_mae: 68753.2500\n",
            "Epoch 933/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1118418688.0000 - mae: 18792.1641 - val_loss: 8274720256.0000 - val_mae: 68461.3203\n",
            "Epoch 934/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1138109440.0000 - mae: 19366.8691 - val_loss: 8282238976.0000 - val_mae: 68553.2422\n",
            "Epoch 935/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1034934784.0000 - mae: 17971.7207 - val_loss: 8278455808.0000 - val_mae: 68546.1641\n",
            "Epoch 936/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1086838144.0000 - mae: 19540.7344 - val_loss: 8280496128.0000 - val_mae: 68585.2422\n",
            "Epoch 937/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1031375488.0000 - mae: 19419.4102 - val_loss: 8288441344.0000 - val_mae: 68695.2500\n",
            "Epoch 938/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 825969344.0000 - mae: 16951.6855 - val_loss: 8275844096.0000 - val_mae: 68584.0000\n",
            "Epoch 939/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1017646656.0000 - mae: 18911.1230 - val_loss: 8286282240.0000 - val_mae: 68746.5000\n",
            "Epoch 940/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1338560384.0000 - mae: 20319.6836 - val_loss: 8275736064.0000 - val_mae: 68687.7500\n",
            "Epoch 941/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1458709376.0000 - mae: 21493.9824 - val_loss: 8257553920.0000 - val_mae: 68537.0156\n",
            "Epoch 942/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1383985280.0000 - mae: 19359.9082 - val_loss: 8250246656.0000 - val_mae: 68450.1875\n",
            "Epoch 943/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 908271360.0000 - mae: 17154.1543 - val_loss: 8252626432.0000 - val_mae: 68465.6484\n",
            "Epoch 944/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 926502144.0000 - mae: 17472.3359 - val_loss: 8261420544.0000 - val_mae: 68529.7656\n",
            "Epoch 945/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 964567552.0000 - mae: 18003.8711 - val_loss: 8254419968.0000 - val_mae: 68441.6484\n",
            "Epoch 946/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1435375488.0000 - mae: 20326.4395 - val_loss: 8254858752.0000 - val_mae: 68444.0938\n",
            "Epoch 947/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1514077568.0000 - mae: 20787.3203 - val_loss: 8255626752.0000 - val_mae: 68466.7578\n",
            "Epoch 948/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 980985600.0000 - mae: 17872.9043 - val_loss: 8253055488.0000 - val_mae: 68456.7266\n",
            "Epoch 949/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1120397568.0000 - mae: 19680.0547 - val_loss: 8248824832.0000 - val_mae: 68443.8047\n",
            "Epoch 950/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1059295872.0000 - mae: 18781.2578 - val_loss: 8256550912.0000 - val_mae: 68533.1484\n",
            "Epoch 951/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1110610176.0000 - mae: 19206.5859 - val_loss: 8246379008.0000 - val_mae: 68465.4531\n",
            "Epoch 952/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1226424448.0000 - mae: 18865.3789 - val_loss: 8244904448.0000 - val_mae: 68461.9609\n",
            "Epoch 953/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 894896768.0000 - mae: 17876.1406 - val_loss: 8236665856.0000 - val_mae: 68381.0781\n",
            "Epoch 954/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1048264576.0000 - mae: 18711.3711 - val_loss: 8225757184.0000 - val_mae: 68262.5547\n",
            "Epoch 955/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1303277568.0000 - mae: 19877.3770 - val_loss: 8274242048.0000 - val_mae: 68765.7500\n",
            "Epoch 956/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1531261184.0000 - mae: 22121.2656 - val_loss: 8256666624.0000 - val_mae: 68634.6953\n",
            "Epoch 957/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1365806208.0000 - mae: 20868.3789 - val_loss: 8235897856.0000 - val_mae: 68467.8516\n",
            "Epoch 958/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1121749760.0000 - mae: 18562.2383 - val_loss: 8231914496.0000 - val_mae: 68460.2109\n",
            "Epoch 959/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1044672128.0000 - mae: 19684.9102 - val_loss: 8223371776.0000 - val_mae: 68361.7891\n",
            "Epoch 960/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1042486848.0000 - mae: 18733.1348 - val_loss: 8223345152.0000 - val_mae: 68342.0000\n",
            "Epoch 961/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 848384512.0000 - mae: 16651.1719 - val_loss: 8232215552.0000 - val_mae: 68448.0469\n",
            "Epoch 962/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1103763456.0000 - mae: 19035.7754 - val_loss: 8233427968.0000 - val_mae: 68484.8438\n",
            "Epoch 963/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1148527360.0000 - mae: 19498.4004 - val_loss: 8224404480.0000 - val_mae: 68406.4531\n",
            "Epoch 964/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1240542464.0000 - mae: 20646.6582 - val_loss: 8219694080.0000 - val_mae: 68340.4297\n",
            "Epoch 965/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1159357056.0000 - mae: 18764.8574 - val_loss: 8216623616.0000 - val_mae: 68328.0703\n",
            "Epoch 966/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1355559552.0000 - mae: 19766.7402 - val_loss: 8231920128.0000 - val_mae: 68507.0625\n",
            "Epoch 967/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1393113472.0000 - mae: 19675.2031 - val_loss: 8239148032.0000 - val_mae: 68575.2734\n",
            "Epoch 968/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1118009728.0000 - mae: 19161.5195 - val_loss: 8223929856.0000 - val_mae: 68420.0391\n",
            "Epoch 969/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 955083648.0000 - mae: 17964.4219 - val_loss: 8229706752.0000 - val_mae: 68486.7734\n",
            "Epoch 970/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 924978752.0000 - mae: 17942.0527 - val_loss: 8222951424.0000 - val_mae: 68456.5859\n",
            "Epoch 971/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 940554048.0000 - mae: 17529.2656 - val_loss: 8216849920.0000 - val_mae: 68427.0000\n",
            "Epoch 972/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1161547520.0000 - mae: 20185.2754 - val_loss: 8215578112.0000 - val_mae: 68431.5703\n",
            "Epoch 973/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1237024768.0000 - mae: 20028.0977 - val_loss: 8218983424.0000 - val_mae: 68467.0312\n",
            "Epoch 974/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 949958912.0000 - mae: 18074.5391 - val_loss: 8208073216.0000 - val_mae: 68374.5469\n",
            "Epoch 975/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1030839168.0000 - mae: 19005.4375 - val_loss: 8216415744.0000 - val_mae: 68459.4922\n",
            "Epoch 976/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1225512448.0000 - mae: 19501.7656 - val_loss: 8212066816.0000 - val_mae: 68417.7109\n",
            "Epoch 977/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 932352448.0000 - mae: 18208.4004 - val_loss: 8197568512.0000 - val_mae: 68287.5469\n",
            "Epoch 978/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1275160192.0000 - mae: 20975.7500 - val_loss: 8210510848.0000 - val_mae: 68445.4453\n",
            "Epoch 979/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 955397568.0000 - mae: 17746.2891 - val_loss: 8193260032.0000 - val_mae: 68284.0703\n",
            "Epoch 980/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1393791488.0000 - mae: 19961.3145 - val_loss: 8196553728.0000 - val_mae: 68296.0938\n",
            "Epoch 981/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1107743616.0000 - mae: 19000.4219 - val_loss: 8198769152.0000 - val_mae: 68316.2422\n",
            "Epoch 982/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 922619968.0000 - mae: 17682.5117 - val_loss: 8202564096.0000 - val_mae: 68374.8203\n",
            "Epoch 983/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1277799680.0000 - mae: 20334.9883 - val_loss: 8190346752.0000 - val_mae: 68229.7266\n",
            "Epoch 984/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1062485056.0000 - mae: 19023.9199 - val_loss: 8192070656.0000 - val_mae: 68258.9609\n",
            "Epoch 985/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1017433024.0000 - mae: 18227.9141 - val_loss: 8214091776.0000 - val_mae: 68475.8047\n",
            "Epoch 986/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 936425856.0000 - mae: 18569.2402 - val_loss: 8195257856.0000 - val_mae: 68290.0781\n",
            "Epoch 987/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 886500800.0000 - mae: 16916.5020 - val_loss: 8188283904.0000 - val_mae: 68239.9844\n",
            "Epoch 988/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1010398848.0000 - mae: 17892.5762 - val_loss: 8192641536.0000 - val_mae: 68328.3047\n",
            "Epoch 989/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1243575936.0000 - mae: 19704.9082 - val_loss: 8174641664.0000 - val_mae: 68171.7031\n",
            "Epoch 990/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1055477952.0000 - mae: 19954.6777 - val_loss: 8170604544.0000 - val_mae: 68159.5156\n",
            "Epoch 991/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 866521152.0000 - mae: 17332.4922 - val_loss: 8185040384.0000 - val_mae: 68311.3906\n",
            "Epoch 992/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 850431552.0000 - mae: 16716.2969 - val_loss: 8165561344.0000 - val_mae: 68097.3125\n",
            "Epoch 993/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1388927616.0000 - mae: 19608.9141 - val_loss: 8171091456.0000 - val_mae: 68186.8516\n",
            "Epoch 994/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1340713600.0000 - mae: 21085.0703 - val_loss: 8174869504.0000 - val_mae: 68246.2188\n",
            "Epoch 995/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1569038976.0000 - mae: 20791.3203 - val_loss: 8165756416.0000 - val_mae: 68178.6406\n",
            "Epoch 996/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1096136192.0000 - mae: 18985.2773 - val_loss: 8143796736.0000 - val_mae: 67920.1484\n",
            "Epoch 997/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1102037504.0000 - mae: 19132.2871 - val_loss: 8150094848.0000 - val_mae: 68002.4844\n",
            "Epoch 998/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 941772992.0000 - mae: 17708.6484 - val_loss: 8164163584.0000 - val_mae: 68150.1875\n",
            "Epoch 999/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1116810880.0000 - mae: 19084.8438 - val_loss: 8169965568.0000 - val_mae: 68209.2344\n",
            "Epoch 1000/1000\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1119604736.0000 - mae: 18728.2871 - val_loss: 8163528192.0000 - val_mae: 68139.9062\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3819418880.0000 - mae: 47001.4375\n",
            "MLP MAE: 45938.50390625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3be11968-2f67-4faf-b382-b688e4f42d39",
      "metadata": {
        "id": "3be11968-2f67-4faf-b382-b688e4f42d39"
      },
      "source": [
        "# Results\n",
        "Below is a bar chart that compares the mean absolute error of all the models. In addition, a bell curve plotting the residuals from the best model is displayed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "b2a475ea-bd2c-495c-9cfa-7676cc5aeff5",
      "metadata": {
        "id": "b2a475ea-bd2c-495c-9cfa-7676cc5aeff5",
        "outputId": "cacdf6d3-5375-4883-af8a-c359e7199234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Model names\n",
        "models = ['Linear Regression (FS vs PCA)', 'SVM', 'Random Forest', 'Gradient Boosting', 'MLP']\n",
        "\n",
        "# MAE values\n",
        "mae_with_pca = [best_mae_lrfs, best_mae_svr_w_pca, best_mae_rf_w_pca, best_mae_gb_w_pca, mlp_mae]\n",
        "\n",
        "# Bar positions\n",
        "bar_width = 0.35  # Width of the bars\n",
        "index = np.arange(len(models))  # Index for each group (each model)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "bar = ax.bar(index + bar_width, mae_with_pca, bar_width)\n",
        "\n",
        "ax.set_xlabel('Models')\n",
        "ax.set_ylabel('Mean Absolute Error')\n",
        "ax.set_title('MAE comparison of models')\n",
        "ax.set_xticks(index + bar_width)  # Centering the ticks\n",
        "ax.set_xticklabels(models)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "db862bd9-fd16-4333-ba9e-31fc09de9e9c",
      "metadata": {
        "id": "db862bd9-fd16-4333-ba9e-31fc09de9e9c",
        "outputId": "8277a988-16aa-481b-f059-01d112581c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Re-create the best model, extract the residuals, and plot the bell curve\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train = sm.add_constant(X_train)\n",
        "X_test = sm.add_constant(X_test)\n",
        "\n",
        "best_model = sm.OLS(y_train, X_train[initial_features]).fit()\n",
        "y_pred = best_model.predict(X_test[initial_features])\n",
        "\n",
        "pred_test_vals = [(y_pred_i, y_test_i) for y_pred_i, y_test_i in zip(y_pred, y_test)]\n",
        "\n",
        "# residuals (predictions - actual values)\n",
        "residuals = np.array([pred - actual for pred, actual in pred_test_vals])\n",
        "\n",
        "# Calculate mean and standard deviation\n",
        "mean_residuals = np.mean(residuals)\n",
        "std_residuals = np.std(residuals)\n",
        "\n",
        "# Generate x values for the bell curve\n",
        "x_values = np.linspace(mean_residuals - 4*std_residuals, mean_residuals + 4*std_residuals, 100)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "# Plot the histogram\n",
        "hist = plt.hist(residuals, bins=30, density=True, alpha=0.6, color='g', label=\"Residuals\")\n",
        "\n",
        "# Plot the bell curve (normal distribution)\n",
        "curve, = plt.plot(x_values, norm.pdf(x_values, mean_residuals, std_residuals), label=\"Normal Distribution\")\n",
        "\n",
        "# Plot vertical lines for standard deviations\n",
        "for i in range(1, 4):\n",
        "    line1 = plt.axvline(mean_residuals + i*std_residuals, color='r', linestyle='--', label=f'+{i} SD')\n",
        "    line2 = plt.axvline(mean_residuals - i*std_residuals, color='r', linestyle='--', label=f'-{i} SD')\n",
        "\n",
        "plt.annotate(f'Mean: {mean_residuals:.2f}', xy=(0.05, 0.1), xycoords='axes fraction', fontsize=8, color='black')\n",
        "plt.annotate(f'SD: {std_residuals:.2f}', xy=(0.05, 0.05), xycoords='axes fraction', fontsize=8, color='black')\n",
        "\n",
        "# customize which parts of the plot appear in the legend\n",
        "handles, labels = plt.gca().get_legend_handles_labels()\n",
        "\n",
        "# Filter out unwanted legend labels\n",
        "desired_handles = [handles[0], handles[1]]  # Only show 'Normal Distribution'\n",
        "desired_labels = [labels[0], labels[1]]\n",
        "\n",
        "plt.legend(desired_handles, desired_labels)  # Create the legend with filtered labels\n",
        "\n",
        "# Show plot\n",
        "plt.title(\"Residuals Bell Curve\")\n",
        "plt.xlabel(\"Residuals (Prediction - Actual)\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87df933b-cc57-40e8-9bd1-2aa454e00c67",
      "metadata": {
        "id": "87df933b-cc57-40e8-9bd1-2aa454e00c67"
      },
      "source": [
        "# Discussion/Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34762941-e3ac-4397-9c14-4e125f608807",
      "metadata": {
        "id": "34762941-e3ac-4397-9c14-4e125f608807"
      },
      "source": [
        "Based on the bar chart, the model that performed the best was still the linear regressor with forward selection to reduce the features. This could be because forward selection directly selects the most relevant features based on the model's performance, rather than based on variance as in PCA. Forward selection tailors the feature selection process to the model's outcome, which has a direct impact on how well it performs. PCA is great for reducing dimensionality, but it doesn't always keep the features that  result in the best predictions of the target, which may be why it underperformed compared to PCA.\n",
        "\n",
        "SVM and Gradient Boosting saw no effect between keeping all of the features and reducing the features using PCA. This demonstrates that these models are capable of producing consistent results in spite of how large a feature space may be. Therefore, PCA did not provide additional value in improving their performance.\n",
        "\n",
        "The model that saw the largest improvement using PCA to reduce the feature space was random forest. This is an intially suprising result, considering that random forest are generally capable of handling a larger feature space. Nonetheless, the feature space could have contained highly correlated features, which impacts how well random forests are able to generalize to the test data. Since PCA not only reduces the feature space, but also decorrelates the data, the random forrest model saw substantial improvement. Therfore, when the random forrest model is presented with highly correlated data, it could still substantially benefit from the PCA feature reduction technique.\n",
        "\n",
        "The MLP actually performed the worse out of all the models. This is perhaps because the network is fairly simple. Perhaps a deeper model with batch normalization and dropout would perform better. In addition, though the network was trained over 1000 epochs, perhaps more epochs and longer training time would produce better results.\n",
        "\n",
        "\n",
        "Overall, the supervised models producecd moderate predictions of salary information so that they could be used in practical applications. For example, given that some companies do not give a salary range for their job postings, one of these models could be used to predict the salary based on the job title, location, and company score (which could be looked up online). Nonetheless, the prediction has a significant likelihood of having a large error, rendering the result of the prediction to be untrustworthy. Looking at the bell curve for the Linear Regressor with Forward Selection, the model was off on average by $\\$$8000, which is not bad on the surface, however, the data is spread fairly wide with a standard deviation of $\\$$47,791. This means that approximately 70% of the predictions are within a $\\$$47,791 tolerance. That being said, there are some significant outliers affecting the bell curve plot in the model. One prediction was about $\\$$250,000 off of the actual value. This has a significant impact on the mean and standard deviation.\n",
        "\n",
        "A way to improve the predictions would be to work on tuning the features more for each model, even doing more feature engineering past PCA. One of the best ways to improve these models is to find more important features. For example, one highly correlated feature with salary is years of experience. If the expected 'years of experience' data could be extracted from the job postings, perhaps this would make a better feature than 'job title' which is a categorical feature. More numerical features could be helpful in predicting the salaries rather than the categorical variables that I was able to attain in the dataset.\n",
        "\n",
        "Another takeaway from this project is that while neural networks are all the buzz right now, traditional machine learning models can perform just as well if not better than neural networks for certain tasks. In this project, the most complicated model (the MLP) presented the worst results whereas the simplest model (the linear regressor) was the highest performing model. The principal of Occam's Razor also applies here, which states that when multiple models perform similarly, the simiplest model should be selected. In this case, the linear regressor should be chosen to predict the software engineering salaries.\n",
        "\n",
        "In conclusion, while the linear regressor model with feature selection performed the best over the rest of the models, it still contained a significant amount of error. While this could introduce a lack of trust in the model's predictions in a real-world scenario, the prediction could still be used as a practical baseline, since the user understands there may be siginifanct error in the prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad47528c-0e04-45ae-9784-24294693b49f",
      "metadata": {
        "id": "ad47528c-0e04-45ae-9784-24294693b49f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}